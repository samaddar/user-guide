{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"RCC User Guide This user guide provides information on accessing and making use of all RCC resources. The following diagram illustrates the workflow of a typical RCC user: Overview of RCC Systems The following table provides a high-level summary of the various high-performance computing (HPC) systems that the RCC houses. System Description Status Midway3 RCC's flagship HPC cluster for multi-purpose scientific computing Active MidwayR RCC's HPC cluster for sensitive data, housed within the Secure Data Enclave Active Beagle3 A GPU-focused HPC cluster for life sciences research Active DaLI Data Lifecycle Instrument, a data storage and software platform Active MidwaySSD HPC cluster dedicated to social sciences research Active Skyway Run Midway jobs on cloud computing platforms Active Midway2 Primary HPC cluster from 2018-2021; users transitioning to Midway3 Active Getting started Researchers interested in using the RCC systems can request an account at: [create_and_manage_account.md] Request an allocation of computing time and storage resources at: [request_and_manage_allocations.md] If you would like to chat with an RCC specialist about what services are best for you, please email help@rcc.uchicago.edu Using Midway If you'd like to to get started using our RCC resources, our Getting Started webpage provides information on what you need to do in order to get time on our systems, get an account, and how to start running jobs.","title":"Home"},{"location":"#rcc-user-guide","text":"This user guide provides information on accessing and making use of all RCC resources. The following diagram illustrates the workflow of a typical RCC user:","title":"RCC User Guide"},{"location":"#overview-of-rcc-systems","text":"The following table provides a high-level summary of the various high-performance computing (HPC) systems that the RCC houses. System Description Status Midway3 RCC's flagship HPC cluster for multi-purpose scientific computing Active MidwayR RCC's HPC cluster for sensitive data, housed within the Secure Data Enclave Active Beagle3 A GPU-focused HPC cluster for life sciences research Active DaLI Data Lifecycle Instrument, a data storage and software platform Active MidwaySSD HPC cluster dedicated to social sciences research Active Skyway Run Midway jobs on cloud computing platforms Active Midway2 Primary HPC cluster from 2018-2021; users transitioning to Midway3 Active","title":"Overview of RCC Systems"},{"location":"#getting-started","text":"Researchers interested in using the RCC systems can request an account at: [create_and_manage_account.md] Request an allocation of computing time and storage resources at: [request_and_manage_allocations.md] If you would like to chat with an RCC specialist about what services are best for you, please email help@rcc.uchicago.edu","title":"Getting started"},{"location":"#using-midway","text":"If you'd like to to get started using our RCC resources, our Getting Started webpage provides information on what you need to do in order to get time on our systems, get an account, and how to start running jobs.","title":"Using Midway"},{"location":"create_and_manage_accounts/","text":"RCC User Guide Hello! This user guide provides information on accessing and making use of all RCC resources. Overview of RCC Systems Here's a high-level summary of the various high-performance computing (HPC) systems that the RCC houses. System Description Status Midway3 RCC's flagship HPC cluster for multi-purpose scientific computing Active MidwayR RCC's HPC cluster for sensitive data, housed within the Secure Data Enclave Active Beagle3 A GPU-focused HPC cluster for life sciences research Active DaLI Data Lifecycle Instrument, a data storage and software platform Active MidwaySSD HPC cluster dedicated to social sciences research Active Skyway Run Midway jobs on cloud computing platforms Active Midway2 Primary HPC cluster from 2018-2021; users transitioning to Midway3 Active Getting started Researchers interested in using the RCC systems can request an account at: [create_and_manage_account.md] Request an allocation of computing time and storage resources at: [request_and_manage_allocations.md] If you would like to chat with an RCC specialist about what services are best for you, please email help@rcc.uchicago.edu Using Midway If you'd like to to get started using our RCC resources, our Getting Started webpage provides information on what you need to do in order to get time on our systems, get an account, and how to start running jobs.","title":"Account Management"},{"location":"create_and_manage_accounts/#rcc-user-guide-hello","text":"This user guide provides information on accessing and making use of all RCC resources.","title":"RCC User Guide Hello!"},{"location":"create_and_manage_accounts/#overview-of-rcc-systems","text":"Here's a high-level summary of the various high-performance computing (HPC) systems that the RCC houses. System Description Status Midway3 RCC's flagship HPC cluster for multi-purpose scientific computing Active MidwayR RCC's HPC cluster for sensitive data, housed within the Secure Data Enclave Active Beagle3 A GPU-focused HPC cluster for life sciences research Active DaLI Data Lifecycle Instrument, a data storage and software platform Active MidwaySSD HPC cluster dedicated to social sciences research Active Skyway Run Midway jobs on cloud computing platforms Active Midway2 Primary HPC cluster from 2018-2021; users transitioning to Midway3 Active","title":"Overview of RCC Systems"},{"location":"create_and_manage_accounts/#getting-started","text":"Researchers interested in using the RCC systems can request an account at: [create_and_manage_account.md] Request an allocation of computing time and storage resources at: [request_and_manage_allocations.md] If you would like to chat with an RCC specialist about what services are best for you, please email help@rcc.uchicago.edu","title":"Getting started"},{"location":"create_and_manage_accounts/#using-midway","text":"If you'd like to to get started using our RCC resources, our Getting Started webpage provides information on what you need to do in order to get time on our systems, get an account, and how to start running jobs.","title":"Using Midway"},{"location":"facility_policies/","text":"Policies","title":"Policies"},{"location":"facility_policies/#policies","text":"","title":"Policies"},{"location":"general_faq/","text":"Frequently Asked Questions General How do I cite RCC in my publications and talks? Citations and acknowledgements help the RCC demonstrate the importance of computational resources and support staff in research at the University of Chicago. We ask that an acknolwedgment be given to the RCC in any presentation or publication of results that were made possible by RCC resources. Please reference the RCC as \u201cThe University of Chicago Research Computing Center\u201d in citations and acknowledgements. Here are a few examples of suggested text: This work was completed in part with resources provided by the University of Chicago Research Computing Center. We are grateful for the support of the University of Chicago Research Computing Center for assistance with the calculations carried out in this work. We acknowledge the University of Chicago Research Computing Center for support of this work. If you cite or acknowledge the RCC in your work, please notify the RCC by sending an email to info@rcc.uchicago.edu. Getting Started How do I become an RCC user? RCC user account requests should be submitted via our online application forms. See RCC Account Request for more information. How do I access RCC systems? There are various ways to access RCC systems. To access Midway2 interactively, use ThinLinc or an SSH client. See Connecting to RCC Resources for details. To access files stored on Midway2, use scp, Globus Online or SAMBA. See Data Transfer for details. How do I request access to a PI\u2019s account if I already have an account on Midway? Please submit a User Account Request and provide your CNetID and the PI Account name (typically pi- followed by the CNetID of the PI). The PI will receive an automated email requesting authorization for this request. What is my RCC username and password? The RCC uses the University of Chicago CNetIDs for user credentials. Once your RCC account is created, your RCC username and password will be the same as your CNetID credentials. Can an external collaborator get a CNetID so they can log in to RCC? The RCC can create CNetIDs for external collaborators. See RCC Account Request for more information. What should I do if I left the university and my CNetID password no longer works? You can use your CNetID for authentication after you have left, but IT Services may expire it when you leave. If you have an RCC account, but you still can\u2019t log in, it is likely that password authentication has been disabled by IT Services. Please contact help@rcc.uchicago.edu to request re-enabling access to your account. How do I change/reset my password? The RCC cannot change or reset your password. Go to the CNet Password Recovery page to change or reset your password. What groups am I a member of? To list the groups you are a member of, type groups on any RCC system. How do I access the data visualization lab in the Zar room of Crerar Library? The Zar room and its visualization equipment can be reserved for events, classes, or visualization work by contacting the RCC at help@rcc.uchicago.edu. More information regarding the RCC\u2019s visualization facilities can be found on the RCC Data Visualization page. What login shells are supported and how do I change my default shell? The RCC supports the following shells: /bin/bash /bin/tcsh /bin/zsh Use this command to change your default shell: $ chsh -s /path/to/shell It may take up to 30 minutes for that change to take effect. Is remote access with Mosh supported? Yes. To use Mosh, first log in to Midway via SSH, and add the command module load mosh to your ~/.bashrc (or ~/.zshenv if you use zsh). Then, you can log in by entering the following command in a terminal window: $ mosh @midway2.rcc.uchicago.edu Is SSH key authentication allowed on RCC machines? No. Why am I getting \u201cssh_exchange_identification: read: Connection reset by peer\u201d when I try to log in via SSH ? You can get this error if you incorrectly enter your password too many times. This is a security measure that is in place to limit the ability for malicious users to use brute force SSH attacks against our systems. After 3 failed password entry attempts, an IP address will be blocked for 4 hours. While you wait for the block to be lifted, you should still be able to access Midway2 using ThinLinc. Why am I getting prompted for YubiKey when I try to log in via SSH ? There are few reasons to get that error message. Please enroll in two factor authentication if you have not done already by visiting https://2fa.rcc.uchicago.edu. Please make sure you run ssh -Y your_cnetID@midway2.rcc.uchicago.edu. Finally, please make sure your Midway account has not been expired. Allocations What is an allocation? An allocation is a specified number of computing and storage resources granted to a PI or education account. An allocation is necessary to run jobs on RCC systems. See RCC Allocations for more details. What is a service unit (SU)? A service unit (SU) is roughly equal to 1 core-hour; for a more precise definition, see RCC Service Units. How do I obtain an allocation? The RCC accepts proposals for large (\u201cResearch II\u201d) allocations bi-annually. Medium-sized allocations, special purpose allocations for time-critical research, and allocations for education and outreach may be submitted at any time. See RCC Allocations for more information. How is compute cluster usage charged to my account? The charge associated with a job on Midway2 is a function of (1) the number of cores allocated to the job, and (2) the elapsed wall-clock time (in hours). How do I check the balance of my allocation? The rcchelp tool is the easiest way to check your account balance. $ rcchelp balance How do I check how my allocation has been used? The rcchelp tool has several options for summarizing allocation usage. For a summary, run $ rcchelp usage To see usage per job, run $ rcchelp usage --byjob If you are the PI, you may use --byuser option to see your group members\u2019 individual usage $ rcchelp usage --byuser Software What software does RCC offer on its compute systems? Software available within the RCC environment is constantly evolving. We regularly install new software, and new versions of existing software. Information about available software and how to use specific software pacakges can be found in the Software section of the User Guide. To view the current list of installed software on Midway2, run $ module avail To view the list of available versions for a specific software, run $ module avail How do I get help with RCC software? Documentation for many program can be viewed with the following command. $ man Many programs also provide documentation through command-line options such as --help or -h. For example, $ module load gcc $ gcc --help RCC also maintains supplementary documentation for software specific to our systems. Consult the Software page for more information. Why is my favorite command not available? Most likely it is because you have not loaded the appropriate software module. Most software packages are only available after first loading the appropriate software module. See Software for more information on how to access pre-installed software on RCC systems. Why do I get an error that says a module cannot be loaded due to a conflict? Occassionally, modules are incompatible with each other and cannot be loaded simultaneously. The module command typically gives you hints about which previously loaded module conflicts with the one you are trying to load. If you see such an error, try unloading a module with this command: $ module unload How do I request installation of a new or updated software package? Please send email to help@rcc.uchicago.edu with the details of your software request, including what software package you need and which version of the software you prefer. Why can\u2019t I run Gaussian? Gaussian\u2019s creators have historically had a strict usage policy, so we have limited its availability on RCC systems. If you need to use Gaussian for your research, please contact help@rcc.uchicago.edu to request access. Cluster Usage How do I submit a job to the queue? RCC systems use Slurm to manage resources and job queues. For advice on how to run specific types of jobs, consult the Running jobs on midway section of the User Guide. Can I login directly to a compute node? You can start up an interactive session on a compute node with the sinteractive command. This command takes the same arguments as sbatch. More information about interactive jobs, see Interactive Jobs. How do I run jobs in parallel? There are many ways to configure parallel jobs\u2014the best approach will depend on your software and resource requirements. For more information on two commonly used approaches, see Parallel batch jobs and Job arrays. Are there any limits to running jobs on Midway2? Run rcchelp qos on Midway to view the current criteria. I am a member of multiple accounts. How do I choose which allocation is charged? If you belong to multiple accounts, jobs will get charged to your default account unless you specify the --account= option when you submit a job with sbatch. Run this command to determine your default account. sacctmgr list user $USER To change your default account, run this command. sacctmgr modify user $USER set defaultaccount= Alternatively, you may request the change by contacting the RCC. Why is my job not starting? This could be due to a variety of factors. Running squeue --user= can will help to find the answer; see in particular the NODELIST(REASON) column in the squeue output. A job that is waiting in the queue may show one of the following labels in this column: (Priority): Other jobs currently have higher priority than your job. (Resources): Your job has enough priority to run, but there aren\u2019t yet enough free resources to run it. (QOSResourceLimit): Your job exceeds the QOS limits. The QOS limits include wall time, number of jobs a user can have running at once, number of nodes a user can use at once, and so on. For example, if you are at or near the limit of number of jobs that can be run at once, your job will become eligible to run as soon as other jobs finish. Please contact RCC support if you believe that your job is not being handled correctly by the Slurm queuing system. Also, note that if you see a large number of jobs that aren\u2019t running when many resources are idle, it is possible that RCC staff have scheduled an upcoming maintenance window. In this case, any jobs requesting a wall time that overlaps with the maintenance window will remain in the queue until after the maintainence period is over. The RCC staff will typically notify users via email prior to performing a maintenance and after a maintenance is completed. Why does my job fail after a few seconds? This is most likely because there is an error in your job submission script, or because the program you are trying to run is producing an error and terminating prematurely. If you need help troubleshooting the issue, please send your job submission script, as well as the error generated by your job submission script, to help@rcc.uchicago.edu. Why does my job fail with message \u201cexceeded memory limit, being killed\u201d? On the main midway2 partition, broadwl, Slurm allocates 2 GB of memory per allocated CPU by default. If your computations require more than the default amount, you should adjust the memory allocated to your job with the --mem or --mem-per-cpu flags. For example, to request 10 cores and 40 GB of memory on a broadwl node, include these options when running sbatch or sinteractive: --ntasks=1 --cpus-per-task=10 --mem=40G. Why does my sinteractive job fail with \u201cConnection to closed.\u201d? There are two likely explanations for this error. One possibility is that you are over the time limit. The default walltime for sinteractive is 2 hours. This can be increased by including the --time flag to your sinteractive call. Another possiblity is that your job exceeded the memory limit. You can resolve this by requesting additional memory using --mem or --mem-per-cpu. How do I run jobs that need to run longer than the maximum wall time? The RCC queuing system is designed to provide fair resource allocation to all RCC users. The maximum wall time is intended to prevent individual users from using more than their fair share of cluster resources. If you have specific computing tasks that cannot be solved with the current constraints, please submit a special request for resources to help@rcc.uchicago.edu. Can I create a cron job? The RCC does not support users creating cron jobs. However, it is possible to use Slurm to submit \u201ccron-like\u201d jobs. See Cron-like jobs for more information. Performance and Coding What compilers does the RCC support? The RCC supports the GNU, Intel, PGI and NVidia\u2019s CUDA compilers. Which versions of MPI does RCC support? The RCC maintains OpenMPI, IntelMPI, and MVAPICH2 compilers. See Message Passing Interface (MPI) for more information and instructions for using these MPI frameworks. Can the RCC help me parallelize and optimize my code? The RCC support staff are available to consult with you or your research team to help parallelize and optimize your code for use on RCC systems. Contact the RCC staff at help@rcc.uchicago.edu to set up a consultation. Does RCC provide GPU computing resources? Yes. The RCC high-performance systems provide GPU-equipped compute nodes. For instructions on using the GPU nodes, see GPU jobs. File I/O, Storage, and Transfers How much storage space do I have? Use the quota command to get a summary of your current file system usage and available storage space. How do I get my storage quota increased? Additional storage space can be purchased through the Cluster Partnership Program. You may also request additional storage as part of a Research II Allocation or Special Allocation. How do I share files with others? The recommended way to share files with members of your group is to store them in the /project or /project2 directory for your group. Project directories are created for all PI and project accounts. File and directory permissions can be customized to allow access to users within the group, as well as RCC users that do not belong to your group. I accidentally deleted or lost a file. How do I restore it? The best way to recover a recently deleted, corrupted or lost file is from a snapshot. See Data Recovery and Backups for more information. How do I request a restore of my files from tape backup? The RCC maintains tape backups of all home and project directories. These tape backups are intended for disaster recovery purposes only. There is no long-term history of files on tape. In most cases, you should use file system snapshots to retrieve recover files. See Data Recovery and Backups for more information.","title":"Frequently Asked Questions"},{"location":"general_faq/#frequently-asked-questions","text":"","title":"Frequently Asked Questions"},{"location":"general_faq/#general","text":"","title":"General"},{"location":"general_faq/#how-do-i-cite-rcc-in-my-publications-and-talks","text":"Citations and acknowledgements help the RCC demonstrate the importance of computational resources and support staff in research at the University of Chicago. We ask that an acknolwedgment be given to the RCC in any presentation or publication of results that were made possible by RCC resources. Please reference the RCC as \u201cThe University of Chicago Research Computing Center\u201d in citations and acknowledgements. Here are a few examples of suggested text: This work was completed in part with resources provided by the University of Chicago Research Computing Center. We are grateful for the support of the University of Chicago Research Computing Center for assistance with the calculations carried out in this work. We acknowledge the University of Chicago Research Computing Center for support of this work. If you cite or acknowledge the RCC in your work, please notify the RCC by sending an email to info@rcc.uchicago.edu.","title":"How do I cite RCC in my publications and talks?"},{"location":"general_faq/#getting-started","text":"","title":"Getting Started"},{"location":"general_faq/#how-do-i-become-an-rcc-user","text":"RCC user account requests should be submitted via our online application forms. See RCC Account Request for more information.","title":"How do I become an RCC user?"},{"location":"general_faq/#how-do-i-access-rcc-systems","text":"There are various ways to access RCC systems. To access Midway2 interactively, use ThinLinc or an SSH client. See Connecting to RCC Resources for details. To access files stored on Midway2, use scp, Globus Online or SAMBA. See Data Transfer for details.","title":"How do I access RCC systems?"},{"location":"general_faq/#how-do-i-request-access-to-a-pis-account-if-i-already-have-an-account-on-midway","text":"Please submit a User Account Request and provide your CNetID and the PI Account name (typically pi- followed by the CNetID of the PI). The PI will receive an automated email requesting authorization for this request.","title":"How do I request access to a PI\u2019s account if I already have an account on Midway?"},{"location":"general_faq/#what-is-my-rcc-username-and-password","text":"The RCC uses the University of Chicago CNetIDs for user credentials. Once your RCC account is created, your RCC username and password will be the same as your CNetID credentials.","title":"What is my RCC username and password?"},{"location":"general_faq/#can-an-external-collaborator-get-a-cnetid-so-they-can-log-in-to-rcc","text":"The RCC can create CNetIDs for external collaborators. See RCC Account Request for more information.","title":"Can an external collaborator get a CNetID so they can log in to RCC?"},{"location":"general_faq/#what-should-i-do-if-i-left-the-university-and-my-cnetid-password-no-longer-works","text":"You can use your CNetID for authentication after you have left, but IT Services may expire it when you leave. If you have an RCC account, but you still can\u2019t log in, it is likely that password authentication has been disabled by IT Services. Please contact help@rcc.uchicago.edu to request re-enabling access to your account.","title":"What should I do if I left the university and my CNetID password no longer works?"},{"location":"general_faq/#how-do-i-changereset-my-password","text":"The RCC cannot change or reset your password. Go to the CNet Password Recovery page to change or reset your password.","title":"How do I change/reset my password?"},{"location":"general_faq/#what-groups-am-i-a-member-of","text":"To list the groups you are a member of, type groups on any RCC system.","title":"What groups am I a member of?"},{"location":"general_faq/#how-do-i-access-the-data-visualization-lab-in-the-zar-room-of-crerar-library","text":"The Zar room and its visualization equipment can be reserved for events, classes, or visualization work by contacting the RCC at help@rcc.uchicago.edu. More information regarding the RCC\u2019s visualization facilities can be found on the RCC Data Visualization page.","title":"How do I access the data visualization lab in the Zar room of Crerar Library?"},{"location":"general_faq/#what-login-shells-are-supported-and-how-do-i-change-my-default-shell","text":"The RCC supports the following shells: /bin/bash /bin/tcsh /bin/zsh Use this command to change your default shell: $ chsh -s /path/to/shell It may take up to 30 minutes for that change to take effect.","title":"What login shells are supported and how do I change my default shell?"},{"location":"general_faq/#is-remote-access-with-mosh-supported","text":"Yes. To use Mosh, first log in to Midway via SSH, and add the command module load mosh to your ~/.bashrc (or ~/.zshenv if you use zsh). Then, you can log in by entering the following command in a terminal window: $ mosh @midway2.rcc.uchicago.edu","title":"Is remote access with Mosh supported?"},{"location":"general_faq/#is-ssh-key-authentication-allowed-on-rcc-machines","text":"No.","title":"Is SSH key authentication allowed on RCC machines?"},{"location":"general_faq/#why-am-i-getting-ssh_exchange_identification-read-connection-reset-by-peer-when-i-try-to-log-in-via-ssh","text":"You can get this error if you incorrectly enter your password too many times. This is a security measure that is in place to limit the ability for malicious users to use brute force SSH attacks against our systems. After 3 failed password entry attempts, an IP address will be blocked for 4 hours. While you wait for the block to be lifted, you should still be able to access Midway2 using ThinLinc.","title":"Why am I getting \u201cssh_exchange_identification: read: Connection reset by peer\u201d when I try to log in via SSH ?"},{"location":"general_faq/#why-am-i-getting-prompted-for-yubikey-when-i-try-to-log-in-via-ssh","text":"There are few reasons to get that error message. Please enroll in two factor authentication if you have not done already by visiting https://2fa.rcc.uchicago.edu. Please make sure you run ssh -Y your_cnetID@midway2.rcc.uchicago.edu. Finally, please make sure your Midway account has not been expired.","title":"Why am I getting prompted for YubiKey when I try to log in via SSH ?"},{"location":"general_faq/#allocations","text":"","title":"Allocations"},{"location":"general_faq/#what-is-an-allocation","text":"An allocation is a specified number of computing and storage resources granted to a PI or education account. An allocation is necessary to run jobs on RCC systems. See RCC Allocations for more details.","title":"What is an allocation?"},{"location":"general_faq/#what-is-a-service-unit-su","text":"A service unit (SU) is roughly equal to 1 core-hour; for a more precise definition, see RCC Service Units.","title":"What is a service unit (SU)?"},{"location":"general_faq/#how-do-i-obtain-an-allocation","text":"The RCC accepts proposals for large (\u201cResearch II\u201d) allocations bi-annually. Medium-sized allocations, special purpose allocations for time-critical research, and allocations for education and outreach may be submitted at any time. See RCC Allocations for more information.","title":"How do I obtain an allocation?"},{"location":"general_faq/#how-is-compute-cluster-usage-charged-to-my-account","text":"The charge associated with a job on Midway2 is a function of (1) the number of cores allocated to the job, and (2) the elapsed wall-clock time (in hours). How do I check the balance of my allocation? The rcchelp tool is the easiest way to check your account balance. $ rcchelp balance How do I check how my allocation has been used? The rcchelp tool has several options for summarizing allocation usage. For a summary, run $ rcchelp usage To see usage per job, run $ rcchelp usage --byjob If you are the PI, you may use --byuser option to see your group members\u2019 individual usage $ rcchelp usage --byuser Software","title":"How is compute cluster usage charged to my account?"},{"location":"general_faq/#what-software-does-rcc-offer-on-its-compute-systems","text":"Software available within the RCC environment is constantly evolving. We regularly install new software, and new versions of existing software. Information about available software and how to use specific software pacakges can be found in the Software section of the User Guide. To view the current list of installed software on Midway2, run $ module avail To view the list of available versions for a specific software, run $ module avail How do I get help with RCC software? Documentation for many program can be viewed with the following command. $ man Many programs also provide documentation through command-line options such as --help or -h. For example, $ module load gcc $ gcc --help RCC also maintains supplementary documentation for software specific to our systems. Consult the Software page for more information.","title":"What software does RCC offer on its compute systems?"},{"location":"general_faq/#why-is-my-favorite-command-not-available","text":"Most likely it is because you have not loaded the appropriate software module. Most software packages are only available after first loading the appropriate software module. See Software for more information on how to access pre-installed software on RCC systems.","title":"Why is my favorite command not available?"},{"location":"general_faq/#why-do-i-get-an-error-that-says-a-module-cannot-be-loaded-due-to-a-conflict","text":"Occassionally, modules are incompatible with each other and cannot be loaded simultaneously. The module command typically gives you hints about which previously loaded module conflicts with the one you are trying to load. If you see such an error, try unloading a module with this command: $ module unload How do I request installation of a new or updated software package? Please send email to help@rcc.uchicago.edu with the details of your software request, including what software package you need and which version of the software you prefer.","title":"Why do I get an error that says a module cannot be loaded due to a conflict?"},{"location":"general_faq/#why-cant-i-run-gaussian","text":"Gaussian\u2019s creators have historically had a strict usage policy, so we have limited its availability on RCC systems. If you need to use Gaussian for your research, please contact help@rcc.uchicago.edu to request access.","title":"Why can\u2019t I run Gaussian?"},{"location":"general_faq/#cluster-usage","text":"How do I submit a job to the queue? RCC systems use Slurm to manage resources and job queues. For advice on how to run specific types of jobs, consult the Running jobs on midway section of the User Guide.","title":"Cluster Usage"},{"location":"general_faq/#can-i-login-directly-to-a-compute-node","text":"You can start up an interactive session on a compute node with the sinteractive command. This command takes the same arguments as sbatch. More information about interactive jobs, see Interactive Jobs.","title":"Can I login directly to a compute node?"},{"location":"general_faq/#how-do-i-run-jobs-in-parallel","text":"There are many ways to configure parallel jobs\u2014the best approach will depend on your software and resource requirements. For more information on two commonly used approaches, see Parallel batch jobs and Job arrays.","title":"How do I run jobs in parallel?"},{"location":"general_faq/#are-there-any-limits-to-running-jobs-on-midway2","text":"Run rcchelp qos on Midway to view the current criteria.","title":"Are there any limits to running jobs on Midway2?"},{"location":"general_faq/#i-am-a-member-of-multiple-accounts-how-do-i-choose-which-allocation-is-charged","text":"If you belong to multiple accounts, jobs will get charged to your default account unless you specify the --account= option when you submit a job with sbatch. Run this command to determine your default account. sacctmgr list user $USER To change your default account, run this command. sacctmgr modify user $USER set defaultaccount= Alternatively, you may request the change by contacting the RCC.","title":"I am a member of multiple accounts. How do I choose which allocation is charged?"},{"location":"general_faq/#why-is-my-job-not-starting","text":"This could be due to a variety of factors. Running squeue --user= can will help to find the answer; see in particular the NODELIST(REASON) column in the squeue output. A job that is waiting in the queue may show one of the following labels in this column: (Priority): Other jobs currently have higher priority than your job. (Resources): Your job has enough priority to run, but there aren\u2019t yet enough free resources to run it. (QOSResourceLimit): Your job exceeds the QOS limits. The QOS limits include wall time, number of jobs a user can have running at once, number of nodes a user can use at once, and so on. For example, if you are at or near the limit of number of jobs that can be run at once, your job will become eligible to run as soon as other jobs finish. Please contact RCC support if you believe that your job is not being handled correctly by the Slurm queuing system. Also, note that if you see a large number of jobs that aren\u2019t running when many resources are idle, it is possible that RCC staff have scheduled an upcoming maintenance window. In this case, any jobs requesting a wall time that overlaps with the maintenance window will remain in the queue until after the maintainence period is over. The RCC staff will typically notify users via email prior to performing a maintenance and after a maintenance is completed.","title":"Why is my job not starting?"},{"location":"general_faq/#why-does-my-job-fail-after-a-few-seconds","text":"This is most likely because there is an error in your job submission script, or because the program you are trying to run is producing an error and terminating prematurely. If you need help troubleshooting the issue, please send your job submission script, as well as the error generated by your job submission script, to help@rcc.uchicago.edu.","title":"Why does my job fail after a few seconds?"},{"location":"general_faq/#why-does-my-job-fail-with-message-exceeded-memory-limit-being-killed","text":"On the main midway2 partition, broadwl, Slurm allocates 2 GB of memory per allocated CPU by default. If your computations require more than the default amount, you should adjust the memory allocated to your job with the --mem or --mem-per-cpu flags. For example, to request 10 cores and 40 GB of memory on a broadwl node, include these options when running sbatch or sinteractive: --ntasks=1 --cpus-per-task=10 --mem=40G.","title":"Why does my job fail with message \u201cexceeded memory limit, being killed\u201d?"},{"location":"general_faq/#why-does-my-sinteractive-job-fail-with-connection-to-closed","text":"There are two likely explanations for this error. One possibility is that you are over the time limit. The default walltime for sinteractive is 2 hours. This can be increased by including the --time flag to your sinteractive call. Another possiblity is that your job exceeded the memory limit. You can resolve this by requesting additional memory using --mem or --mem-per-cpu.","title":"Why does my sinteractive job fail with \u201cConnection to closed.\u201d?"},{"location":"general_faq/#how-do-i-run-jobs-that-need-to-run-longer-than-the-maximum-wall-time","text":"The RCC queuing system is designed to provide fair resource allocation to all RCC users. The maximum wall time is intended to prevent individual users from using more than their fair share of cluster resources. If you have specific computing tasks that cannot be solved with the current constraints, please submit a special request for resources to help@rcc.uchicago.edu.","title":"How do I run jobs that need to run longer than the maximum wall time?"},{"location":"general_faq/#can-i-create-a-cron-job","text":"The RCC does not support users creating cron jobs. However, it is possible to use Slurm to submit \u201ccron-like\u201d jobs. See Cron-like jobs for more information.","title":"Can I create a cron job?"},{"location":"general_faq/#performance-and-coding","text":"","title":"Performance and Coding"},{"location":"general_faq/#what-compilers-does-the-rcc-support","text":"The RCC supports the GNU, Intel, PGI and NVidia\u2019s CUDA compilers.","title":"What compilers does the RCC support?"},{"location":"general_faq/#which-versions-of-mpi-does-rcc-support","text":"The RCC maintains OpenMPI, IntelMPI, and MVAPICH2 compilers. See Message Passing Interface (MPI) for more information and instructions for using these MPI frameworks.","title":"Which versions of MPI does RCC support?"},{"location":"general_faq/#can-the-rcc-help-me-parallelize-and-optimize-my-code","text":"The RCC support staff are available to consult with you or your research team to help parallelize and optimize your code for use on RCC systems. Contact the RCC staff at help@rcc.uchicago.edu to set up a consultation.","title":"Can the RCC help me parallelize and optimize my code?"},{"location":"general_faq/#does-rcc-provide-gpu-computing-resources","text":"Yes. The RCC high-performance systems provide GPU-equipped compute nodes. For instructions on using the GPU nodes, see GPU jobs.","title":"Does RCC provide GPU computing resources?"},{"location":"general_faq/#file-io-storage-and-transfers","text":"How much storage space do I have? Use the quota command to get a summary of your current file system usage and available storage space.","title":"File I/O, Storage, and Transfers"},{"location":"general_faq/#how-do-i-get-my-storage-quota-increased","text":"Additional storage space can be purchased through the Cluster Partnership Program. You may also request additional storage as part of a Research II Allocation or Special Allocation.","title":"How do I get my storage quota increased?"},{"location":"general_faq/#how-do-i-share-files-with-others","text":"The recommended way to share files with members of your group is to store them in the /project or /project2 directory for your group. Project directories are created for all PI and project accounts. File and directory permissions can be customized to allow access to users within the group, as well as RCC users that do not belong to your group.","title":"How do I share files with others?"},{"location":"general_faq/#i-accidentally-deleted-or-lost-a-file-how-do-i-restore-it","text":"The best way to recover a recently deleted, corrupted or lost file is from a snapshot. See Data Recovery and Backups for more information.","title":"I accidentally deleted or lost a file. How do I restore it?"},{"location":"general_faq/#how-do-i-request-a-restore-of-my-files-from-tape-backup","text":"The RCC maintains tape backups of all home and project directories. These tape backups are intended for disaster recovery purposes only. There is no long-term history of files on tape. In most cases, you should use file system snapshots to retrieve recover files. See Data Recovery and Backups for more information.","title":"How do I request a restore of my files from tape backup?"},{"location":"general_troubleshooting/","text":"General Troubleshooting and Frequently Asked Questions","title":"General Troubleshooting and Frequently Asked Questions"},{"location":"general_troubleshooting/#general-troubleshooting-and-frequently-asked-questions","text":"","title":"General Troubleshooting and Frequently Asked Questions"},{"location":"glossary/","text":"Term Definition Batch job A job is the Slurm\u2019s computing unit by which resources are allocated and shared. Users create job submission scripts to ask Slurm for resources such as cores, memory, walltime, etc. Slurm puts the requests in a queue and allocates requested resources based on jobs\u2019 priority. Compute cluster A group of independent computers connected via a fast network interconnect, managed by a resource manage, and act as a large parallel computer. Each node in a cluster can be a shared memory parallel computer. Compute node A compute node is a stand-alone computer connected to other compute nodes via a fast network interconnect. A compute node is where a batch job runs and is not usually accessible directly by the users. Core Smallest computation unit that can run a program (used to be called a processor, still is, also called a CPU \u2013 Central Processing Unit) Distributed memory architecture Distributed memory architecture refers to a way to create a parallel computer. In this architecture, stand-alone compute nodes are connected using a fast interconnect such as Infiniband and exchange messages over the network. FLOPS FLoating point Operation Per Second (FLOPS) is a measure of computing performance in terms of number of floating operations that a CPU can perfomr per second. Modern CPUs are capable of doing Tera FLOPS (10^12 floating point operations per second) GPU Graphics Processing Unit (GPU) is a specialized device initially used to generate computer output. GPUs have their own memory but should be hosted in a node. Each compute node can host one or more GPUs. Modern GPUs have many simple compute cores and have been used for parallel processing. HPC High Performance Computing (HPC) refers to the practice of aggregating computing power to achieve higher performance that would not possible by using a typical computer. Infiniband A computer network standard featuring high bandwidth and low latency. The current Infiniband devices are capable of transferring data at up to 100Gbits/sec with less than a microsecond latency. As of this writing, the popular Infiniband versions are FDR (Fourteen Data Rate) with 56Gbits/sec and EDR (Enhanced Data Rate) with 100Gbits/sec. Login node Login nodes (a.k.a. head nodes) are point of access to a parallel computer. Users usually connect to login nodes via SSH to compile and debug their code, review their results, do some simple tests, and submit their batch jobs to the parallel computer. Modules An open source software management tool used in most HPC facilities. Using modules enable users to selectively pick the software that they want and add them to their environment. Node A stand-alone computer system that contains one or more sockets, memory, storage, etc. connected to other nodes via a fast network interconnect OpenMP Open Multi Processing (OpenMP) is a parallel programming model designed for shared memory architecture. In this programming mode, programmers insert compiler directives in their code and the compiler generates a code that can run on more than one core. Partition A subset of a compute cluster with a common feature. For example, compute nodes with GPU could form a partition. Shared memory architecture Shared memory architecture is a way to create a parallel computer. In this architecture, a large memory is shared among many cores and communication between cores is done via the shared memory.By introducing the multi-core CPUs, each computer is a shared-memory parallel computer. Slurm Simple Linux Utility for Resource Management (SLURM) is a software that manages high performance computing resources. SLURM coordinates running of many programs on a shared facility and makes sure that resources are used in a fair share manner. Socket A computational unit, packaged as one and usually made of a single chip often called processor. Modern sockets carry many cores (2, 4 on most laptops, 8 to 16 on most servers) SSH Secure Shell is a protocol to securely access remote computers. Based on the client-server model, multiple users with an SSH client can access to a remote computer. Some operating systems such as Linux and Mac OS have a built-in SSH client and others can use one of many publicly available clients. Tightly-coupled nodes A set of compute nodes connected via fast Infiniband interconnect. These nodes can exchange data in a fast rate and are used to solve big problems that cannot fit in a single computer. Walltime The time that requires a program to finish it execution.","title":"Glossary"},{"location":"midway23/midway3_data_storage/","text":"Data Storage RCC provides a high-performance GPFS shared file system which is used for users\u2019 home directories, shared project spaces, and high-throughput scratch space. All compute nodes are diskless. In addition to high-performance GPFS file system, RCC also offers Cost-effective Data Storage (CDS) through Cluster Partnership Program for long-term data storage. CDS is only available from login nodes and is meant to be used as a storage for less frequently used data. Before performing any computation on the data stored on CDS, it first needs to be copied to the GPFS file system. Midway2 Midway3 Quotas The amount of data that can be stored in home directories, project directories, and shared scratch directories is controlled by quota. RCC enforces hard and soft limits on quotas. A soft quota can be exceeded for a short period of time called a grace period. The hard quota cannot be exceeded under any circumstances. Additional storage is available through the Cluster Partnership Program , a Research I Allocation , Research II Allocation or, in certain circumstances, a Special Allocation . Checking available space To check your current quotas use rcchelp quota . Typical output may look like this --------------------------------------------------------------------------- fileset type used quota limit grace ---------------- ---------------- ---------- ---------- ---------- -------- home blocks (user) 8.77G 30.00G 35.00G none files (user) 157865 300000 1000000 none scratch blocks (user) 16.07G 100.00G 5.00T none files (user) 193028 10000000 20000000 none ---------------- ---------------- ---------- ---------- ---------- -------- >>> Capacity Filesystem: project2 (GPFS) ---------------- ---------------- ---------- ---------- ---------- -------- rcc blocks (group) 259.10T 500.00T 501.00T none files (group) 45825436 384500000 385500000 none ---------------- ---------------- ---------- ---------- ---------- -------- --------------------------------------------------------------------------- The following table describes the fields: Field Meaning fileset File set or file system where this quota is valid. type Type of quota. Blocks are the amount of consumed disk space. Files are the number of files in a directory. Blocks or files quotas can be set at the user or group level. used The amount of disk space consumed or the number of files in the specified location. quota The soft quota (disk space or file count) associated with the specified location. It is possible for usage to exceed the soft quota for the grace period or up to the hard limit. limit The hard quota (disk space or file count) associated with the specified location. When your usage exceeds this limit, you will NOT be able to write to that filesystem. grace The amount of time remaining that the soft quota can be exceeded. None means that the quota is not exceeded. After a soft quota has been exceeded for longer than the grace period, it will no longer be possible to create new files. Persistent Space Persistent space is appropriate for long term storage. The two locations for persistent space are the home and project directories. The home and project directories have both file system Snapshots and tape backup for data protection. Home Directories Every RCC user has a home directory located at /home/<CNetID> . The HOME environment variable points to this location. The home directory is accessible from all RCC compute systems and is generally used for storing frequently used items such as source code, binaries, and scripts. By default, a home directory is only accessible by its owner (mode 0700 ) and is suitable for storing files which do not need to be shared with others. Project Directories All RCC PI Groups are allocated a Project Directory located at /project/<PI CNetID> or /project2/<PI CNetID> where is the CNetID of your RCC PI account holder. These directories are accessible by all members of the PI Group and are generally used for storing files which need to be shared by members of the group. Additional storage in project directories is available through the Cluster Partnership Program , a Research I Allocation or Research II Allocation or, in certain circumstances, a Special Allocation . The default permissions for files and directories created in a project directory allow group read/write with the group sticky bit set (mode 2770 ). The group ownership is set to the PI group. Scratch Space Shared Scratch Space High performance shared scratch space can be accessed using the SCRATCH environment variable. This scratch space is intended to be used for reading or writing data required by jobs running on the cluster. If a user is over quota, s/he can use scratch space as a temporary location to hold files (and/or compress them for archival purposes) but as scratch space is neither snapshotted nor backed up, it should always be viewed as temporary. NOTE : It is the responsibility of the user to ensure any important data in scratch space is moved to persistent storage. Scratch space is meant to be used for temporary, short-term storage only. The default permissions for scratch space allow access only by its owner (mode 0700 ). The standard quota for the high performance scratch directory is 5 TB with a 100GB soft limit. The grace period that the soft limit may be exceeded is 30 days for shared scratch space. Data Recovery and Backups Snapshots Automated snapshots of home and project directories are available in case of accidental file deletion or other problems. Currently snapshots are available for these time periods: Directory Snapshot kept Snapshot Path $HOME 7 daily and 2 weekly /snapshots/home/SNAPSHOT/home/CNetID /project/<any_folder> 7 daily and 2 weekly /snapshots/project/SNAPSHOT/project/<any_folder> /project2/<any_folder> 7 daily and 4 weekly /snapshots/project2/SNAPSHOT/project2/<any_folder> The snapshots for the home and project directories are available from the login nodes. The {SNAPSHOT} refers to the time of the backup, e.g. daily-YYYY-MM-DD.05h30 or weekly-YYYY-MM-DD.05h30. To view the available snapshots of the home directory, for example, use the command ls /snapshots/home To restore a file from a snapshot, simply copy the file to where you want it with either cp or rsync .","title":"Data Storage"},{"location":"midway23/midway3_data_storage/#data-storage","text":"RCC provides a high-performance GPFS shared file system which is used for users\u2019 home directories, shared project spaces, and high-throughput scratch space. All compute nodes are diskless. In addition to high-performance GPFS file system, RCC also offers Cost-effective Data Storage (CDS) through Cluster Partnership Program for long-term data storage. CDS is only available from login nodes and is meant to be used as a storage for less frequently used data. Before performing any computation on the data stored on CDS, it first needs to be copied to the GPFS file system. Midway2 Midway3","title":"Data Storage"},{"location":"midway23/midway3_data_storage/#quotas","text":"The amount of data that can be stored in home directories, project directories, and shared scratch directories is controlled by quota. RCC enforces hard and soft limits on quotas. A soft quota can be exceeded for a short period of time called a grace period. The hard quota cannot be exceeded under any circumstances. Additional storage is available through the Cluster Partnership Program , a Research I Allocation , Research II Allocation or, in certain circumstances, a Special Allocation .","title":"Quotas"},{"location":"midway23/midway3_data_storage/#checking-available-space","text":"To check your current quotas use rcchelp quota . Typical output may look like this --------------------------------------------------------------------------- fileset type used quota limit grace ---------------- ---------------- ---------- ---------- ---------- -------- home blocks (user) 8.77G 30.00G 35.00G none files (user) 157865 300000 1000000 none scratch blocks (user) 16.07G 100.00G 5.00T none files (user) 193028 10000000 20000000 none ---------------- ---------------- ---------- ---------- ---------- -------- >>> Capacity Filesystem: project2 (GPFS) ---------------- ---------------- ---------- ---------- ---------- -------- rcc blocks (group) 259.10T 500.00T 501.00T none files (group) 45825436 384500000 385500000 none ---------------- ---------------- ---------- ---------- ---------- -------- --------------------------------------------------------------------------- The following table describes the fields: Field Meaning fileset File set or file system where this quota is valid. type Type of quota. Blocks are the amount of consumed disk space. Files are the number of files in a directory. Blocks or files quotas can be set at the user or group level. used The amount of disk space consumed or the number of files in the specified location. quota The soft quota (disk space or file count) associated with the specified location. It is possible for usage to exceed the soft quota for the grace period or up to the hard limit. limit The hard quota (disk space or file count) associated with the specified location. When your usage exceeds this limit, you will NOT be able to write to that filesystem. grace The amount of time remaining that the soft quota can be exceeded. None means that the quota is not exceeded. After a soft quota has been exceeded for longer than the grace period, it will no longer be possible to create new files.","title":"Checking available space"},{"location":"midway23/midway3_data_storage/#persistent-space","text":"Persistent space is appropriate for long term storage. The two locations for persistent space are the home and project directories. The home and project directories have both file system Snapshots and tape backup for data protection.","title":"Persistent Space"},{"location":"midway23/midway3_data_storage/#home-directories","text":"Every RCC user has a home directory located at /home/<CNetID> . The HOME environment variable points to this location. The home directory is accessible from all RCC compute systems and is generally used for storing frequently used items such as source code, binaries, and scripts. By default, a home directory is only accessible by its owner (mode 0700 ) and is suitable for storing files which do not need to be shared with others.","title":"Home Directories"},{"location":"midway23/midway3_data_storage/#project-directories","text":"All RCC PI Groups are allocated a Project Directory located at /project/<PI CNetID> or /project2/<PI CNetID> where is the CNetID of your RCC PI account holder. These directories are accessible by all members of the PI Group and are generally used for storing files which need to be shared by members of the group. Additional storage in project directories is available through the Cluster Partnership Program , a Research I Allocation or Research II Allocation or, in certain circumstances, a Special Allocation . The default permissions for files and directories created in a project directory allow group read/write with the group sticky bit set (mode 2770 ). The group ownership is set to the PI group.","title":"Project Directories"},{"location":"midway23/midway3_data_storage/#scratch-space","text":"","title":"Scratch Space"},{"location":"midway23/midway3_data_storage/#shared-scratch-space","text":"High performance shared scratch space can be accessed using the SCRATCH environment variable. This scratch space is intended to be used for reading or writing data required by jobs running on the cluster. If a user is over quota, s/he can use scratch space as a temporary location to hold files (and/or compress them for archival purposes) but as scratch space is neither snapshotted nor backed up, it should always be viewed as temporary. NOTE : It is the responsibility of the user to ensure any important data in scratch space is moved to persistent storage. Scratch space is meant to be used for temporary, short-term storage only. The default permissions for scratch space allow access only by its owner (mode 0700 ). The standard quota for the high performance scratch directory is 5 TB with a 100GB soft limit. The grace period that the soft limit may be exceeded is 30 days for shared scratch space.","title":"Shared Scratch Space"},{"location":"midway23/midway3_data_storage/#data-recovery-and-backups","text":"","title":"Data Recovery and Backups"},{"location":"midway23/midway3_data_storage/#snapshots","text":"Automated snapshots of home and project directories are available in case of accidental file deletion or other problems. Currently snapshots are available for these time periods: Directory Snapshot kept Snapshot Path $HOME 7 daily and 2 weekly /snapshots/home/SNAPSHOT/home/CNetID /project/<any_folder> 7 daily and 2 weekly /snapshots/project/SNAPSHOT/project/<any_folder> /project2/<any_folder> 7 daily and 4 weekly /snapshots/project2/SNAPSHOT/project2/<any_folder> The snapshots for the home and project directories are available from the login nodes. The {SNAPSHOT} refers to the time of the backup, e.g. daily-YYYY-MM-DD.05h30 or weekly-YYYY-MM-DD.05h30. To view the available snapshots of the home directory, for example, use the command ls /snapshots/home To restore a file from a snapshot, simply copy the file to where you want it with either cp or rsync .","title":"Snapshots"},{"location":"midway23/midway3_data_transfer/","text":"Transferring Data to Midway This page provides information on how to transfer data to Midway from your local computer (and vice versa). The following table summarizes available data transfer methods and what tasks they are suited for: Transfer Method Suitable For Not Suitable For Secure Copy (SCP) Transferring files of no more than a few GB. Terminal users. Transferring large datasets SAMBA Transferring files of no more than a few GB. Desktop GUI users. Transferring large datasets HTTP Sharing data publically via web with collaborators. Sharing data with large number of users. Transferring data to Midway via HTTP is not possible. Globus Transferring large files, datasets, and multiple directories. Quick data transfer of few files Secure Copy (SCP) Mac and Linux systems provide a scp command which can be accessed from the command line. To transfer files from your local computer to your home directory (see Data Storage for information on directories), open a terminal window and issue the command: For single files: Midway2 Midway3 scp <some file> <CNetID>@midway2.rcc.uchicago.edu: scp <some file> <CNetID>@midway3.rcc.uchicago.edu: For directories: Midway2 Midway3 scp -r <some dir> <CNetID>@midway2.rcc.uchicago.edu: scp -r <some dir> <CNetID>@midway3.rcc.uchicago.edu: To transfer to a directory other than your home directory (for example, project): Midway2 Midway3 scp -r <some dir> <CNetID>@midway2.rcc.uchicago.edu:/project2 scp -r <some dir> <CNetID>@midway3.rcc.uchicago.edu:/project When prompted, enter your CNet password. SAMBA SAMBA allows one to connect to (or \u201cmount\u201d) their home and project directories on their local computer. This method of accessing your RCC home and project space is only available from within the UChicago campus network. From off-campus you will need to first connect through the UChicago VPN. Connecting from Windows On a Windows computer, select \u201cMap Network Drive\u201d and enter one of the following UNC paths depending on which location on Midway you wish to connect to: Midway2 Midway3 Home Project2 Scratch \\\\midwaysmb.rcc.uchicago.edu\\homes \\\\midwaysmb.rcc.uchicago.edu\\project2 \\\\midwaysmb.rcc.uchicago.edu\\midway2-scratch Home Project Scratch \\\\midway3smb.rcc.uchicago.edu\\homes \\\\midway3smb.rcc.uchicago.edu\\project \\\\midway3smb.rcc.uchicago.edu\\midway3-scratch Enter ADLOCAL\\CNetID for the username and enter your CNet password. Connecting from Mac OS X On a Mac OS X computer, select \u201cConnect to Server\u201d (from \"Go\" dropdown in Finder) and enter one of the following URLs depending on which location on Midway you wish to connect to: Midway2 Midway3 Home Project2 Scratch smb://midwaysmb.rcc.uchicago.edu/homes smb://midwaysmb.rcc.uchicago.edu/project2 smb://midwaysmb.rcc.uchicago.edu/midway2-scratch Home Project Scratch smb://midway3smb.rcc.uchicago.edu/homes smb://midway3smb.rcc.uchicago.edu/project smb://midway3smb.rcc.uchicago.edu/midway3-scratch Enter ADLOCAL\\CNetID for the username and enter your CNet password. HTTP RCC provides web access to data on their storage system via public_html directories in users\u2019 home directories. Local path Corresponding URL /home/[your_CNetID]/public_html/research.dat http://users.rcc.uchicago.edu/~[your_CNetID]/research.dat Ensure your home directories and public_html have the execute permissions. Optionally, ensure public_html has read permissions if you would like to allow indexing. You may set these permissions using the following commands: chmod o+x $HOME mkdir -p $HOME/public_html chmod o+x $HOME/public_html // optional; if you would like to allow directory listing. chmod o+r $HOME/public_html Files in public_html must also be readable by the web user, \"other\", but should not be made executable. You may set read permissions for web users/\"other\" using the following command: chmod o+r $HOME/public_html/research.dat NOTE : Use of these directories must conform with the RCC usage policy . Please notify RCC if you expect a large number of people to access data hosted here. Globus Online Globus Online is a robust tool for transferring large data files to/from Midway. RCC has a customized Globus Online login site. Go to https://globus.rcc.uchicago.edu and Select \u201cUniversity of Chicago\u201d for the existing orginizational login: Enter your CNetID and password when prompted You will need to link your University of Chicago credentials to a Globus Online account. Either create a new Globus Online account or sign in to your existing account if you have one. Once you are signed in, select the \"File Manager\" tab on the sidebar, then enter \"ucrcc#midway\". You can select \"UChicago RCC Midway\" to access your Midway 2 files or \"UChicago RCC Midway3\" to access your Midway 3 files. You will then be able to perform actions such as transfer files, share collections, or create new directories. To learn more about how to use these tools, please refer to the \"Help\" tab on the left toolbar. There is extensive documentation on the Globus Online site as to how to transfer files in different modes. Please refer to their documentation for more details or contact us with any RCC specific issues.","title":"Data Transfer"},{"location":"midway23/midway3_data_transfer/#transferring-data-to-midway","text":"This page provides information on how to transfer data to Midway from your local computer (and vice versa). The following table summarizes available data transfer methods and what tasks they are suited for: Transfer Method Suitable For Not Suitable For Secure Copy (SCP) Transferring files of no more than a few GB. Terminal users. Transferring large datasets SAMBA Transferring files of no more than a few GB. Desktop GUI users. Transferring large datasets HTTP Sharing data publically via web with collaborators. Sharing data with large number of users. Transferring data to Midway via HTTP is not possible. Globus Transferring large files, datasets, and multiple directories. Quick data transfer of few files","title":"Transferring Data to Midway"},{"location":"midway23/midway3_data_transfer/#secure-copy-scp","text":"Mac and Linux systems provide a scp command which can be accessed from the command line. To transfer files from your local computer to your home directory (see Data Storage for information on directories), open a terminal window and issue the command: For single files: Midway2 Midway3 scp <some file> <CNetID>@midway2.rcc.uchicago.edu: scp <some file> <CNetID>@midway3.rcc.uchicago.edu: For directories: Midway2 Midway3 scp -r <some dir> <CNetID>@midway2.rcc.uchicago.edu: scp -r <some dir> <CNetID>@midway3.rcc.uchicago.edu: To transfer to a directory other than your home directory (for example, project): Midway2 Midway3 scp -r <some dir> <CNetID>@midway2.rcc.uchicago.edu:/project2 scp -r <some dir> <CNetID>@midway3.rcc.uchicago.edu:/project When prompted, enter your CNet password.","title":"Secure Copy (SCP)"},{"location":"midway23/midway3_data_transfer/#samba","text":"SAMBA allows one to connect to (or \u201cmount\u201d) their home and project directories on their local computer. This method of accessing your RCC home and project space is only available from within the UChicago campus network. From off-campus you will need to first connect through the UChicago VPN. Connecting from Windows On a Windows computer, select \u201cMap Network Drive\u201d and enter one of the following UNC paths depending on which location on Midway you wish to connect to: Midway2 Midway3 Home Project2 Scratch \\\\midwaysmb.rcc.uchicago.edu\\homes \\\\midwaysmb.rcc.uchicago.edu\\project2 \\\\midwaysmb.rcc.uchicago.edu\\midway2-scratch Home Project Scratch \\\\midway3smb.rcc.uchicago.edu\\homes \\\\midway3smb.rcc.uchicago.edu\\project \\\\midway3smb.rcc.uchicago.edu\\midway3-scratch Enter ADLOCAL\\CNetID for the username and enter your CNet password. Connecting from Mac OS X On a Mac OS X computer, select \u201cConnect to Server\u201d (from \"Go\" dropdown in Finder) and enter one of the following URLs depending on which location on Midway you wish to connect to: Midway2 Midway3 Home Project2 Scratch smb://midwaysmb.rcc.uchicago.edu/homes smb://midwaysmb.rcc.uchicago.edu/project2 smb://midwaysmb.rcc.uchicago.edu/midway2-scratch Home Project Scratch smb://midway3smb.rcc.uchicago.edu/homes smb://midway3smb.rcc.uchicago.edu/project smb://midway3smb.rcc.uchicago.edu/midway3-scratch Enter ADLOCAL\\CNetID for the username and enter your CNet password.","title":"SAMBA"},{"location":"midway23/midway3_data_transfer/#http","text":"RCC provides web access to data on their storage system via public_html directories in users\u2019 home directories. Local path Corresponding URL /home/[your_CNetID]/public_html/research.dat http://users.rcc.uchicago.edu/~[your_CNetID]/research.dat Ensure your home directories and public_html have the execute permissions. Optionally, ensure public_html has read permissions if you would like to allow indexing. You may set these permissions using the following commands: chmod o+x $HOME mkdir -p $HOME/public_html chmod o+x $HOME/public_html // optional; if you would like to allow directory listing. chmod o+r $HOME/public_html Files in public_html must also be readable by the web user, \"other\", but should not be made executable. You may set read permissions for web users/\"other\" using the following command: chmod o+r $HOME/public_html/research.dat NOTE : Use of these directories must conform with the RCC usage policy . Please notify RCC if you expect a large number of people to access data hosted here.","title":"HTTP"},{"location":"midway23/midway3_data_transfer/#globus-online","text":"Globus Online is a robust tool for transferring large data files to/from Midway. RCC has a customized Globus Online login site. Go to https://globus.rcc.uchicago.edu and Select \u201cUniversity of Chicago\u201d for the existing orginizational login: Enter your CNetID and password when prompted You will need to link your University of Chicago credentials to a Globus Online account. Either create a new Globus Online account or sign in to your existing account if you have one. Once you are signed in, select the \"File Manager\" tab on the sidebar, then enter \"ucrcc#midway\". You can select \"UChicago RCC Midway\" to access your Midway 2 files or \"UChicago RCC Midway3\" to access your Midway 3 files. You will then be able to perform actions such as transfer files, share collections, or create new directories. To learn more about how to use these tools, please refer to the \"Help\" tab on the left toolbar. There is extensive documentation on the Globus Online site as to how to transfer files in different modes. Please refer to their documentation for more details or contact us with any RCC specific issues.","title":"Globus Online"},{"location":"midway23/midway3_file_permissions/","text":"File System Permissions Let\u2019s summarize the default file system permissions: Directory Permissions $HOME 0700 \u2013 Accessible only to the owner $SCRATCH 0700 \u2013 Accessible only to the owner /project/<PI CNetID> 2770 \u2013 Read/write for the project group /project2/<PI CNetID> 2770 \u2013 Read/write for the project group The default umask is 002 . When new files or directories are created, the umask influences the default permissions of those files and directories. With the umask set to 002 all files and directories will be group readable and writable by default. In your home directory, the group ownership will be set to your personal group, which is the same as your CNetID, so you will still be the only user that can access your files and directories. In the project directories, the group sticky bit causes the group ownership to be the same as the directory. This means files created in a project directory will be readable and writable by the project group, which is typically what is wanted in those directories. Here is an example of what this means in practice: $ ls -ld $HOME /project/rcc drwx------ 108 wettstein wettstein 32768 2013-01-15 10:51 /home/wettstein drwxrws--- 24 root rcc-staff 32768 2013-01-15 10:48 /project/rcc $ touch $HOME/newfile /project/rcc/newfile $ ls -l /project/rcc/newfile $HOME/newfile -rw-rw-r-- 1 wettstein wettstein 0 2013-01-15 10:48 /home/wettstein/newfile -rw-rw-r-- 1 wettstein rcc-staff 0 2013-01-15 10:48 /project/rcc/newfile Both files are readable and writable by the group owner due to the default umask, but the group owner differs due to the sticky bit being set on /project/rcc . NOTE : This applies only to newly created files and directories. If files or directories are moved from elsewhere, the ownership and permission may not work like this. Contact RCC help if you need assistance with setting filesystem permissions. Advanced Access Control via ACL General Instructions This section discusses a more flexible mechanism to administer data permissions. By default, only Linux-based permissions are set for folders and files, as described in File System Permissions. However, this only supports the permissions at the owner/group/others level. A second mechanism is called \u201cAccess Control Lists\u201d (ACL), which provides precise control over any data (files or directories) customizable for individual users or groups. Before applying ACL to your data, please read and understand the following caveats. By default no ACL is set for user data. ACL provides a highly flexible permission control, however, it also brings increased complexity to user access and management. PIs will normally want to share an entire project folder to all group members, and for this, the Linux-based permissions are enough. We suggest that users implement ACL controls only when necessary. One example is to protect confidential data in the project space by allowing only certain users to access confidential directories or files. After ACL is set, both Linux-based and ACL permissions will work together as a dual-guard system. The final effective access to data is granted only if permitted by both mechanisms. For example, if a folder is group-accessible to a user by Linux-based permission but restricted by ACL, the user cannot access this folder. Be sure you have enough knowledge setting up access via Linux-based permissions and ACL, i.e. you understand what \u201cusers\u201d, \u201cgroups\u201d and each attribute in \u201crwx\u201d mean and how to use them. Otherwise, please ask help@rcc.uchicago.edu for assistance managing your data access. We are here and happy to help you set up the permissions to keep your data safe and accessible as required. Example Suppose there is a folder tree as below, and you want to allow the folder my_folder to be accessible by the user jim only, and jim is already a member of your group rcctemp1 : /project2/rcctemp1 |- my_folder |- other_stuff Before using ACL, you need to confirm that this folder is permitted by all members in the group rcctemp1 : $ cd /project2 $ chgrp -R rcctemp1 my_folder $ chmod -R 770 rcctemp1 $ cd rcctemp1 At this moment, the folder rcctemp1 becomes readable and writable by all members of group rcctemp1 . Then, you can use the setfacl command to control the individual users access precisely. First, you need to remove the default group access by ACL: $ setfacl -m g::--- my_folder Although the command ls -l will still display group rwx access for the my_folder folder in the Linux-based permissions, users cannot access it anymore due to the permission set by ACL. Then, you can grant the user jim access to the folder: $ setfacl -m u:jim:rwx my_folder At this step, the user jim has both read and write permissions to the folder my_folder . You can set up permissions for each user the way you want. To view the list of configured accesses on the folder my_folder , run: $ getfacl my_folder # file: my_folder # owner: root # group: rcctemp1 user::rwx user:jim:rwx group::--- mask::rwx other::--- To revoke the permissions of the user jim to the folder: $ setfacl -x u:jim my_folder To clean up (remove) all ACL controls to the folder: $ setfacl -b my_folder For more information, please visit the ACL manual at https://wiki.archlinux.org/index.php/Access_Control_Lists","title":"File System Permissions"},{"location":"midway23/midway3_file_permissions/#file-system-permissions","text":"Let\u2019s summarize the default file system permissions: Directory Permissions $HOME 0700 \u2013 Accessible only to the owner $SCRATCH 0700 \u2013 Accessible only to the owner /project/<PI CNetID> 2770 \u2013 Read/write for the project group /project2/<PI CNetID> 2770 \u2013 Read/write for the project group The default umask is 002 . When new files or directories are created, the umask influences the default permissions of those files and directories. With the umask set to 002 all files and directories will be group readable and writable by default. In your home directory, the group ownership will be set to your personal group, which is the same as your CNetID, so you will still be the only user that can access your files and directories. In the project directories, the group sticky bit causes the group ownership to be the same as the directory. This means files created in a project directory will be readable and writable by the project group, which is typically what is wanted in those directories. Here is an example of what this means in practice: $ ls -ld $HOME /project/rcc drwx------ 108 wettstein wettstein 32768 2013-01-15 10:51 /home/wettstein drwxrws--- 24 root rcc-staff 32768 2013-01-15 10:48 /project/rcc $ touch $HOME/newfile /project/rcc/newfile $ ls -l /project/rcc/newfile $HOME/newfile -rw-rw-r-- 1 wettstein wettstein 0 2013-01-15 10:48 /home/wettstein/newfile -rw-rw-r-- 1 wettstein rcc-staff 0 2013-01-15 10:48 /project/rcc/newfile Both files are readable and writable by the group owner due to the default umask, but the group owner differs due to the sticky bit being set on /project/rcc . NOTE : This applies only to newly created files and directories. If files or directories are moved from elsewhere, the ownership and permission may not work like this. Contact RCC help if you need assistance with setting filesystem permissions.","title":"File System Permissions"},{"location":"midway23/midway3_file_permissions/#advanced-access-control-via-acl","text":"","title":"Advanced Access Control via ACL"},{"location":"midway23/midway3_file_permissions/#general-instructions","text":"This section discusses a more flexible mechanism to administer data permissions. By default, only Linux-based permissions are set for folders and files, as described in File System Permissions. However, this only supports the permissions at the owner/group/others level. A second mechanism is called \u201cAccess Control Lists\u201d (ACL), which provides precise control over any data (files or directories) customizable for individual users or groups. Before applying ACL to your data, please read and understand the following caveats. By default no ACL is set for user data. ACL provides a highly flexible permission control, however, it also brings increased complexity to user access and management. PIs will normally want to share an entire project folder to all group members, and for this, the Linux-based permissions are enough. We suggest that users implement ACL controls only when necessary. One example is to protect confidential data in the project space by allowing only certain users to access confidential directories or files. After ACL is set, both Linux-based and ACL permissions will work together as a dual-guard system. The final effective access to data is granted only if permitted by both mechanisms. For example, if a folder is group-accessible to a user by Linux-based permission but restricted by ACL, the user cannot access this folder. Be sure you have enough knowledge setting up access via Linux-based permissions and ACL, i.e. you understand what \u201cusers\u201d, \u201cgroups\u201d and each attribute in \u201crwx\u201d mean and how to use them. Otherwise, please ask help@rcc.uchicago.edu for assistance managing your data access. We are here and happy to help you set up the permissions to keep your data safe and accessible as required.","title":"General Instructions"},{"location":"midway23/midway3_file_permissions/#example","text":"Suppose there is a folder tree as below, and you want to allow the folder my_folder to be accessible by the user jim only, and jim is already a member of your group rcctemp1 : /project2/rcctemp1 |- my_folder |- other_stuff Before using ACL, you need to confirm that this folder is permitted by all members in the group rcctemp1 : $ cd /project2 $ chgrp -R rcctemp1 my_folder $ chmod -R 770 rcctemp1 $ cd rcctemp1 At this moment, the folder rcctemp1 becomes readable and writable by all members of group rcctemp1 . Then, you can use the setfacl command to control the individual users access precisely. First, you need to remove the default group access by ACL: $ setfacl -m g::--- my_folder Although the command ls -l will still display group rwx access for the my_folder folder in the Linux-based permissions, users cannot access it anymore due to the permission set by ACL. Then, you can grant the user jim access to the folder: $ setfacl -m u:jim:rwx my_folder At this step, the user jim has both read and write permissions to the folder my_folder . You can set up permissions for each user the way you want. To view the list of configured accesses on the folder my_folder , run: $ getfacl my_folder # file: my_folder # owner: root # group: rcctemp1 user::rwx user:jim:rwx group::--- mask::rwx other::--- To revoke the permissions of the user jim to the folder: $ setfacl -x u:jim my_folder To clean up (remove) all ACL controls to the folder: $ setfacl -b my_folder For more information, please visit the ACL manual at https://wiki.archlinux.org/index.php/Access_Control_Lists","title":"Example"},{"location":"midway23/midway_connecting/","text":"Connecting to RCC Resources The information here describes how users can access RCC resources. All users of RCC resources are responsible for knowing and abiding by the RCC User Policy. Upon logging in to Midway, you will be connected to either one of two login nodes on the respective system: Midway2: midway2-login1.rcc.uchicago.edu or midway2-login2.rcc.uchicago.edu Midway3: midway3-login1.rcc.uchicago.edu or midway3-login2.rcc.uchicago.edu NOTE : The login nodes are NOT for computionally intensive work. For running computationally intensive programs, see Running jobs on midway (link). Account Credentials To use resources provided by the Research Computing Center you must have a RCC user account. If you do not already have a RCC acount, see the Getting Started page (link) for more information on obtaining a RCC account. Your RCC account uses your UChicago CNetID for the username and the corresponding CNetID password for the password: Username: CNetID Password: CNet password NOTE : If you require password assistance, please see the CNet Password Recovery webpage or contact UChicago IT Services (link). Connecting with SSH Secure Shell (SSH) is a protocol that provides secure command-line access to remote resources such as Midway.* To log in to Midway from a Linux or Mac computer, open a terminal. To log in to Midway from a Windows computer, open powershell .** At the command line enter: Midway2 Midway3 ssh <CNetID>@midway2.rcc.uchicago.edu ssh <CNetID>@midway3.rcc.uchicago.edu Provide your CNetID password when prompted. Duo two-factor autentication will request you select from the available 2FA options to authenticate to Midway. Duo two-factor authentication for user Enter a passcode or select one of the following options: 1) receive a push code on your Duo app, 2) Receive authentication through your phone number, and 3) get an SMS code. Passcode or option (1-3): Choose from the available two-factor authentication options and finish the authentication process. X11 Forwarding To enable X11 forwarding when connecting to a Midway system with ssh, the -Y flag should be included: Midway2 Midway3 ssh -Y <CNetID>@midway2.rcc.uchicago.edu ssh -Y <CNetID>@midway3.rcc.uchicago.edu NOTE : XQuartz is required to enable trusted X11 forwarding on a Mac. Connecting with ThinLinc ThinLinc is a remote desktop server used to connect to Midway and obtain a remote graphical user interface (GUI). We recommend using ThinLinc to use software that requires a GUI. Using ThinLinc through a web browser Point your web browser to the following web address: Midway2 Midway3 https://midway2.rcc.uchicago.edu. You will land on this page: https://midway3.rcc.uchicago.edu. You will land on this page: Proceed to log in with your CNetID and password. Duo two-factor autentication will request you select from the available 2FA options to authenticate to Midway. Duo two-factor authentication for user Enter a passcode or select one of the following options: 1) receive a push code on your Duo app, 2) Receive authentication through your phone number, and 3) get an SMS code. Passcode or option (1-3): Using the ThinLinc Desktop Client Download and install the appropriate ThinLinc client here: https://www.cendio.com/thinlinc/download Open the ThinLinc client and use the following information to set up your connection to Midway: Midway2 Midway3 Server: midway2.rcc.uchicago.edu Username: CNetID Password: CNet password Your client should look similar to this: Server: midway3.rcc.uchicago.edu Username: CNetID Password: CNet password Your client should look similar to this: ThinLinc will default to open in a fullscreen window that fills all monitors . To change this use Options from the initial login interface. After clicking the Connect button, Duo two-factor autentication will request you select from the available 2FA options to authenticate to Midway. Duo two-factor authentication for user Enter a passcode or select one of the following options: 1) receive a push code on your Duo app, 2) Receive authentication through your phone number, and 3) get an SMS code. Passcode or option (1-3): Using ThinLinc's Interface Upon successfully logging in, you will be presented with an IceWM desktop. Select Applications tab in the top left corner to access the terminal, file browser, and other utilities. To copy/paste between Thinlinc webaccess client and your computer, open the side toolbar by clicking the purple handle. Click the Clipboard icon. The text field that just open will be synced with the clipboard on the server, so you can copy and paste to and from this text field. With ThinLinc it is possible to maintain an active session after you have closed your connection to Midway. To disconnect from Midway but maintain an active session, simply close the ThinLinc window. NOTE: You must have End existing session unchecked for this to occur. To exit ThinLinc and terminate your session completely, simply exit or close the ThinLinc application. Remote Visualization on Midway 2 RCC provides a mechanism for accessing a GPU-equipped visualization node, which can be used for running 3D and graphics-intensive visualization software packages. First log into Midway via ThinLinc. Once logged in, open a terminal and in the terminal window, issue the command sviz To exit the Visualization node, simply close the terminal window from which it was launched. You can then log out of Midway by selecting Logout from the Applications menu in ThinLinc, or by simply closing the ThinLinc window. ** Windows users running a version of Windows older than Windows 10\u2019s April 2018 release will have to download an ssh client to connect via ssh. We recommend the MobaXterm, client, although other options are available. * SSH key-based authentication is no longer supported. The SSH password-based authentication is currently the only supported method for authentication.","title":"Connecting to Midway"},{"location":"midway23/midway_connecting/#connecting-to-rcc-resources","text":"The information here describes how users can access RCC resources. All users of RCC resources are responsible for knowing and abiding by the RCC User Policy. Upon logging in to Midway, you will be connected to either one of two login nodes on the respective system: Midway2: midway2-login1.rcc.uchicago.edu or midway2-login2.rcc.uchicago.edu Midway3: midway3-login1.rcc.uchicago.edu or midway3-login2.rcc.uchicago.edu NOTE : The login nodes are NOT for computionally intensive work. For running computationally intensive programs, see Running jobs on midway (link).","title":"Connecting to RCC Resources"},{"location":"midway23/midway_connecting/#account-credentials","text":"To use resources provided by the Research Computing Center you must have a RCC user account. If you do not already have a RCC acount, see the Getting Started page (link) for more information on obtaining a RCC account. Your RCC account uses your UChicago CNetID for the username and the corresponding CNetID password for the password: Username: CNetID Password: CNet password NOTE : If you require password assistance, please see the CNet Password Recovery webpage or contact UChicago IT Services (link).","title":"Account Credentials"},{"location":"midway23/midway_connecting/#connecting-with-ssh","text":"Secure Shell (SSH) is a protocol that provides secure command-line access to remote resources such as Midway.* To log in to Midway from a Linux or Mac computer, open a terminal. To log in to Midway from a Windows computer, open powershell .** At the command line enter: Midway2 Midway3 ssh <CNetID>@midway2.rcc.uchicago.edu ssh <CNetID>@midway3.rcc.uchicago.edu Provide your CNetID password when prompted. Duo two-factor autentication will request you select from the available 2FA options to authenticate to Midway. Duo two-factor authentication for user Enter a passcode or select one of the following options: 1) receive a push code on your Duo app, 2) Receive authentication through your phone number, and 3) get an SMS code. Passcode or option (1-3): Choose from the available two-factor authentication options and finish the authentication process.","title":"Connecting with SSH"},{"location":"midway23/midway_connecting/#x11-forwarding","text":"To enable X11 forwarding when connecting to a Midway system with ssh, the -Y flag should be included: Midway2 Midway3 ssh -Y <CNetID>@midway2.rcc.uchicago.edu ssh -Y <CNetID>@midway3.rcc.uchicago.edu NOTE : XQuartz is required to enable trusted X11 forwarding on a Mac.","title":"X11 Forwarding"},{"location":"midway23/midway_connecting/#connecting-with-thinlinc","text":"ThinLinc is a remote desktop server used to connect to Midway and obtain a remote graphical user interface (GUI). We recommend using ThinLinc to use software that requires a GUI.","title":"Connecting with ThinLinc"},{"location":"midway23/midway_connecting/#using-thinlinc-through-a-web-browser","text":"Point your web browser to the following web address: Midway2 Midway3 https://midway2.rcc.uchicago.edu. You will land on this page: https://midway3.rcc.uchicago.edu. You will land on this page: Proceed to log in with your CNetID and password. Duo two-factor autentication will request you select from the available 2FA options to authenticate to Midway. Duo two-factor authentication for user Enter a passcode or select one of the following options: 1) receive a push code on your Duo app, 2) Receive authentication through your phone number, and 3) get an SMS code. Passcode or option (1-3):","title":"Using ThinLinc through a web browser"},{"location":"midway23/midway_connecting/#using-the-thinlinc-desktop-client","text":"Download and install the appropriate ThinLinc client here: https://www.cendio.com/thinlinc/download Open the ThinLinc client and use the following information to set up your connection to Midway: Midway2 Midway3 Server: midway2.rcc.uchicago.edu Username: CNetID Password: CNet password Your client should look similar to this: Server: midway3.rcc.uchicago.edu Username: CNetID Password: CNet password Your client should look similar to this: ThinLinc will default to open in a fullscreen window that fills all monitors . To change this use Options from the initial login interface. After clicking the Connect button, Duo two-factor autentication will request you select from the available 2FA options to authenticate to Midway. Duo two-factor authentication for user Enter a passcode or select one of the following options: 1) receive a push code on your Duo app, 2) Receive authentication through your phone number, and 3) get an SMS code. Passcode or option (1-3):","title":"Using the ThinLinc Desktop Client"},{"location":"midway23/midway_connecting/#using-thinlincs-interface","text":"Upon successfully logging in, you will be presented with an IceWM desktop. Select Applications tab in the top left corner to access the terminal, file browser, and other utilities. To copy/paste between Thinlinc webaccess client and your computer, open the side toolbar by clicking the purple handle. Click the Clipboard icon. The text field that just open will be synced with the clipboard on the server, so you can copy and paste to and from this text field. With ThinLinc it is possible to maintain an active session after you have closed your connection to Midway. To disconnect from Midway but maintain an active session, simply close the ThinLinc window. NOTE: You must have End existing session unchecked for this to occur. To exit ThinLinc and terminate your session completely, simply exit or close the ThinLinc application.","title":"Using ThinLinc's Interface"},{"location":"midway23/midway_connecting/#remote-visualization-on-midway-2","text":"RCC provides a mechanism for accessing a GPU-equipped visualization node, which can be used for running 3D and graphics-intensive visualization software packages. First log into Midway via ThinLinc. Once logged in, open a terminal and in the terminal window, issue the command sviz To exit the Visualization node, simply close the terminal window from which it was launched. You can then log out of Midway by selecting Logout from the Applications menu in ThinLinc, or by simply closing the ThinLinc window. ** Windows users running a version of Windows older than Windows 10\u2019s April 2018 release will have to download an ssh client to connect via ssh. We recommend the MobaXterm, client, although other options are available. * SSH key-based authentication is no longer supported. The SSH password-based authentication is currently the only supported method for authentication.","title":"Remote Visualization on Midway 2"},{"location":"midway23/midway_getting_started/","text":"Getting Started on Midway What is Midway? Midway2 and Midway3 are professionally-managed high performance computing clusters that constitute the core of the RCC\u2019s advanced computational infrastructure. Technical details about the systems are available here . Gaining Access The RCC offers two types of user accounts: a PI Account and a General User Account. All General Users must be sponsored by a PI with an active RCC account. More information about creating an account can be found here (link). Connecting and Running Jobs After your RCC User account is created, you will connect to Midway . There are several different ways to connect, depending on your operating system and desired user experience. Once you successful connect to Midway and move data onto the system, you will be able to begin submitting and running jobs (running your programs on the cluster). Troubleshooting Please direct questions, requests, and feedback to help@rcc.uchicago.edu For frequently asked questions and troubleshooting, refer to this page .","title":"Getting Started"},{"location":"midway23/midway_getting_started/#getting-started-on-midway","text":"","title":"Getting Started on Midway"},{"location":"midway23/midway_getting_started/#what-is-midway","text":"Midway2 and Midway3 are professionally-managed high performance computing clusters that constitute the core of the RCC\u2019s advanced computational infrastructure. Technical details about the systems are available here .","title":"What is Midway?"},{"location":"midway23/midway_getting_started/#gaining-access","text":"The RCC offers two types of user accounts: a PI Account and a General User Account. All General Users must be sponsored by a PI with an active RCC account. More information about creating an account can be found here (link).","title":"Gaining Access"},{"location":"midway23/midway_getting_started/#connecting-and-running-jobs","text":"After your RCC User account is created, you will connect to Midway . There are several different ways to connect, depending on your operating system and desired user experience. Once you successful connect to Midway and move data onto the system, you will be able to begin submitting and running jobs (running your programs on the cluster).","title":"Connecting and Running Jobs"},{"location":"midway23/midway_getting_started/#troubleshooting","text":"Please direct questions, requests, and feedback to help@rcc.uchicago.edu For frequently asked questions and troubleshooting, refer to this page .","title":"Troubleshooting"},{"location":"midway23/midway_hardware_overview/","text":"Hardware Overview This page provides technical details about the Midway2 and Midway3 compute clusters. Midway2 Midway3 Midway 2 A professionally-managed high performance computing cluster forms the second generation core of RCC\u2019s advanced computational infrastructure. The key features of the Midway 2 hardware are listed as follows: 572 nodes total (16,016 cores) 210 standard compute nodes 4 NVIDIA K80 GPUs Total of 2.2 PB SSD local disk Operating System throughout cluster is Centos 8 Large shared memory nodes\u2014up to 1TB of memory per node with either 16, 28, or 32 Intel CPU cores GPU Nodes There are 4 GPU nodes that are part of the Midway2 communal resources. Each GPU node has the Standard Intel Compute Node specifications and the following GPU configurations: 1 GPU node w/ 4x NVIDIA K80 GPUs Big Memory Nodes There is 1 big memory node available to all users. The big memory node has the Standard Intel Compute Node specifications, but with the following larger memory configurations: 1 nodes w/ 512 GB of memory Midway 3 The latest high performance computing cluster built, deployed and maintained by RCC. At this time, only the Intel specific resources are made available. The key features of the Midway3 Intel hardware are listed as follows: 220 nodes total (10,560 cores) 210 standard compute nodes 2 big memory nodes (1x768GB and 1x1.52TB) 11 GPU nodes All nodes have HDR InfiniBand (100 Gbps) network cards. Each node has 960 GB SSD local disk Operating System throughout cluster is Centos 8 GPU Nodes There are 11 GPU nodes that are part of the Midway3 communal resources. Each GPU node has the Standard Intel Compute Node specifications and the following GPU configurations: 5 GPU nodes w/ 4x NVIDIA V100 GPUs per node 5 GPU nodes w/ 4x NVIDIA Quadro RTX 6000 GPUs per node 1 GPU node w/ 4x NVIDIA A100 GPUs per node Big Memory Nodes There are 2 big memory nodes available to all users. The big memory node has the Standard Intel Compute Node specifications, but with the following larger memory configurations: 1 nodes w/ 768 GB of memory 1 nodes w/ 1.52 TB of memory File Systems There is a total of 2.2 PB of raw parallel file storage (1.7PB usable) that is part of the Midway3 cluster. Both file systems store their file metadata on a storage controller built of solid state drives, which overall will improve the responsiveness of each file system. Furthermore, the new storage system is designed that any file that is smaller than 4 KB in size will be bundled with the file metadata and stored on the pool of dedicated metadata SSDs that are part of the parallel storage system. This can lead to considerable improvement in performance for small file size (< 4 KB) I/O. This feature was not available with the Midway2 storage system as the metadata and data were both stored on slower mechanical hard drives.","title":"Hardware Overview"},{"location":"midway23/midway_hardware_overview/#hardware-overview","text":"This page provides technical details about the Midway2 and Midway3 compute clusters. Midway2 Midway3","title":"Hardware Overview"},{"location":"midway23/midway_hardware_overview/#midway-2","text":"A professionally-managed high performance computing cluster forms the second generation core of RCC\u2019s advanced computational infrastructure. The key features of the Midway 2 hardware are listed as follows: 572 nodes total (16,016 cores) 210 standard compute nodes 4 NVIDIA K80 GPUs Total of 2.2 PB SSD local disk Operating System throughout cluster is Centos 8 Large shared memory nodes\u2014up to 1TB of memory per node with either 16, 28, or 32 Intel CPU cores","title":"Midway 2"},{"location":"midway23/midway_hardware_overview/#gpu-nodes","text":"There are 4 GPU nodes that are part of the Midway2 communal resources. Each GPU node has the Standard Intel Compute Node specifications and the following GPU configurations: 1 GPU node w/ 4x NVIDIA K80 GPUs","title":"GPU Nodes"},{"location":"midway23/midway_hardware_overview/#big-memory-nodes","text":"There is 1 big memory node available to all users. The big memory node has the Standard Intel Compute Node specifications, but with the following larger memory configurations: 1 nodes w/ 512 GB of memory","title":"Big Memory Nodes"},{"location":"midway23/midway_hardware_overview/#midway-3","text":"The latest high performance computing cluster built, deployed and maintained by RCC. At this time, only the Intel specific resources are made available. The key features of the Midway3 Intel hardware are listed as follows: 220 nodes total (10,560 cores) 210 standard compute nodes 2 big memory nodes (1x768GB and 1x1.52TB) 11 GPU nodes All nodes have HDR InfiniBand (100 Gbps) network cards. Each node has 960 GB SSD local disk Operating System throughout cluster is Centos 8","title":"Midway 3"},{"location":"midway23/midway_hardware_overview/#gpu-nodes_1","text":"There are 11 GPU nodes that are part of the Midway3 communal resources. Each GPU node has the Standard Intel Compute Node specifications and the following GPU configurations: 5 GPU nodes w/ 4x NVIDIA V100 GPUs per node 5 GPU nodes w/ 4x NVIDIA Quadro RTX 6000 GPUs per node 1 GPU node w/ 4x NVIDIA A100 GPUs per node","title":"GPU Nodes"},{"location":"midway23/midway_hardware_overview/#big-memory-nodes_1","text":"There are 2 big memory nodes available to all users. The big memory node has the Standard Intel Compute Node specifications, but with the following larger memory configurations: 1 nodes w/ 768 GB of memory 1 nodes w/ 1.52 TB of memory","title":"Big Memory Nodes"},{"location":"midway23/midway_hardware_overview/#file-systems","text":"There is a total of 2.2 PB of raw parallel file storage (1.7PB usable) that is part of the Midway3 cluster. Both file systems store their file metadata on a storage controller built of solid state drives, which overall will improve the responsiveness of each file system. Furthermore, the new storage system is designed that any file that is smaller than 4 KB in size will be bundled with the file metadata and stored on the pool of dedicated metadata SSDs that are part of the parallel storage system. This can lead to considerable improvement in performance for small file size (< 4 KB) I/O. This feature was not available with the Midway2 storage system as the metadata and data were both stored on slower mechanical hard drives.","title":"File Systems"},{"location":"midway23/midway_job_management/","text":"Managing Jobs The Glurm job scheduler provides several command-line tools for checking on the status of your jobs and for managing them. For a complete list of Slurm commands, see the Slurm man pages. Checking Job Status Use the squeue command to check on the status of your jobs. squeue Any job with 0:00 under the TIME column is a job that is still waiting in the queue. To view only the jobs that you have submitted, use the --user flag. squeue --user=$USER To get information about all jobs that are waiting to run on the bigmem2 partition, enter: squeue --state=PENDING --partition=bigmem2 To get information about all your jobs that are running on the bigmem2 partition, type: squeue --state=RUNNING --partition=bigmem2 --user=$USER For more information, consult the command-line help by typing squeue --help , or visit the official online documentation. Monitoring Job Memory You can monitor your job by connecting to the compute node it is running on via SSH and using the htop command. To do this, run the following to see your running jobs and which compute nodes your jobs are running on: squeue --state=RUNNING --user=$USER The last column of the output tells us which nodes are allocated for each job. You can connect to the compute node using the following command, where for example we are connecting to compute node midway2-0172. ssh midway2-0172 Finally run: htop To view processes running on the node, including your job's process which will be listed under your CNetID in the USER column. Canceling your jobs To cancel a job you have submitted, use the scancel command. This requires you to specify the id of the job you wish to cancel. For example, to cancel a job with id 8885128, do the following: scancel 8885128 If you are unsure what is the id of the job you would like to cancel, see the JOBID column from running squeue --user=$USER . To cancel all jobs you have submitted that are either running or waiting in the queue, enter the following: scancel --user=$USER","title":"Managing Jobs"},{"location":"midway23/midway_job_management/#managing-jobs","text":"The Glurm job scheduler provides several command-line tools for checking on the status of your jobs and for managing them. For a complete list of Slurm commands, see the Slurm man pages.","title":"Managing Jobs"},{"location":"midway23/midway_job_management/#checking-job-status","text":"Use the squeue command to check on the status of your jobs. squeue Any job with 0:00 under the TIME column is a job that is still waiting in the queue. To view only the jobs that you have submitted, use the --user flag. squeue --user=$USER To get information about all jobs that are waiting to run on the bigmem2 partition, enter: squeue --state=PENDING --partition=bigmem2 To get information about all your jobs that are running on the bigmem2 partition, type: squeue --state=RUNNING --partition=bigmem2 --user=$USER For more information, consult the command-line help by typing squeue --help , or visit the official online documentation.","title":"Checking Job Status"},{"location":"midway23/midway_job_management/#monitoring-job-memory","text":"You can monitor your job by connecting to the compute node it is running on via SSH and using the htop command. To do this, run the following to see your running jobs and which compute nodes your jobs are running on: squeue --state=RUNNING --user=$USER The last column of the output tells us which nodes are allocated for each job. You can connect to the compute node using the following command, where for example we are connecting to compute node midway2-0172. ssh midway2-0172 Finally run: htop To view processes running on the node, including your job's process which will be listed under your CNetID in the USER column.","title":"Monitoring Job Memory"},{"location":"midway23/midway_job_management/#canceling-your-jobs","text":"To cancel a job you have submitted, use the scancel command. This requires you to specify the id of the job you wish to cancel. For example, to cancel a job with id 8885128, do the following: scancel 8885128 If you are unsure what is the id of the job you would like to cancel, see the JOBID column from running squeue --user=$USER . To cancel all jobs you have submitted that are either running or waiting in the queue, enter the following: scancel --user=$USER","title":"Canceling your jobs"},{"location":"midway23/midway_jobs_overview/","text":"Running jobs on midway The information here describes how users can run computations on Midway 2 or Midway 3. All jobs running on compute nodes consume Service Units (SUs); see RCC Service Units (link) for more information. Midway 2 and Midway 3 are compute clusters shared by the entire University of Chicago community. Sharing computational resources creates unique challenges: Jobs must be scheduled in a way that is fair to all users. Consumption of resources needs to be recorded. Access to resources needs to be controlled. The compute clusters use a scheduler to manage requests for access to compute resources. These requests are called jobs . In particular, we use the Slurm resource manager to schedule jobs as well as interactive access to compute nodes. Here, we give the essential information you need to know to start computing on Midway 2 and Midway 3. For more detailed information on running specialized compute jobs, see Running jobs on midway . The following graphic shows the workflow for submitting jobs on Midway. Login nodes vs. Compute nodes Once you have connected to Midway 2 or 3 (see Connecting to RCC Resources (link)) you may work on one of the login nodes. Login nodes may be used for compiling and debugging code, installing software, editing and managing files, submitting jobs, or any other work that is not long-running or computationally intensive (see Using Midway (link)). Login nodes should not be used for computionally intensive work. All intensive computations should be performed on compute nodes. Access to compute nodes can be obtained by submitting a job through the Slurm scheduler, or by requesting an interactive session. If you are unsure whether your computations will be intensive, please request an interactive session and continue your work once you have connected to the compute node. NOTE : Running computationally intensive jobs on the login nodes prevents other users from efficiently using the cluster. RCC System Administrators may terminate your processes without warning if your processes disrupt other users\u2019 work on the RCC cluster. For more information on how to interact with Midway through the Slurm resource manager, see Using Midway (link)). Job Limits To distribute computational resources fairly the RCC sets limits on the amount of computing resources that may be requested by a single user at any given time. The maximum run-time for an individual job is 36 hours . This applies to all batch and interactive jobs submitted to nodes in the general-access partitions. Groups participating in the cluster parternership program may customize resources limits for their partitions. Additional information on limits can be found by entering the command rcchelp qos on any login or compute node on Midway 2 or Midway 3. Observe that these limits are often different depending on the partition. Usage limits may change, so rcchelp qos will always give you the most up-to-date information. If your research requires a temporary exception to a particular limit, you may apply for a special allocation. Special allocations are evaluated on an individual basis and may or may not be granted.","title":"Overview"},{"location":"midway23/midway_jobs_overview/#running-jobs-on-midway","text":"The information here describes how users can run computations on Midway 2 or Midway 3. All jobs running on compute nodes consume Service Units (SUs); see RCC Service Units (link) for more information. Midway 2 and Midway 3 are compute clusters shared by the entire University of Chicago community. Sharing computational resources creates unique challenges: Jobs must be scheduled in a way that is fair to all users. Consumption of resources needs to be recorded. Access to resources needs to be controlled. The compute clusters use a scheduler to manage requests for access to compute resources. These requests are called jobs . In particular, we use the Slurm resource manager to schedule jobs as well as interactive access to compute nodes. Here, we give the essential information you need to know to start computing on Midway 2 and Midway 3. For more detailed information on running specialized compute jobs, see Running jobs on midway . The following graphic shows the workflow for submitting jobs on Midway.","title":"Running jobs on midway"},{"location":"midway23/midway_jobs_overview/#login-nodes-vs-compute-nodes","text":"Once you have connected to Midway 2 or 3 (see Connecting to RCC Resources (link)) you may work on one of the login nodes. Login nodes may be used for compiling and debugging code, installing software, editing and managing files, submitting jobs, or any other work that is not long-running or computationally intensive (see Using Midway (link)). Login nodes should not be used for computionally intensive work. All intensive computations should be performed on compute nodes. Access to compute nodes can be obtained by submitting a job through the Slurm scheduler, or by requesting an interactive session. If you are unsure whether your computations will be intensive, please request an interactive session and continue your work once you have connected to the compute node. NOTE : Running computationally intensive jobs on the login nodes prevents other users from efficiently using the cluster. RCC System Administrators may terminate your processes without warning if your processes disrupt other users\u2019 work on the RCC cluster. For more information on how to interact with Midway through the Slurm resource manager, see Using Midway (link)).","title":"Login nodes vs. Compute nodes"},{"location":"midway23/midway_jobs_overview/#job-limits","text":"To distribute computational resources fairly the RCC sets limits on the amount of computing resources that may be requested by a single user at any given time. The maximum run-time for an individual job is 36 hours . This applies to all batch and interactive jobs submitted to nodes in the general-access partitions. Groups participating in the cluster parternership program may customize resources limits for their partitions. Additional information on limits can be found by entering the command rcchelp qos on any login or compute node on Midway 2 or Midway 3. Observe that these limits are often different depending on the partition. Usage limits may change, so rcchelp qos will always give you the most up-to-date information. If your research requires a temporary exception to a particular limit, you may apply for a special allocation. Special allocations are evaluated on an individual basis and may or may not be granted.","title":"Job Limits"},{"location":"midway23/midway_submitting_jobs/","text":"Submitting Jobs The information here describes how users can submit jobs to compute nodes on Midway 2 or Midway 3 using either batch jobs or interactive jobs. The following graphic shows the workflow for submitting jobs on Midway. Batch Jobs The sbatch command is used to request computing resources on the Midway clusters. Rather than specify all the options in the command line, users typically write an \u201csbatch script\u201d that contains all the commands and parameters neccessary to run a program on the cluster. SBATCH Scripts In an sbatch script, all Slurm parameters are declared with #SBATCH , followed by additional definitions. Here is an example of a Midway 2 sbatch script: #!/bin/bash #SBATCH --job-name=example_sbatch #SBATCH --output=example_sbatch.out #SBATCH --error=example_sbatch.err #SBATCH --time=00:05:00 #SBATCH --partition=broadwl #SBATCH --nodes=4 #SBATCH --ntasks-per-node=14 #SBATCH --mem-per-cpu=2000 module load openmpi mpirun ./hello-mpi And here is an explanation of what each of these parameters does: Option Description --job-name=example_sbatch Assigns name example_sbatch to the job. --output=example_sbatch.out Writes console output to file example_sbatch.out . --error=example_sbatch.err Writes error messages to file example_sbatch.err . --time=00:05:00 Reserves the computing resources for 5 minutes (or less if program completes before 5 min). --partition=broadwl Requests compute nodes from the broadwell partition on the Midway2 cluster. --nodes=4 Requests 4 compute nodes --ntasks-per-node=14 Requests 14 cores (CPUs) per node, for a total of 14 * 4 = 56 cores. --mem-per-cpu=2000 Requests 2000 MB (2 GB) of memory (RAM) per core, for a total of 2 * 14 = 28 GB per node. In this example, we have requested 4 compute nodes with 14 CPUs each. Therefore, we have requested a total of 56 CPUs for running our program. The last two lines of the script load the OpenMPI module and launch the MPI-based executable that we have called hello-mpi . Submitting a Batch Job Continuing the example above, suppose that the sbatch script is saved in the current directory into a file called example.sbatch. This script is submitted to the cluster using the following command: sbatch ./example.sbatch or more generally: sbatch ./<your_sbatch_file> Example Submission Scripts Here are some example sbatch job submission scripts that demonstrate the different options and jobs types you make wish to use. A single core job to the standard compute partition: Midway2 Midway3 #!/bin/bash #SBATCH --job-name=single-node-cpu-example #SBATCH --account=pi-[group] #SBATCH --partition=broadwl #SBATCH --ntasks-per-node=1 # number of tasks #SBATCH --cpus-per-task=1 # number of threads per task # LOAD MODULES module load python # DO COMPUTE WORK export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK python hello.py #!/bin/sh #SBATCH --job-name=single-node-cpu-example #SBATCH --account=pi-[group] #SBATCH --partition=caslake #SBATCH --ntasks-per-node=1 # number of tasks #SBATCH --cpus-per-task=1 # number of threads per task # LOAD MODULES module load python # DO COMPUTE WORK export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK python hello.py A single node gpu job to the gpu partition: Midway2 Midway3 #!/bin/bash #SBATCH --job-name=1gpu-example #SBATCH --account=pi-[group] #SBATCH --partition=gpu2 #SBATCH --gres=gpu:1 #SBATCH --ntasks-per-node=1 # num cores to drive each gpu #SBATCH --cpus-per-task=1 # set this to the desired number of threads # LOAD MODULES module load tensorflow module load cudnn # DO COMPUTE WORK export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK python training.py #!/bin/sh #SBATCH --job-name=1gpu-example #SBATCH --account=pi-[group] #SBATCH --partition=gpu #SBATCH --gres=gpu:1 # TO USE V100 specify --constraint=v100 # TO USE RTX600 specify --constraint=rtx6000 #SBATCH --constraint=v100 # constraint job runs on V100 GPU use #SBATCH --ntasks-per-node=1 # num cores to drive each gpu #SBATCH --cpus-per-task=1 # set this to the desired number of threads # LOAD MODULES module load tensorflow module load cudnn # DO COMPUTE WORK export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK python training.py [Add another example here] You can find more example sbatch submission scripts in the RCC SLURM workshop materials Interactive Jobs This section describes how to submit an \u201cinteractive job\u201d on Midway 2 or Midway 3. This interactive session will persist until you disconnect from the compute node, or until you reach the maximum requested time. To request an interactive job, run the following command: sinteractive As soon as the requested resources become available, sinteractive will do the following: 1. Log in to the node. 2. Change into the directory you were working in. 3. Set up X11 forwarding for displaying graphics. 4. Transfer your current shell environment, including any modules you have previously loaded. By default, an interactive session times out after 2 hours. If you would like more than 2 hours, be sure to include a --time=HH:MM:SS flag to specify the necessary amount of time. For example, to request an interactive session for 6 hours, run the following command: sinteractive --time=06:00:00 There are many additional options for the sinteractive command, including options to select the number of nodes, the number of cores per node, the amount of memory, and so on. For example, to request exclusive use of two compute nodes on the Midway broadwl partition for 8 hours, enter the following: sinteractive --exclusive --partition=broadwl --nodes=2 --time=08:00:00 For more details about these and other useful options, read below about the sbatch command, and see Running jobs on midway. Note that all options available in the sbatch command are also available for the sinteractive command. There is a debug QoS setup on the broadwl partition to help users quickly access some resources to debug or test their code before submitting their jobs to the main broadwl partition. The debug QoS will allow you to run one job and get up to 4 cores for 15 minutes. To use the debug QoS, you have to specify --time which should be 15 minutes or less. For example, to get 2 cores for 15 minutes, you could run: sinteractive --qos=debug --time=00:15:00 --ntasks=2 An alternative to the sinteractive command is the srun command: srun --pty bash Unlike sinteractive, this command does not set up X11 forwarding, which means you cannot display graphics using srun. Both the srun and sinteractive commands have the same command options.","title":"Submitting Jobs"},{"location":"midway23/midway_submitting_jobs/#submitting-jobs","text":"The information here describes how users can submit jobs to compute nodes on Midway 2 or Midway 3 using either batch jobs or interactive jobs. The following graphic shows the workflow for submitting jobs on Midway.","title":"Submitting Jobs"},{"location":"midway23/midway_submitting_jobs/#batch-jobs","text":"The sbatch command is used to request computing resources on the Midway clusters. Rather than specify all the options in the command line, users typically write an \u201csbatch script\u201d that contains all the commands and parameters neccessary to run a program on the cluster.","title":"Batch Jobs"},{"location":"midway23/midway_submitting_jobs/#sbatch-scripts","text":"In an sbatch script, all Slurm parameters are declared with #SBATCH , followed by additional definitions. Here is an example of a Midway 2 sbatch script: #!/bin/bash #SBATCH --job-name=example_sbatch #SBATCH --output=example_sbatch.out #SBATCH --error=example_sbatch.err #SBATCH --time=00:05:00 #SBATCH --partition=broadwl #SBATCH --nodes=4 #SBATCH --ntasks-per-node=14 #SBATCH --mem-per-cpu=2000 module load openmpi mpirun ./hello-mpi And here is an explanation of what each of these parameters does: Option Description --job-name=example_sbatch Assigns name example_sbatch to the job. --output=example_sbatch.out Writes console output to file example_sbatch.out . --error=example_sbatch.err Writes error messages to file example_sbatch.err . --time=00:05:00 Reserves the computing resources for 5 minutes (or less if program completes before 5 min). --partition=broadwl Requests compute nodes from the broadwell partition on the Midway2 cluster. --nodes=4 Requests 4 compute nodes --ntasks-per-node=14 Requests 14 cores (CPUs) per node, for a total of 14 * 4 = 56 cores. --mem-per-cpu=2000 Requests 2000 MB (2 GB) of memory (RAM) per core, for a total of 2 * 14 = 28 GB per node. In this example, we have requested 4 compute nodes with 14 CPUs each. Therefore, we have requested a total of 56 CPUs for running our program. The last two lines of the script load the OpenMPI module and launch the MPI-based executable that we have called hello-mpi .","title":"SBATCH Scripts"},{"location":"midway23/midway_submitting_jobs/#submitting-a-batch-job","text":"Continuing the example above, suppose that the sbatch script is saved in the current directory into a file called example.sbatch. This script is submitted to the cluster using the following command: sbatch ./example.sbatch or more generally: sbatch ./<your_sbatch_file>","title":"Submitting a Batch Job"},{"location":"midway23/midway_submitting_jobs/#example-submission-scripts","text":"Here are some example sbatch job submission scripts that demonstrate the different options and jobs types you make wish to use. A single core job to the standard compute partition: Midway2 Midway3 #!/bin/bash #SBATCH --job-name=single-node-cpu-example #SBATCH --account=pi-[group] #SBATCH --partition=broadwl #SBATCH --ntasks-per-node=1 # number of tasks #SBATCH --cpus-per-task=1 # number of threads per task # LOAD MODULES module load python # DO COMPUTE WORK export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK python hello.py #!/bin/sh #SBATCH --job-name=single-node-cpu-example #SBATCH --account=pi-[group] #SBATCH --partition=caslake #SBATCH --ntasks-per-node=1 # number of tasks #SBATCH --cpus-per-task=1 # number of threads per task # LOAD MODULES module load python # DO COMPUTE WORK export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK python hello.py A single node gpu job to the gpu partition: Midway2 Midway3 #!/bin/bash #SBATCH --job-name=1gpu-example #SBATCH --account=pi-[group] #SBATCH --partition=gpu2 #SBATCH --gres=gpu:1 #SBATCH --ntasks-per-node=1 # num cores to drive each gpu #SBATCH --cpus-per-task=1 # set this to the desired number of threads # LOAD MODULES module load tensorflow module load cudnn # DO COMPUTE WORK export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK python training.py #!/bin/sh #SBATCH --job-name=1gpu-example #SBATCH --account=pi-[group] #SBATCH --partition=gpu #SBATCH --gres=gpu:1 # TO USE V100 specify --constraint=v100 # TO USE RTX600 specify --constraint=rtx6000 #SBATCH --constraint=v100 # constraint job runs on V100 GPU use #SBATCH --ntasks-per-node=1 # num cores to drive each gpu #SBATCH --cpus-per-task=1 # set this to the desired number of threads # LOAD MODULES module load tensorflow module load cudnn # DO COMPUTE WORK export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK python training.py [Add another example here] You can find more example sbatch submission scripts in the RCC SLURM workshop materials","title":"Example Submission Scripts"},{"location":"midway23/midway_submitting_jobs/#interactive-jobs","text":"This section describes how to submit an \u201cinteractive job\u201d on Midway 2 or Midway 3. This interactive session will persist until you disconnect from the compute node, or until you reach the maximum requested time. To request an interactive job, run the following command: sinteractive As soon as the requested resources become available, sinteractive will do the following: 1. Log in to the node. 2. Change into the directory you were working in. 3. Set up X11 forwarding for displaying graphics. 4. Transfer your current shell environment, including any modules you have previously loaded. By default, an interactive session times out after 2 hours. If you would like more than 2 hours, be sure to include a --time=HH:MM:SS flag to specify the necessary amount of time. For example, to request an interactive session for 6 hours, run the following command: sinteractive --time=06:00:00 There are many additional options for the sinteractive command, including options to select the number of nodes, the number of cores per node, the amount of memory, and so on. For example, to request exclusive use of two compute nodes on the Midway broadwl partition for 8 hours, enter the following: sinteractive --exclusive --partition=broadwl --nodes=2 --time=08:00:00 For more details about these and other useful options, read below about the sbatch command, and see Running jobs on midway. Note that all options available in the sbatch command are also available for the sinteractive command. There is a debug QoS setup on the broadwl partition to help users quickly access some resources to debug or test their code before submitting their jobs to the main broadwl partition. The debug QoS will allow you to run one job and get up to 4 cores for 15 minutes. To use the debug QoS, you have to specify --time which should be 15 minutes or less. For example, to get 2 cores for 15 minutes, you could run: sinteractive --qos=debug --time=00:15:00 --ntasks=2 An alternative to the sinteractive command is the srun command: srun --pty bash Unlike sinteractive, this command does not set up X11 forwarding, which means you cannot display graphics using srun. Both the srun and sinteractive commands have the same command options.","title":"Interactive Jobs"},{"location":"midway23/midway_troubleshooting/","text":"Frequently Asked Questions This page provides answers to frequently asked questions when using the Midway2 and Midway3. Midway2 Midway3 How can I list the software packages available? At the terminal on the login node you can run module list You can list all the versions of a software package, or a software bundle, with module avail module avail [package-name] For example, module avail cuda or module avail python You can then show the dependencies of a particular module, its location and the environment variables that are set: module show [package-name] You can load the software package into your environment module load [package-name] which essentially updates the environment variables so that you can access to the binaries (with the prepended PATH ) or your application can link with the package libraries (with the modified LD_LIBRARY_PATH ). How can I install new python packges? The recommended practice is to load an existing python module, create your own environment and then install the packge(s) into your own environment. module load python/anaconda-2021.05 then create and activate your own environment conda create --prefix=/path/to/your/env/my-env python=3.8 conda activate my-env or with venv python -m venv /path/to/your/env/my-env source /path/to/your/env/my-env/bin/activate Finally, install your packages via conda install or pip install : conda install -c conda-forge numpy or pip install numpy Whenever possible, specify the variant of the package that you want explicitly that matches the modules you already loaded. pip install tensorflow cudatoolkit=11.2 cudnn=8.1.0 or pip3 install torch==1.12.0+cu113 torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113 Reference: PyTorch documentation How can I use Tensorflow and PyTorch with GPUs? You need to install these packages with the existing CUDA toolkit modules on Midway2 (see module avail cuda ), then load the module via module load cuda/11.3 . Then install Tensorflow and PyTorch into your own environment (see above). You can check if the installed version of Tensorflow in your enviroment can access to the GPUs on a GPU compute node via python3 -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\" Similarly for PyTorch with GPU support python -c \"import torch; print(torch.vresion.cuda)\" Reference: Tensorflow documentation How can I compile third-party packages or my own codes? How can I list the software packages available? At the terminal on the login node you can run module list You can list all the versions of a software package, or a software bundle, with module avail module avail [package-name] For example, module avail cuda or module avail python You can then show the dependencies of a particular module, its location and the environment variables that are set: module show [package-name] You can load the software package into your environment module load [package-name] which essentially updates the environment variables so that you can access to the binaries (with the prepended PATH ) or your application can link with the package libraries (with the modified LD_LIBRARY_PATH ). How can I install new python packges? How can I compile third-party packages or my own codes? How can I use Tensorflow and PyTorch with GPUs?","title":"Troubleshooting and FAQ"},{"location":"midway23/midway_troubleshooting/#frequently-asked-questions","text":"This page provides answers to frequently asked questions when using the Midway2 and Midway3. Midway2 Midway3","title":"Frequently Asked Questions"},{"location":"midway23/midway_troubleshooting/#how-can-i-list-the-software-packages-available","text":"At the terminal on the login node you can run module list You can list all the versions of a software package, or a software bundle, with module avail module avail [package-name] For example, module avail cuda or module avail python You can then show the dependencies of a particular module, its location and the environment variables that are set: module show [package-name] You can load the software package into your environment module load [package-name] which essentially updates the environment variables so that you can access to the binaries (with the prepended PATH ) or your application can link with the package libraries (with the modified LD_LIBRARY_PATH ).","title":"How can I list the software packages available?"},{"location":"midway23/midway_troubleshooting/#how-can-i-install-new-python-packges","text":"The recommended practice is to load an existing python module, create your own environment and then install the packge(s) into your own environment. module load python/anaconda-2021.05 then create and activate your own environment conda create --prefix=/path/to/your/env/my-env python=3.8 conda activate my-env or with venv python -m venv /path/to/your/env/my-env source /path/to/your/env/my-env/bin/activate Finally, install your packages via conda install or pip install : conda install -c conda-forge numpy or pip install numpy Whenever possible, specify the variant of the package that you want explicitly that matches the modules you already loaded. pip install tensorflow cudatoolkit=11.2 cudnn=8.1.0 or pip3 install torch==1.12.0+cu113 torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113 Reference: PyTorch documentation","title":"How can I install new python packges?"},{"location":"midway23/midway_troubleshooting/#how-can-i-use-tensorflow-and-pytorch-with-gpus","text":"You need to install these packages with the existing CUDA toolkit modules on Midway2 (see module avail cuda ), then load the module via module load cuda/11.3 . Then install Tensorflow and PyTorch into your own environment (see above). You can check if the installed version of Tensorflow in your enviroment can access to the GPUs on a GPU compute node via python3 -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\" Similarly for PyTorch with GPU support python -c \"import torch; print(torch.vresion.cuda)\" Reference: Tensorflow documentation","title":"How can I use Tensorflow and PyTorch with GPUs?"},{"location":"midway23/midway_troubleshooting/#how-can-i-compile-third-party-packages-or-my-own-codes","text":"","title":"How can I compile third-party packages or my own codes?"},{"location":"midway23/midway_troubleshooting/#how-can-i-list-the-software-packages-available_1","text":"At the terminal on the login node you can run module list You can list all the versions of a software package, or a software bundle, with module avail module avail [package-name] For example, module avail cuda or module avail python You can then show the dependencies of a particular module, its location and the environment variables that are set: module show [package-name] You can load the software package into your environment module load [package-name] which essentially updates the environment variables so that you can access to the binaries (with the prepended PATH ) or your application can link with the package libraries (with the modified LD_LIBRARY_PATH ).","title":"How can I list the software packages available?"},{"location":"midway23/midway_troubleshooting/#how-can-i-install-new-python-packges_1","text":"","title":"How can I install new python packges?"},{"location":"midway23/midway_troubleshooting/#how-can-i-compile-third-party-packages-or-my-own-codes_1","text":"","title":"How can I compile third-party packages or my own codes?"},{"location":"midway23/midway_troubleshooting/#how-can-i-use-tensorflow-and-pytorch-with-gpus_1","text":"","title":"How can I use Tensorflow and PyTorch with GPUs?"},{"location":"midway23/request_and_manage_allocations/","text":"Checking Your SU Balance and Usage The rcchelp tool can be used to check account balances. After logging into Midway 2 or Midway 3, simply type: rcchelp balance If you are a member of multiple groups, this will display the allocations and usage for all your groups. The rcchelp balance command has a number of options for summarizing allocation usage. For information on these options, type rcchelp balance --help To see an overall summary of your usage, simply enter: rcchelp usage","title":"Request and manage allocations"},{"location":"midway23/request_and_manage_allocations/#checking-your-su-balance-and-usage","text":"The rcchelp tool can be used to check account balances. After logging into Midway 2 or Midway 3, simply type: rcchelp balance If you are a member of multiple groups, this will display the allocations and usage for all your groups. The rcchelp balance command has a number of options for summarizing allocation usage. For information on these options, type rcchelp balance --help To see an overall summary of your usage, simply enter: rcchelp usage","title":"Checking Your SU Balance and Usage"},{"location":"midway23/examples/array/","text":"Job arrays Slurm job arrays provide a convenient way to submit a large number of independent processing jobs. For example, Slurm job arrays can be useful for applying the same or similar computation to a collection of data sets. When a job array script is submitted, a specified number of \u201carray tasks\u201d are created based on the \u201cmaster\u201d sbatch script. Consider the following example (from array.sbatch ): #!/bin/bash #SBATCH --job-name=array #SBATCH --output=array_%A_%a.out #SBATCH --error=array_%A_%a.err #SBATCH --array=1-16 #SBATCH --time=01:00:00 #SBATCH --partition=broadwl #SBATCH --ntasks=1 #SBATCH --mem=4G # Print the task id. echo \"My SLURM_ARRAY_TASK_ID: \" $SLURM_ARRAY_TASK_ID # Add lines here to run your computations. In this simple example, --array=1-16 requests 16 array tasks (numbered 1 through 16). The \u201carray tasks\u201d are copies of the master script that are automatically submitted to the scheduler on your behalf. In each array task, the environment variable SLURM_ARRAY_TASK_ID is set to a unique value (in this example, numbers ranging from 1 to 16). Job array indices can be specified in several different ways. Here are some examples: # A job array with array tasks numbered from 0 to 31. #SBATCH --array=0-31 # A job array with array tasks numbered 1, 2, 5, 19, 27. #SBATCH --array=1,2,5,19,27 # A job array with array tasks numbered 1, 3, 5 and 7. #SBATCH --array=1-7:2 In the example sbatch script above, the %A_%a notation is filled in with the master job id ( %A ) and the array task id ( %a ). This is a simple way to create output files in which the file name is different for each job in the array. The remaining options in the sbatch script are the same as the options used in other, non-array settings; in this example, we are requesting that each array task be allocated 1 CPU ( --ntasks=1 ) and 4 GB of memory ( --mem=4G ) on the broadwl partition ( --partition=broadwl ) for up to one hour ( --time=01:00:00 ). Most partitions have limits on the number of array tasks that can run simultaneously. To achieve a higher throughput, consider Parallel batch jobs . For more information about Slurm job arrays, consule the the `Slurm documentation on job arrays`_","title":"Job arrays"},{"location":"midway23/examples/array/#job-arrays","text":"Slurm job arrays provide a convenient way to submit a large number of independent processing jobs. For example, Slurm job arrays can be useful for applying the same or similar computation to a collection of data sets. When a job array script is submitted, a specified number of \u201carray tasks\u201d are created based on the \u201cmaster\u201d sbatch script. Consider the following example (from array.sbatch ): #!/bin/bash #SBATCH --job-name=array #SBATCH --output=array_%A_%a.out #SBATCH --error=array_%A_%a.err #SBATCH --array=1-16 #SBATCH --time=01:00:00 #SBATCH --partition=broadwl #SBATCH --ntasks=1 #SBATCH --mem=4G # Print the task id. echo \"My SLURM_ARRAY_TASK_ID: \" $SLURM_ARRAY_TASK_ID # Add lines here to run your computations. In this simple example, --array=1-16 requests 16 array tasks (numbered 1 through 16). The \u201carray tasks\u201d are copies of the master script that are automatically submitted to the scheduler on your behalf. In each array task, the environment variable SLURM_ARRAY_TASK_ID is set to a unique value (in this example, numbers ranging from 1 to 16). Job array indices can be specified in several different ways. Here are some examples: # A job array with array tasks numbered from 0 to 31. #SBATCH --array=0-31 # A job array with array tasks numbered 1, 2, 5, 19, 27. #SBATCH --array=1,2,5,19,27 # A job array with array tasks numbered 1, 3, 5 and 7. #SBATCH --array=1-7:2 In the example sbatch script above, the %A_%a notation is filled in with the master job id ( %A ) and the array task id ( %a ). This is a simple way to create output files in which the file name is different for each job in the array. The remaining options in the sbatch script are the same as the options used in other, non-array settings; in this example, we are requesting that each array task be allocated 1 CPU ( --ntasks=1 ) and 4 GB of memory ( --mem=4G ) on the broadwl partition ( --partition=broadwl ) for up to one hour ( --time=01:00:00 ). Most partitions have limits on the number of array tasks that can run simultaneously. To achieve a higher throughput, consider Parallel batch jobs . For more information about Slurm job arrays, consule the the `Slurm documentation on job arrays`_","title":"Job arrays"},{"location":"midway23/examples/bigmem/","text":"Large-memory jobs The bigmem2 partition is particularly well suited for computations that need more than about 60 GB of memory; see Types of Compute Nodes for technical specifications of the bigmem2 nodes. Running a large-memory job To submit a job to bigmem2, include this line in your sbatch script: #SBATCH --partition=bigmem2 Additionally, it is important to use the --mem or --mem-per-cpu options. For example, to request 8 CPU cores and 128 GB of memory on a bigmem2 node, add the following to your sbatch script: #SBATCH --ntasks=1 #SBATCH --cpus-per-task=8 #SBATCH --mem=128G Interactive computing on bigmem2 These same options can also be used to set up an sinteractive session. For example, to access a bigmem2 node with 1 CPU and 128 GB of memory, run: sinteractive --partition = bigmem2 --ntasks = 1 --cpus-per-task = 8 --mem = 128G","title":"Large-memory jobs"},{"location":"midway23/examples/bigmem/#large-memory-jobs","text":"The bigmem2 partition is particularly well suited for computations that need more than about 60 GB of memory; see Types of Compute Nodes for technical specifications of the bigmem2 nodes.","title":"Large-memory jobs"},{"location":"midway23/examples/bigmem/#running-a-large-memory-job","text":"To submit a job to bigmem2, include this line in your sbatch script: #SBATCH --partition=bigmem2 Additionally, it is important to use the --mem or --mem-per-cpu options. For example, to request 8 CPU cores and 128 GB of memory on a bigmem2 node, add the following to your sbatch script: #SBATCH --ntasks=1 #SBATCH --cpus-per-task=8 #SBATCH --mem=128G","title":"Running a large-memory job"},{"location":"midway23/examples/bigmem/#interactive-computing-on-bigmem2","text":"These same options can also be used to set up an sinteractive session. For example, to access a bigmem2 node with 1 CPU and 128 GB of memory, run: sinteractive --partition = bigmem2 --ntasks = 1 --cpus-per-task = 8 --mem = 128G","title":"Interactive computing on bigmem2"},{"location":"midway23/examples/cron/","text":"Cron-like jobs Cron jobs persist until they are canceled or encounter an error. The Midway2 cluster has a dedicated partition, cron , for running Cron jobs. Please email help@rcc.uchicago.edu to request submitting Cron-like jobs. These jobs are subject to scheduling limits and will be monitored. Here is an example of an sbatch script that runs a Cron job (see also cron.sbatch ): #!/bin/bash #SBATCH --time=00:05:00 #SBATCH --output=cron.log #SBATCH --open-mode=append #SBATCH --account=cron-account #SBATCH --partition=cron #SBATCH --qos=cron # Specify a valid Cron string for the schedule. This specifies that # the Cron job run once per day at 5:15a. SCHEDULE = '15 5 * * *' # Here is an example of a simple command that prints the host name and # the date and time. echo \"Hello on $( hostname ) at $( date ) .\" # This schedules the next run. sbatch --quiet --begin = $( next-cron-time \" $SCHEDULE \" ) cron.sbatch After executing a simple command (print the host name, date and time), the script schedules the next run with another call to sbatch with the --begin option.","title":"Cron-like jobs"},{"location":"midway23/examples/cron/#cron-like-jobs","text":"Cron jobs persist until they are canceled or encounter an error. The Midway2 cluster has a dedicated partition, cron , for running Cron jobs. Please email help@rcc.uchicago.edu to request submitting Cron-like jobs. These jobs are subject to scheduling limits and will be monitored. Here is an example of an sbatch script that runs a Cron job (see also cron.sbatch ): #!/bin/bash #SBATCH --time=00:05:00 #SBATCH --output=cron.log #SBATCH --open-mode=append #SBATCH --account=cron-account #SBATCH --partition=cron #SBATCH --qos=cron # Specify a valid Cron string for the schedule. This specifies that # the Cron job run once per day at 5:15a. SCHEDULE = '15 5 * * *' # Here is an example of a simple command that prints the host name and # the date and time. echo \"Hello on $( hostname ) at $( date ) .\" # This schedules the next run. sbatch --quiet --begin = $( next-cron-time \" $SCHEDULE \" ) cron.sbatch After executing a simple command (print the host name, date and time), the script schedules the next run with another call to sbatch with the --begin option.","title":"Cron-like jobs"},{"location":"midway23/examples/example_job_scripts/","text":"Illustrative examples Below are a number of example submission scripts that you can adapt to run your jobs on Midway. See also the materials from the RCC Slurm workshop for additional examples. Job arrays Slurm job arrays provide a convenient way to submit a large number of independent processing jobs. For example, Slurm job arrays can be useful for applying the same or similar computation to a collection of data sets. When a job array script is submitted, a specified number of \u201carray tasks\u201d are created based on the \u201cmaster\u201d sbatch script. Consider the following example (from array.sbatch ): #!/bin/bash #SBATCH --job-name=array #SBATCH --output=array_%A_%a.out #SBATCH --error=array_%A_%a.err #SBATCH --array=1-16 #SBATCH --time=01:00:00 #SBATCH --partition=broadwl #SBATCH --ntasks=1 #SBATCH --mem=4G # Print the task id. echo \"My SLURM_ARRAY_TASK_ID: \" $SLURM_ARRAY_TASK_ID # Add lines here to run your computations. In this simple example, --array=1-16 requests 16 array tasks (numbered 1 through 16). The \u201carray tasks\u201d are copies of the master script that are automatically submitted to the scheduler on your behalf. In each array task, the environment variable SLURM_ARRAY_TASK_ID is set to a unique value (in this example, numbers ranging from 1 to 16). Job array indices can be specified in several different ways. Here are some examples: # A job array with array tasks numbered from 0 to 31. #SBATCH --array=0-31 # A job array with array tasks numbered 1, 2, 5, 19, 27. #SBATCH --array=1,2,5,19,27 # A job array with array tasks numbered 1, 3, 5 and 7. #SBATCH --array=1-7:2 In the example sbatch script above, the %A_%a notation is filled in with the master job id ( %A ) and the array task id ( %a ). This is a simple way to create output files in which the file name is different for each job in the array. The remaining options in the sbatch script are the same as the options used in other, non-array settings; in this example, we are requesting that each array task be allocated 1 CPU ( --ntasks=1 ) and 4 GB of memory ( --mem=4G ) on the broadwl partition ( --partition=broadwl ) for up to one hour ( --time=01:00:00 ). Most partitions have limits on the number of array tasks that can run simultaneously. To achieve a higher throughput, consider Parallel batch jobs . For more information about Slurm job arrays, consule the the `Slurm documentation on job arrays`_ Large-memory jobs The bigmem2 partition is particularly well suited for computations that need more than about 60 GB of memory; see Types of Compute Nodes for technical specifications of the bigmem2 nodes. Running a large-memory job To submit a job to bigmem2, include this line in your sbatch script: #SBATCH --partition=bigmem2 Additionally, it is important to use the --mem or --mem-per-cpu options. For example, to request 8 CPU cores and 128 GB of memory on a bigmem2 node, add the following to your sbatch script: #SBATCH --ntasks=1 #SBATCH --cpus-per-task=8 #SBATCH --mem=128G Interactive computing on bigmem2 These same options can also be used to set up an sinteractive session. For example, to access a bigmem2 node with 1 CPU and 128 GB of memory, run: sinteractive --partition = bigmem2 --ntasks = 1 --cpus-per-task = 8 --mem = 128G Parallel batch jobs Computations involving a very large number of independent computations should be combined in some way to reduce the number of jobs submitted to Slurm. Here we illustrate one strategy for doing this using GNU Parallel and srun . The parallel program executes tasks simultaneously until all tasks have been completed. Here\u2019s an example script, parallel.sbatch : #!/bin/sh #SBATCH --time=01:00:00 #SBATCH --partition=broadwl #SBATCH --ntasks=28 #SBATCH --mem-per-cpu=2G # NOTE DO NOT USE THE --mem= OPTION # Load the default version of GNU parallel. module load parallel # When running a large number of tasks simultaneously, it may be # necessary to increase the user process limit. ulimit -u 10000 # This specifies the options used to run srun. The \"-N1 -n1\" options are # used to allocates a single core to each task. srun = \"srun --exclusive -N1 -n1\" # This specifies the options used to run GNU parallel: # # --delay of 0.2 prevents overloading the controlling node. # # -j is the number of tasks run simultaneously. # # The combination of --joblog and --resume create a task log that # can be used to monitor progress. # parallel = \"parallel --delay 0.2 -j $SLURM_NTASKS --joblog runtask.log --resume\" # Run a script, runtask.sh, using GNU parallel and srun. Parallel # will run the runtask script for the numbers 1 through 128. To # illustrate, the first job will run like this: # # srun --exclusive -N1 -n1 ./runtask.sh arg1:1 > runtask.1 # $parallel \" $srun ./runtask.sh arg1:{1} > runtask.sh.{1}\" ::: { 1 ..128 } # Note that if your program does not take any input, use the -n0 option to # call the parallel command: # # $parallel -n0 \"$srun ./run_noinput_task.sh > output.{1}\" ::: {1..128} In this example, our aim is to run script runtask.sh 128 times. The --ntasks option is set to 28, so at most 28 tasks can be run simultaneously. Here is the runtask.sh script that is run by GNU parallel: #!/bin/sh # This script outputs some useful information so we can see what parallel # and srun are doing. sleepsecs = $ [ ( $RANDOM % 10 ) + 10 ] s # $1 is arg1:{1} from GNU parallel. # # $PARALLEL_SEQ is a special variable from GNU parallel. It gives the # number of the job in the sequence. # # Here we print the sleep time, host name, and the date and time. echo task $1 seq: $PARALLEL_SEQ sleep: $sleepsecs host: $( hostname ) date: $( date ) # Sleep a random amount of time. sleep $sleepsecs To submit this job, copy both parallel.sbatch and runtask.sh to the same directory, and run chmod +x runtask.sh to make runtask.sh executable. Then the job can be submitted to the Slurm queue: sbatch parallel.sbatch When this job completes, you should see output files with names runtask.sh.N , where N is a number between 1 and 128. The content of the first output file (i.e., runtask.sh.1 ) should look something like this: task arg1:1 seq:1 sleep:14s host:midway2-0002 date:Thu Jan 10 09:17:36 CST 2017 Another file runtask.log is also created. It gives a list of the completed jobs. (Note: If the sbatch is submitted again, nothing will be run until runtask.log is removed.) It is also possible to use this same technique to run multithreaded tasks in parallel. Here is an example sbatch script, parallel-hybrid.sbatch , that distributes multithreaded computations (each using 28 CPUs) across 2 nodes: #!/bin/sh #SBATCH --partition=broadwl #SBATCH --time=01:00:00 #SBATCH --nodes=2 #SBATCH --ntasks-per-node=1 #SBATCH --cpus-per-task=28 #SBATCH --exclusive # Load the default version of GNU parallel. module load parallel srun = \"srun --exclusive -N1 -n1 --cpus-per-task $SLURM_CPUS_PER_TASK \" # Instead of $SLURM_NTASKS, use $SLURM_NNODES to determine how # many jobs should be run simultaneously. parallel = \"parallel --delay 0.2 -j $SLURM_NNODES --joblog runtask.log --resume\" # Run the parallel command. $parallel \" $srun ./runtask.sh arg1:{1} > runtask.sh.{1}\" ::: { 1 ..6 } MPI jobs Here we present a couple small examples illustrating how to use MPI for distributed computing Midway. For more information on the MPI libraries available on Midway, see Message Passing Interface (MPI) . Our main illustration is a \u201chello world\u201d example. See file hellompi.c for the C code we will compile and run. #include <stdio.h> #include <stdlib.h> #include <mpi.h> int main ( int argc , char * argv [], char * envp []) { int numprocs , rank , namelen ; char processor_name [ MPI_MAX_PROCESSOR_NAME ]; MPI_Init ( & argc , & argv ); MPI_Comm_size ( MPI_COMM_WORLD , & numprocs ); MPI_Comm_rank ( MPI_COMM_WORLD , & rank ); MPI_Get_processor_name ( processor_name , & namelen ); printf ( \"Process %d on %s out of %d \\n \" , rank , processor_name , numprocs ); MPI_Finalize (); } Copy hellompi.c to your home directory on Midway, load the default OpenMPI module, and compile the program on a Midway login node: module load openmpi mpicc hellompi.c -o hellompi hellompi.sbatch is a submission script that can be used to submit a job to Midway to run the hellompi program: #!/bin/bash #SBATCH --job-name=hellompi #SBATCH --output=hellompi.out #SBATCH --ntasks=56 #SBATCH --partition=broadwl #SBATCH --constraint=fdr # Load the default OpenMPI module. module load openmpi # Run the hellompi program with mpirun. The -n flag is not required; # mpirun will automatically figure out the best configuration from the # Slurm environment variables. mpirun ./hellompi Submit the MPI job to the Slurm job scheduler from a Midway login node: sbatch hellompi.sbatch Here is an example output: Process 1 on midway2-0172.rcc.local out of 56 Process 3 on midway2-0172.rcc.local out of 56 Process 5 on midway2-0172.rcc.local out of 56 Process 7 on midway2-0172.rcc.local out of 56 Process 6 on midway2-0172.rcc.local out of 56 Process 9 on midway2-0172.rcc.local out of 56 Process 10 on midway2-0172.rcc.local out of 56 Process 11 on midway2-0172.rcc.local out of 56 Process 13 on midway2-0172.rcc.local out of 56 Process 0 on midway2-0172.rcc.local out of 56 Process 2 on midway2-0172.rcc.local out of 56 Process 4 on midway2-0172.rcc.local out of 56 Process 8 on midway2-0172.rcc.local out of 56 Process 12 on midway2-0172.rcc.local out of 56 Process 17 on midway2-0173.rcc.local out of 56 Process 19 on midway2-0173.rcc.local out of 56 Process 21 on midway2-0173.rcc.local out of 56 Process 28 on midway2-0173.rcc.local out of 56 Process 29 on midway2-0173.rcc.local out of 56 Process 31 on midway2-0173.rcc.local out of 56 Process 32 on midway2-0173.rcc.local out of 56 Process 15 on midway2-0173.rcc.local out of 56 Process 18 on midway2-0173.rcc.local out of 56 Process 20 on midway2-0173.rcc.local out of 56 Process 22 on midway2-0173.rcc.local out of 56 Process 23 on midway2-0173.rcc.local out of 56 Process 24 on midway2-0173.rcc.local out of 56 Process 52 on midway2-0175.rcc.local out of 56 Process 25 on midway2-0173.rcc.local out of 56 Process 53 on midway2-0175.rcc.local out of 56 Process 26 on midway2-0173.rcc.local out of 56 Process 54 on midway2-0175.rcc.local out of 56 Process 27 on midway2-0173.rcc.local out of 56 Process 55 on midway2-0175.rcc.local out of 56 Process 14 on midway2-0173.rcc.local out of 56 Process 16 on midway2-0173.rcc.local out of 56 Process 30 on midway2-0173.rcc.local out of 56 Process 43 on midway2-0174.rcc.local out of 56 Process 51 on midway2-0174.rcc.local out of 56 Process 48 on midway2-0174.rcc.local out of 56 Process 49 on midway2-0174.rcc.local out of 56 Process 46 on midway2-0174.rcc.local out of 56 Process 44 on midway2-0174.rcc.local out of 56 Process 45 on midway2-0174.rcc.local out of 56 Process 40 on midway2-0174.rcc.local out of 56 Process 42 on midway2-0174.rcc.local out of 56 Process 36 on midway2-0174.rcc.local out of 56 Process 37 on midway2-0174.rcc.local out of 56 Process 47 on midway2-0174.rcc.local out of 56 Process 34 on midway2-0174.rcc.local out of 56 Process 38 on midway2-0174.rcc.local out of 56 Process 35 on midway2-0174.rcc.local out of 56 Process 39 on midway2-0174.rcc.local out of 56 Process 41 on midway2-0174.rcc.local out of 56 Process 50 on midway2-0174.rcc.local out of 56 Process 33 on midway2-0174.rcc.local out of 56 From this output, we observe that the computation is distributed on 4 different nodes, with many threads running simultaneously on the same node. When developing your own sbatch script for MPI-based computations, keep in mind the following points. Without the --constraint=fdr or --constraint=edr options, your computations may run on nodes with FDR, EDR, or combination of both. It is possible to control the number of tasks that are run per node with the --ntasks-per-node option. For example, submitting the job like this to Midway: sbatch --ntasks-per-node=1 hellompi.sbatch results in each thread running on a different node: Process 52 on midway2-0175.rcc.local out of 56 Process 50 on midway2-0173.rcc.local out of 56 Process 49 on midway2-0172.rcc.local out of 56 Process 0 on midway2-0002.rcc.local out of 56 Process 13 on midway2-0052.rcc.local out of 56 Process 2 on midway2-0013.rcc.local out of 56 Process 9 on midway2-0033.rcc.local out of 56 Process 54 on midway2-0177.rcc.local out of 56 Process 53 on midway2-0176.rcc.local out of 56 Process 44 on midway2-0157.rcc.local out of 56 Process 55 on midway2-0178.rcc.local out of 56 Process 11 on midway2-0041.rcc.local out of 56 Process 40 on midway2-0152.rcc.local out of 56 Process 43 on midway2-0156.rcc.local out of 56 Process 45 on midway2-0161.rcc.local out of 56 Process 46 on midway2-0162.rcc.local out of 56 Process 38 on midway2-0147.rcc.local out of 56 Process 39 on midway2-0148.rcc.local out of 56 Process 24 on midway2-0101.rcc.local out of 56 Process 3 on midway2-0014.rcc.local out of 56 Process 42 on midway2-0155.rcc.local out of 56 Process 51 on midway2-0174.rcc.local out of 56 Process 36 on midway2-0145.rcc.local out of 56 Process 25 on midway2-0102.rcc.local out of 56 Process 16 on midway2-0055.rcc.local out of 56 Process 18 on midway2-0057.rcc.local out of 56 Process 12 on midway2-0051.rcc.local out of 56 Process 14 on midway2-0053.rcc.local out of 56 Process 4 on midway2-0015.rcc.local out of 56 Process 15 on midway2-0054.rcc.local out of 56 Process 48 on midway2-0164.rcc.local out of 56 Process 28 on midway2-0105.rcc.local out of 56 Process 22 on midway2-0097.rcc.local out of 56 Process 30 on midway2-0118.rcc.local out of 56 Process 1 on midway2-0012.rcc.local out of 56 Process 35 on midway2-0144.rcc.local out of 56 Process 17 on midway2-0056.rcc.local out of 56 Process 37 on midway2-0146.rcc.local out of 56 Process 32 on midway2-0141.rcc.local out of 56 Process 34 on midway2-0143.rcc.local out of 56 Process 27 on midway2-0104.rcc.local out of 56 Process 31 on midway2-0119.rcc.local out of 56 Process 29 on midway2-0106.rcc.local out of 56 Process 10 on midway2-0034.rcc.local out of 56 Process 47 on midway2-0163.rcc.local out of 56 Process 33 on midway2-0142.rcc.local out of 56 Process 26 on midway2-0103.rcc.local out of 56 Process 7 on midway2-0019.rcc.local out of 56 Process 20 on midway2-0073.rcc.local out of 56 Process 5 on midway2-0016.rcc.local out of 56 Process 8 on midway2-0027.rcc.local out of 56 Process 41 on midway2-0153.rcc.local out of 56 Process 6 on midway2-0017.rcc.local out of 56 Process 21 on midway2-0096.rcc.local out of 56 Process 19 on midway2-0072.rcc.local out of 56 Process 23 on midway2-0100.rcc.local out of 56 Additional notes Both OpenMPI and IntelMPI have the ability to launch MPI programs directly with the Slurm command srun . It is not necessary to use this mode for most jobs, but it may provide additional job launch options. For example, from a Midway login node it is possible to launch the above hellompi program using OpenMPI using 28 MPI processes: srun -n28 hellompi With IntelMPI, you need to also set an environment variable for this to work: export I_MPI_PMI_LIBRARY=/software/slurm-current-$DISTARCH/lib/libpmi.so srun -n28 hellompi Hybrid MPI/OpenMP jobs MPI and OpenMP can be used at the same time to create a Hybrid MPI/OpenMP program. Let\u2019s look at an example Hybrid MPI/OpenMP hello world program and explain the steps needed to compile and submit it to the queue. An example hybrid MPI hello world program: hellohybrid.c #include <stdio.h> #include <omp.h> #include \"mpi.h\" int main ( int argc , char * argv []) { int numprocs , rank , namelen ; char processor_name [ MPI_MAX_PROCESSOR_NAME ]; int iam = 0 , np = 1 ; MPI_Init ( & argc , & argv ); MPI_Comm_size ( MPI_COMM_WORLD , & numprocs ); MPI_Comm_rank ( MPI_COMM_WORLD , & rank ); MPI_Get_processor_name ( processor_name , & namelen ); #pragma omp parallel default(shared) private(iam, np) { np = omp_get_num_threads (); iam = omp_get_thread_num (); printf ( \"Hello from thread %d out of %d from process %d out of %d on %s \\n \" , iam , np , rank , numprocs , processor_name ); } MPI_Finalize (); } To run the program on the RCC cluster, copy hellohybrid.c and hellohybrid.sbatch to your home directory, then compile the code interactively by entering the following commands into a terminal on a Midway2 login node: module load openmpi mpicc -fopenmp hellohybrid.c -o hellohybrid Here we load the default MPI compiler, but it should be possible to use any available MPI compiler to compile and run this example. Note that the option -fopenmp must be used here to compile the program because the code includes OpenMP directives (use -openmp for the Intel compiler and -mp for the PGI compiler). hellohybrid.sbatch is a submission script that can be used to submit a job to Midway2 to run the hellohybrid program. #!/bin/bash # A job submission script for running a hybrid MPI/OpenMP job on # Midway2. #SBATCH --job-name=hellohybrid #SBATCH --output=hellohybrid.out #SBATCH --ntasks=4 #SBATCH --cpus-per-task=8 #SBATCH --partition=broadwl #SBATCH --constraint=edr # Load the default OpenMPI module. module load openmpi # Set OMP_NUM_THREADS to the number of CPUs per task we asked for. export OMP_NUM_THREADS = $SLURM_CPUS_PER_TASK # Run the process with mpirun. Note that the -n option is not required # in this case; mpirun will automatically determine how many processes # to run from the Slurm settings. mpirun ./hellohybrid The options are similar to running an MPI job, with some differences: * ` --ntasks = 4 ` specifies the number of MPI processes ( \u201ctasks\u201d ) . * ` --cpus-per-task = 8 ` allocates 8 CPUs for each task. * ` export OMP_NUM_THREADS = $SLURM_CPUS_PER_TASK ` sets the number of OpenMP threads to the number of requested cores ( CPUs ) for each task. You can submit ` hellohybrid.sbatch ` using the following command from one of Midway2 login nodes: ``` default sbatch hellohybrid.sbatch Here is an example output of this program submitted to the broadwl partition on Midway2: Hello from thread 0 out of 8 from process 0 out of 4 on midway2-0269.rcc.local Hello from thread 6 out of 8 from process 0 out of 4 on midway2-0269.rcc.local Hello from thread 0 out of 8 from process 1 out of 4 on midway2-0269.rcc.local Hello from thread 7 out of 8 from process 1 out of 4 on midway2-0269.rcc.local Hello from thread 3 out of 8 from process 1 out of 4 on midway2-0269.rcc.local Hello from thread 2 out of 8 from process 0 out of 4 on midway2-0269.rcc.local Hello from thread 3 out of 8 from process 0 out of 4 on midway2-0269.rcc.local Hello from thread 4 out of 8 from process 0 out of 4 on midway2-0269.rcc.local Hello from thread 5 out of 8 from process 0 out of 4 on midway2-0269.rcc.local Hello from thread 1 out of 8 from process 0 out of 4 on midway2-0269.rcc.local Hello from thread 7 out of 8 from process 0 out of 4 on midway2-0269.rcc.local Hello from thread 2 out of 8 from process 1 out of 4 on midway2-0269.rcc.local Hello from thread 1 out of 8 from process 1 out of 4 on midway2-0269.rcc.local Hello from thread 4 out of 8 from process 1 out of 4 on midway2-0269.rcc.local Hello from thread 5 out of 8 from process 1 out of 4 on midway2-0269.rcc.local Hello from thread 6 out of 8 from process 1 out of 4 on midway2-0269.rcc.local Hello from thread 0 out of 8 from process 2 out of 4 on midway2-0269.rcc.local Hello from thread 7 out of 8 from process 2 out of 4 on midway2-0269.rcc.local Hello from thread 4 out of 8 from process 2 out of 4 on midway2-0269.rcc.local Hello from thread 5 out of 8 from process 2 out of 4 on midway2-0269.rcc.local Hello from thread 1 out of 8 from process 2 out of 4 on midway2-0269.rcc.local Hello from thread 6 out of 8 from process 2 out of 4 on midway2-0269.rcc.local Hello from thread 3 out of 8 from process 2 out of 4 on midway2-0269.rcc.local Hello from thread 2 out of 8 from process 2 out of 4 on midway2-0269.rcc.local Hello from thread 0 out of 8 from process 3 out of 4 on midway2-0270.rcc.local Hello from thread 7 out of 8 from process 3 out of 4 on midway2-0270.rcc.local Hello from thread 4 out of 8 from process 3 out of 4 on midway2-0270.rcc.local Hello from thread 6 out of 8 from process 3 out of 4 on midway2-0270.rcc.local Hello from thread 2 out of 8 from process 3 out of 4 on midway2-0270.rcc.local Hello from thread 5 out of 8 from process 3 out of 4 on midway2-0270.rcc.local Hello from thread 1 out of 8 from process 3 out of 4 on midway2-0270.rcc.local GPU jobs The gpu2 partition is dedicated to software that uses Graphical Processing Units (GPUs). See Types of Compute Nodes for technical specifications of the gpu2 nodes. CUDA and OpenACC are two widely used tools for developing GPU-based software. For information on compiling code with CUDA and OpenACC, see CUDA and OpenACC Compilers . Running GPU code on Midway2 To submit a job to one of the GPU nodes, you must include the following lines in your sbatch script: #SBATCH --partition=gpu2 #SBATCH --gres=gpu:N where N is the number of GPUs requested. Allowable settings for N range from 1 to 4. If your application is entirely GPU driven, then you do not need to explicilty request cores as one CPU core will be assigned by default to act as a master to launch the GPU based calculation. If however your application is mixed CPU-GPU then you will need to request the number of cores with \u2013ntasks as is required by your job. Here is an example sbatch script that allocates GPU resources and loads the CUDA compilers (see also gpu.sbatch ): #!/bin/bash #SBATCH --job-name=gpu # job name #SBATCH --output=gpu.out # output log file #SBATCH --error=gpu.err # error file #SBATCH --time=01:00:00 # 1 hour of wall time #SBATCH --nodes=1 # 1 GPU node #SBATCH --partition=gpu2 # GPU2 partition #SBATCH --ntasks=1 # 1 CPU core to drive GPU #SBATCH --gres=gpu:1 # Request 1 GPU # Load all required modules below. As an example we load cuda/9.1 module load cuda/9.1 # Add lines here to run your GPU-based computations. Cron-like jobs Cron jobs persist until they are canceled or encounter an error. The Midway2 cluster has a dedicated partition, cron , for running Cron jobs. Please email help@rcc.uchicago.edu to request submitting Cron-like jobs. These jobs are subject to scheduling limits and will be monitored. Here is an example of an sbatch script that runs a Cron job (see also cron.sbatch ): #!/bin/bash #SBATCH --time=00:05:00 #SBATCH --output=cron.log #SBATCH --open-mode=append #SBATCH --account=cron-account #SBATCH --partition=cron #SBATCH --qos=cron # Specify a valid Cron string for the schedule. This specifies that # the Cron job run once per day at 5:15a. SCHEDULE = '15 5 * * *' # Here is an example of a simple command that prints the host name and # the date and time. echo \"Hello on $( hostname ) at $( date ) .\" # This schedules the next run. sbatch --quiet --begin = $( next-cron-time \" $SCHEDULE \" ) cron.sbatch After executing a simple command (print the host name, date and time), the script schedules the next run with another call to sbatch with the --begin option.","title":"Example Job Submission Scripts"},{"location":"midway23/examples/example_job_scripts/#illustrative-examples","text":"Below are a number of example submission scripts that you can adapt to run your jobs on Midway. See also the materials from the RCC Slurm workshop for additional examples.","title":"Illustrative examples"},{"location":"midway23/examples/example_job_scripts/#job-arrays","text":"Slurm job arrays provide a convenient way to submit a large number of independent processing jobs. For example, Slurm job arrays can be useful for applying the same or similar computation to a collection of data sets. When a job array script is submitted, a specified number of \u201carray tasks\u201d are created based on the \u201cmaster\u201d sbatch script. Consider the following example (from array.sbatch ): #!/bin/bash #SBATCH --job-name=array #SBATCH --output=array_%A_%a.out #SBATCH --error=array_%A_%a.err #SBATCH --array=1-16 #SBATCH --time=01:00:00 #SBATCH --partition=broadwl #SBATCH --ntasks=1 #SBATCH --mem=4G # Print the task id. echo \"My SLURM_ARRAY_TASK_ID: \" $SLURM_ARRAY_TASK_ID # Add lines here to run your computations. In this simple example, --array=1-16 requests 16 array tasks (numbered 1 through 16). The \u201carray tasks\u201d are copies of the master script that are automatically submitted to the scheduler on your behalf. In each array task, the environment variable SLURM_ARRAY_TASK_ID is set to a unique value (in this example, numbers ranging from 1 to 16). Job array indices can be specified in several different ways. Here are some examples: # A job array with array tasks numbered from 0 to 31. #SBATCH --array=0-31 # A job array with array tasks numbered 1, 2, 5, 19, 27. #SBATCH --array=1,2,5,19,27 # A job array with array tasks numbered 1, 3, 5 and 7. #SBATCH --array=1-7:2 In the example sbatch script above, the %A_%a notation is filled in with the master job id ( %A ) and the array task id ( %a ). This is a simple way to create output files in which the file name is different for each job in the array. The remaining options in the sbatch script are the same as the options used in other, non-array settings; in this example, we are requesting that each array task be allocated 1 CPU ( --ntasks=1 ) and 4 GB of memory ( --mem=4G ) on the broadwl partition ( --partition=broadwl ) for up to one hour ( --time=01:00:00 ). Most partitions have limits on the number of array tasks that can run simultaneously. To achieve a higher throughput, consider Parallel batch jobs . For more information about Slurm job arrays, consule the the `Slurm documentation on job arrays`_","title":"Job arrays"},{"location":"midway23/examples/example_job_scripts/#large-memory-jobs","text":"The bigmem2 partition is particularly well suited for computations that need more than about 60 GB of memory; see Types of Compute Nodes for technical specifications of the bigmem2 nodes.","title":"Large-memory jobs"},{"location":"midway23/examples/example_job_scripts/#running-a-large-memory-job","text":"To submit a job to bigmem2, include this line in your sbatch script: #SBATCH --partition=bigmem2 Additionally, it is important to use the --mem or --mem-per-cpu options. For example, to request 8 CPU cores and 128 GB of memory on a bigmem2 node, add the following to your sbatch script: #SBATCH --ntasks=1 #SBATCH --cpus-per-task=8 #SBATCH --mem=128G","title":"Running a large-memory job"},{"location":"midway23/examples/example_job_scripts/#interactive-computing-on-bigmem2","text":"These same options can also be used to set up an sinteractive session. For example, to access a bigmem2 node with 1 CPU and 128 GB of memory, run: sinteractive --partition = bigmem2 --ntasks = 1 --cpus-per-task = 8 --mem = 128G","title":"Interactive computing on bigmem2"},{"location":"midway23/examples/example_job_scripts/#parallel-batch-jobs","text":"Computations involving a very large number of independent computations should be combined in some way to reduce the number of jobs submitted to Slurm. Here we illustrate one strategy for doing this using GNU Parallel and srun . The parallel program executes tasks simultaneously until all tasks have been completed. Here\u2019s an example script, parallel.sbatch : #!/bin/sh #SBATCH --time=01:00:00 #SBATCH --partition=broadwl #SBATCH --ntasks=28 #SBATCH --mem-per-cpu=2G # NOTE DO NOT USE THE --mem= OPTION # Load the default version of GNU parallel. module load parallel # When running a large number of tasks simultaneously, it may be # necessary to increase the user process limit. ulimit -u 10000 # This specifies the options used to run srun. The \"-N1 -n1\" options are # used to allocates a single core to each task. srun = \"srun --exclusive -N1 -n1\" # This specifies the options used to run GNU parallel: # # --delay of 0.2 prevents overloading the controlling node. # # -j is the number of tasks run simultaneously. # # The combination of --joblog and --resume create a task log that # can be used to monitor progress. # parallel = \"parallel --delay 0.2 -j $SLURM_NTASKS --joblog runtask.log --resume\" # Run a script, runtask.sh, using GNU parallel and srun. Parallel # will run the runtask script for the numbers 1 through 128. To # illustrate, the first job will run like this: # # srun --exclusive -N1 -n1 ./runtask.sh arg1:1 > runtask.1 # $parallel \" $srun ./runtask.sh arg1:{1} > runtask.sh.{1}\" ::: { 1 ..128 } # Note that if your program does not take any input, use the -n0 option to # call the parallel command: # # $parallel -n0 \"$srun ./run_noinput_task.sh > output.{1}\" ::: {1..128} In this example, our aim is to run script runtask.sh 128 times. The --ntasks option is set to 28, so at most 28 tasks can be run simultaneously. Here is the runtask.sh script that is run by GNU parallel: #!/bin/sh # This script outputs some useful information so we can see what parallel # and srun are doing. sleepsecs = $ [ ( $RANDOM % 10 ) + 10 ] s # $1 is arg1:{1} from GNU parallel. # # $PARALLEL_SEQ is a special variable from GNU parallel. It gives the # number of the job in the sequence. # # Here we print the sleep time, host name, and the date and time. echo task $1 seq: $PARALLEL_SEQ sleep: $sleepsecs host: $( hostname ) date: $( date ) # Sleep a random amount of time. sleep $sleepsecs To submit this job, copy both parallel.sbatch and runtask.sh to the same directory, and run chmod +x runtask.sh to make runtask.sh executable. Then the job can be submitted to the Slurm queue: sbatch parallel.sbatch When this job completes, you should see output files with names runtask.sh.N , where N is a number between 1 and 128. The content of the first output file (i.e., runtask.sh.1 ) should look something like this: task arg1:1 seq:1 sleep:14s host:midway2-0002 date:Thu Jan 10 09:17:36 CST 2017 Another file runtask.log is also created. It gives a list of the completed jobs. (Note: If the sbatch is submitted again, nothing will be run until runtask.log is removed.) It is also possible to use this same technique to run multithreaded tasks in parallel. Here is an example sbatch script, parallel-hybrid.sbatch , that distributes multithreaded computations (each using 28 CPUs) across 2 nodes: #!/bin/sh #SBATCH --partition=broadwl #SBATCH --time=01:00:00 #SBATCH --nodes=2 #SBATCH --ntasks-per-node=1 #SBATCH --cpus-per-task=28 #SBATCH --exclusive # Load the default version of GNU parallel. module load parallel srun = \"srun --exclusive -N1 -n1 --cpus-per-task $SLURM_CPUS_PER_TASK \" # Instead of $SLURM_NTASKS, use $SLURM_NNODES to determine how # many jobs should be run simultaneously. parallel = \"parallel --delay 0.2 -j $SLURM_NNODES --joblog runtask.log --resume\" # Run the parallel command. $parallel \" $srun ./runtask.sh arg1:{1} > runtask.sh.{1}\" ::: { 1 ..6 }","title":"Parallel batch jobs"},{"location":"midway23/examples/example_job_scripts/#mpi-jobs","text":"Here we present a couple small examples illustrating how to use MPI for distributed computing Midway. For more information on the MPI libraries available on Midway, see Message Passing Interface (MPI) . Our main illustration is a \u201chello world\u201d example. See file hellompi.c for the C code we will compile and run. #include <stdio.h> #include <stdlib.h> #include <mpi.h> int main ( int argc , char * argv [], char * envp []) { int numprocs , rank , namelen ; char processor_name [ MPI_MAX_PROCESSOR_NAME ]; MPI_Init ( & argc , & argv ); MPI_Comm_size ( MPI_COMM_WORLD , & numprocs ); MPI_Comm_rank ( MPI_COMM_WORLD , & rank ); MPI_Get_processor_name ( processor_name , & namelen ); printf ( \"Process %d on %s out of %d \\n \" , rank , processor_name , numprocs ); MPI_Finalize (); } Copy hellompi.c to your home directory on Midway, load the default OpenMPI module, and compile the program on a Midway login node: module load openmpi mpicc hellompi.c -o hellompi hellompi.sbatch is a submission script that can be used to submit a job to Midway to run the hellompi program: #!/bin/bash #SBATCH --job-name=hellompi #SBATCH --output=hellompi.out #SBATCH --ntasks=56 #SBATCH --partition=broadwl #SBATCH --constraint=fdr # Load the default OpenMPI module. module load openmpi # Run the hellompi program with mpirun. The -n flag is not required; # mpirun will automatically figure out the best configuration from the # Slurm environment variables. mpirun ./hellompi Submit the MPI job to the Slurm job scheduler from a Midway login node: sbatch hellompi.sbatch Here is an example output: Process 1 on midway2-0172.rcc.local out of 56 Process 3 on midway2-0172.rcc.local out of 56 Process 5 on midway2-0172.rcc.local out of 56 Process 7 on midway2-0172.rcc.local out of 56 Process 6 on midway2-0172.rcc.local out of 56 Process 9 on midway2-0172.rcc.local out of 56 Process 10 on midway2-0172.rcc.local out of 56 Process 11 on midway2-0172.rcc.local out of 56 Process 13 on midway2-0172.rcc.local out of 56 Process 0 on midway2-0172.rcc.local out of 56 Process 2 on midway2-0172.rcc.local out of 56 Process 4 on midway2-0172.rcc.local out of 56 Process 8 on midway2-0172.rcc.local out of 56 Process 12 on midway2-0172.rcc.local out of 56 Process 17 on midway2-0173.rcc.local out of 56 Process 19 on midway2-0173.rcc.local out of 56 Process 21 on midway2-0173.rcc.local out of 56 Process 28 on midway2-0173.rcc.local out of 56 Process 29 on midway2-0173.rcc.local out of 56 Process 31 on midway2-0173.rcc.local out of 56 Process 32 on midway2-0173.rcc.local out of 56 Process 15 on midway2-0173.rcc.local out of 56 Process 18 on midway2-0173.rcc.local out of 56 Process 20 on midway2-0173.rcc.local out of 56 Process 22 on midway2-0173.rcc.local out of 56 Process 23 on midway2-0173.rcc.local out of 56 Process 24 on midway2-0173.rcc.local out of 56 Process 52 on midway2-0175.rcc.local out of 56 Process 25 on midway2-0173.rcc.local out of 56 Process 53 on midway2-0175.rcc.local out of 56 Process 26 on midway2-0173.rcc.local out of 56 Process 54 on midway2-0175.rcc.local out of 56 Process 27 on midway2-0173.rcc.local out of 56 Process 55 on midway2-0175.rcc.local out of 56 Process 14 on midway2-0173.rcc.local out of 56 Process 16 on midway2-0173.rcc.local out of 56 Process 30 on midway2-0173.rcc.local out of 56 Process 43 on midway2-0174.rcc.local out of 56 Process 51 on midway2-0174.rcc.local out of 56 Process 48 on midway2-0174.rcc.local out of 56 Process 49 on midway2-0174.rcc.local out of 56 Process 46 on midway2-0174.rcc.local out of 56 Process 44 on midway2-0174.rcc.local out of 56 Process 45 on midway2-0174.rcc.local out of 56 Process 40 on midway2-0174.rcc.local out of 56 Process 42 on midway2-0174.rcc.local out of 56 Process 36 on midway2-0174.rcc.local out of 56 Process 37 on midway2-0174.rcc.local out of 56 Process 47 on midway2-0174.rcc.local out of 56 Process 34 on midway2-0174.rcc.local out of 56 Process 38 on midway2-0174.rcc.local out of 56 Process 35 on midway2-0174.rcc.local out of 56 Process 39 on midway2-0174.rcc.local out of 56 Process 41 on midway2-0174.rcc.local out of 56 Process 50 on midway2-0174.rcc.local out of 56 Process 33 on midway2-0174.rcc.local out of 56 From this output, we observe that the computation is distributed on 4 different nodes, with many threads running simultaneously on the same node. When developing your own sbatch script for MPI-based computations, keep in mind the following points. Without the --constraint=fdr or --constraint=edr options, your computations may run on nodes with FDR, EDR, or combination of both. It is possible to control the number of tasks that are run per node with the --ntasks-per-node option. For example, submitting the job like this to Midway: sbatch --ntasks-per-node=1 hellompi.sbatch results in each thread running on a different node: Process 52 on midway2-0175.rcc.local out of 56 Process 50 on midway2-0173.rcc.local out of 56 Process 49 on midway2-0172.rcc.local out of 56 Process 0 on midway2-0002.rcc.local out of 56 Process 13 on midway2-0052.rcc.local out of 56 Process 2 on midway2-0013.rcc.local out of 56 Process 9 on midway2-0033.rcc.local out of 56 Process 54 on midway2-0177.rcc.local out of 56 Process 53 on midway2-0176.rcc.local out of 56 Process 44 on midway2-0157.rcc.local out of 56 Process 55 on midway2-0178.rcc.local out of 56 Process 11 on midway2-0041.rcc.local out of 56 Process 40 on midway2-0152.rcc.local out of 56 Process 43 on midway2-0156.rcc.local out of 56 Process 45 on midway2-0161.rcc.local out of 56 Process 46 on midway2-0162.rcc.local out of 56 Process 38 on midway2-0147.rcc.local out of 56 Process 39 on midway2-0148.rcc.local out of 56 Process 24 on midway2-0101.rcc.local out of 56 Process 3 on midway2-0014.rcc.local out of 56 Process 42 on midway2-0155.rcc.local out of 56 Process 51 on midway2-0174.rcc.local out of 56 Process 36 on midway2-0145.rcc.local out of 56 Process 25 on midway2-0102.rcc.local out of 56 Process 16 on midway2-0055.rcc.local out of 56 Process 18 on midway2-0057.rcc.local out of 56 Process 12 on midway2-0051.rcc.local out of 56 Process 14 on midway2-0053.rcc.local out of 56 Process 4 on midway2-0015.rcc.local out of 56 Process 15 on midway2-0054.rcc.local out of 56 Process 48 on midway2-0164.rcc.local out of 56 Process 28 on midway2-0105.rcc.local out of 56 Process 22 on midway2-0097.rcc.local out of 56 Process 30 on midway2-0118.rcc.local out of 56 Process 1 on midway2-0012.rcc.local out of 56 Process 35 on midway2-0144.rcc.local out of 56 Process 17 on midway2-0056.rcc.local out of 56 Process 37 on midway2-0146.rcc.local out of 56 Process 32 on midway2-0141.rcc.local out of 56 Process 34 on midway2-0143.rcc.local out of 56 Process 27 on midway2-0104.rcc.local out of 56 Process 31 on midway2-0119.rcc.local out of 56 Process 29 on midway2-0106.rcc.local out of 56 Process 10 on midway2-0034.rcc.local out of 56 Process 47 on midway2-0163.rcc.local out of 56 Process 33 on midway2-0142.rcc.local out of 56 Process 26 on midway2-0103.rcc.local out of 56 Process 7 on midway2-0019.rcc.local out of 56 Process 20 on midway2-0073.rcc.local out of 56 Process 5 on midway2-0016.rcc.local out of 56 Process 8 on midway2-0027.rcc.local out of 56 Process 41 on midway2-0153.rcc.local out of 56 Process 6 on midway2-0017.rcc.local out of 56 Process 21 on midway2-0096.rcc.local out of 56 Process 19 on midway2-0072.rcc.local out of 56 Process 23 on midway2-0100.rcc.local out of 56","title":"MPI jobs"},{"location":"midway23/examples/example_job_scripts/#additional-notes","text":"Both OpenMPI and IntelMPI have the ability to launch MPI programs directly with the Slurm command srun . It is not necessary to use this mode for most jobs, but it may provide additional job launch options. For example, from a Midway login node it is possible to launch the above hellompi program using OpenMPI using 28 MPI processes: srun -n28 hellompi With IntelMPI, you need to also set an environment variable for this to work: export I_MPI_PMI_LIBRARY=/software/slurm-current-$DISTARCH/lib/libpmi.so srun -n28 hellompi","title":"Additional notes"},{"location":"midway23/examples/example_job_scripts/#hybrid-mpiopenmp-jobs","text":"MPI and OpenMP can be used at the same time to create a Hybrid MPI/OpenMP program. Let\u2019s look at an example Hybrid MPI/OpenMP hello world program and explain the steps needed to compile and submit it to the queue. An example hybrid MPI hello world program: hellohybrid.c #include <stdio.h> #include <omp.h> #include \"mpi.h\" int main ( int argc , char * argv []) { int numprocs , rank , namelen ; char processor_name [ MPI_MAX_PROCESSOR_NAME ]; int iam = 0 , np = 1 ; MPI_Init ( & argc , & argv ); MPI_Comm_size ( MPI_COMM_WORLD , & numprocs ); MPI_Comm_rank ( MPI_COMM_WORLD , & rank ); MPI_Get_processor_name ( processor_name , & namelen ); #pragma omp parallel default(shared) private(iam, np) { np = omp_get_num_threads (); iam = omp_get_thread_num (); printf ( \"Hello from thread %d out of %d from process %d out of %d on %s \\n \" , iam , np , rank , numprocs , processor_name ); } MPI_Finalize (); } To run the program on the RCC cluster, copy hellohybrid.c and hellohybrid.sbatch to your home directory, then compile the code interactively by entering the following commands into a terminal on a Midway2 login node: module load openmpi mpicc -fopenmp hellohybrid.c -o hellohybrid Here we load the default MPI compiler, but it should be possible to use any available MPI compiler to compile and run this example. Note that the option -fopenmp must be used here to compile the program because the code includes OpenMP directives (use -openmp for the Intel compiler and -mp for the PGI compiler). hellohybrid.sbatch is a submission script that can be used to submit a job to Midway2 to run the hellohybrid program. #!/bin/bash # A job submission script for running a hybrid MPI/OpenMP job on # Midway2. #SBATCH --job-name=hellohybrid #SBATCH --output=hellohybrid.out #SBATCH --ntasks=4 #SBATCH --cpus-per-task=8 #SBATCH --partition=broadwl #SBATCH --constraint=edr # Load the default OpenMPI module. module load openmpi # Set OMP_NUM_THREADS to the number of CPUs per task we asked for. export OMP_NUM_THREADS = $SLURM_CPUS_PER_TASK # Run the process with mpirun. Note that the -n option is not required # in this case; mpirun will automatically determine how many processes # to run from the Slurm settings. mpirun ./hellohybrid The options are similar to running an MPI job, with some differences: * ` --ntasks = 4 ` specifies the number of MPI processes ( \u201ctasks\u201d ) . * ` --cpus-per-task = 8 ` allocates 8 CPUs for each task. * ` export OMP_NUM_THREADS = $SLURM_CPUS_PER_TASK ` sets the number of OpenMP threads to the number of requested cores ( CPUs ) for each task. You can submit ` hellohybrid.sbatch ` using the following command from one of Midway2 login nodes: ``` default sbatch hellohybrid.sbatch Here is an example output of this program submitted to the broadwl partition on Midway2: Hello from thread 0 out of 8 from process 0 out of 4 on midway2-0269.rcc.local Hello from thread 6 out of 8 from process 0 out of 4 on midway2-0269.rcc.local Hello from thread 0 out of 8 from process 1 out of 4 on midway2-0269.rcc.local Hello from thread 7 out of 8 from process 1 out of 4 on midway2-0269.rcc.local Hello from thread 3 out of 8 from process 1 out of 4 on midway2-0269.rcc.local Hello from thread 2 out of 8 from process 0 out of 4 on midway2-0269.rcc.local Hello from thread 3 out of 8 from process 0 out of 4 on midway2-0269.rcc.local Hello from thread 4 out of 8 from process 0 out of 4 on midway2-0269.rcc.local Hello from thread 5 out of 8 from process 0 out of 4 on midway2-0269.rcc.local Hello from thread 1 out of 8 from process 0 out of 4 on midway2-0269.rcc.local Hello from thread 7 out of 8 from process 0 out of 4 on midway2-0269.rcc.local Hello from thread 2 out of 8 from process 1 out of 4 on midway2-0269.rcc.local Hello from thread 1 out of 8 from process 1 out of 4 on midway2-0269.rcc.local Hello from thread 4 out of 8 from process 1 out of 4 on midway2-0269.rcc.local Hello from thread 5 out of 8 from process 1 out of 4 on midway2-0269.rcc.local Hello from thread 6 out of 8 from process 1 out of 4 on midway2-0269.rcc.local Hello from thread 0 out of 8 from process 2 out of 4 on midway2-0269.rcc.local Hello from thread 7 out of 8 from process 2 out of 4 on midway2-0269.rcc.local Hello from thread 4 out of 8 from process 2 out of 4 on midway2-0269.rcc.local Hello from thread 5 out of 8 from process 2 out of 4 on midway2-0269.rcc.local Hello from thread 1 out of 8 from process 2 out of 4 on midway2-0269.rcc.local Hello from thread 6 out of 8 from process 2 out of 4 on midway2-0269.rcc.local Hello from thread 3 out of 8 from process 2 out of 4 on midway2-0269.rcc.local Hello from thread 2 out of 8 from process 2 out of 4 on midway2-0269.rcc.local Hello from thread 0 out of 8 from process 3 out of 4 on midway2-0270.rcc.local Hello from thread 7 out of 8 from process 3 out of 4 on midway2-0270.rcc.local Hello from thread 4 out of 8 from process 3 out of 4 on midway2-0270.rcc.local Hello from thread 6 out of 8 from process 3 out of 4 on midway2-0270.rcc.local Hello from thread 2 out of 8 from process 3 out of 4 on midway2-0270.rcc.local Hello from thread 5 out of 8 from process 3 out of 4 on midway2-0270.rcc.local Hello from thread 1 out of 8 from process 3 out of 4 on midway2-0270.rcc.local","title":"Hybrid MPI/OpenMP jobs"},{"location":"midway23/examples/example_job_scripts/#gpu-jobs","text":"The gpu2 partition is dedicated to software that uses Graphical Processing Units (GPUs). See Types of Compute Nodes for technical specifications of the gpu2 nodes. CUDA and OpenACC are two widely used tools for developing GPU-based software. For information on compiling code with CUDA and OpenACC, see CUDA and OpenACC Compilers .","title":"GPU jobs"},{"location":"midway23/examples/example_job_scripts/#running-gpu-code-on-midway2","text":"To submit a job to one of the GPU nodes, you must include the following lines in your sbatch script: #SBATCH --partition=gpu2 #SBATCH --gres=gpu:N where N is the number of GPUs requested. Allowable settings for N range from 1 to 4. If your application is entirely GPU driven, then you do not need to explicilty request cores as one CPU core will be assigned by default to act as a master to launch the GPU based calculation. If however your application is mixed CPU-GPU then you will need to request the number of cores with \u2013ntasks as is required by your job. Here is an example sbatch script that allocates GPU resources and loads the CUDA compilers (see also gpu.sbatch ): #!/bin/bash #SBATCH --job-name=gpu # job name #SBATCH --output=gpu.out # output log file #SBATCH --error=gpu.err # error file #SBATCH --time=01:00:00 # 1 hour of wall time #SBATCH --nodes=1 # 1 GPU node #SBATCH --partition=gpu2 # GPU2 partition #SBATCH --ntasks=1 # 1 CPU core to drive GPU #SBATCH --gres=gpu:1 # Request 1 GPU # Load all required modules below. As an example we load cuda/9.1 module load cuda/9.1 # Add lines here to run your GPU-based computations.","title":"Running GPU code on Midway2"},{"location":"midway23/examples/example_job_scripts/#cron-like-jobs","text":"Cron jobs persist until they are canceled or encounter an error. The Midway2 cluster has a dedicated partition, cron , for running Cron jobs. Please email help@rcc.uchicago.edu to request submitting Cron-like jobs. These jobs are subject to scheduling limits and will be monitored. Here is an example of an sbatch script that runs a Cron job (see also cron.sbatch ): #!/bin/bash #SBATCH --time=00:05:00 #SBATCH --output=cron.log #SBATCH --open-mode=append #SBATCH --account=cron-account #SBATCH --partition=cron #SBATCH --qos=cron # Specify a valid Cron string for the schedule. This specifies that # the Cron job run once per day at 5:15a. SCHEDULE = '15 5 * * *' # Here is an example of a simple command that prints the host name and # the date and time. echo \"Hello on $( hostname ) at $( date ) .\" # This schedules the next run. sbatch --quiet --begin = $( next-cron-time \" $SCHEDULE \" ) cron.sbatch After executing a simple command (print the host name, date and time), the script schedules the next run with another call to sbatch with the --begin option.","title":"Cron-like jobs"},{"location":"midway23/examples/gpu/","text":"GPU jobs The gpu2 partition is dedicated to software that uses Graphical Processing Units (GPUs). See Types of Compute Nodes for technical specifications of the gpu2 nodes. CUDA and OpenACC are two widely used tools for developing GPU-based software. For information on compiling code with CUDA and OpenACC, see CUDA and OpenACC Compilers . Running GPU code on Midway2 To submit a job to one of the GPU nodes, you must include the following lines in your sbatch script: #SBATCH --partition=gpu2 #SBATCH --gres=gpu:N where N is the number of GPUs requested. Allowable settings for N range from 1 to 4. If your application is entirely GPU driven, then you do not need to explicilty request cores as one CPU core will be assigned by default to act as a master to launch the GPU based calculation. If however your application is mixed CPU-GPU then you will need to request the number of cores with \u2013ntasks as is required by your job. Here is an example sbatch script that allocates GPU resources and loads the CUDA compilers (see also gpu.sbatch ): #!/bin/bash #SBATCH --job-name=gpu # job name #SBATCH --output=gpu.out # output log file #SBATCH --error=gpu.err # error file #SBATCH --time=01:00:00 # 1 hour of wall time #SBATCH --nodes=1 # 1 GPU node #SBATCH --partition=gpu2 # GPU2 partition #SBATCH --ntasks=1 # 1 CPU core to drive GPU #SBATCH --gres=gpu:1 # Request 1 GPU # Load all required modules below. As an example we load cuda/9.1 module load cuda/9.1 # Add lines here to run your GPU-based computations.","title":"GPU jobs"},{"location":"midway23/examples/gpu/#gpu-jobs","text":"The gpu2 partition is dedicated to software that uses Graphical Processing Units (GPUs). See Types of Compute Nodes for technical specifications of the gpu2 nodes. CUDA and OpenACC are two widely used tools for developing GPU-based software. For information on compiling code with CUDA and OpenACC, see CUDA and OpenACC Compilers .","title":"GPU jobs"},{"location":"midway23/examples/gpu/#running-gpu-code-on-midway2","text":"To submit a job to one of the GPU nodes, you must include the following lines in your sbatch script: #SBATCH --partition=gpu2 #SBATCH --gres=gpu:N where N is the number of GPUs requested. Allowable settings for N range from 1 to 4. If your application is entirely GPU driven, then you do not need to explicilty request cores as one CPU core will be assigned by default to act as a master to launch the GPU based calculation. If however your application is mixed CPU-GPU then you will need to request the number of cores with \u2013ntasks as is required by your job. Here is an example sbatch script that allocates GPU resources and loads the CUDA compilers (see also gpu.sbatch ): #!/bin/bash #SBATCH --job-name=gpu # job name #SBATCH --output=gpu.out # output log file #SBATCH --error=gpu.err # error file #SBATCH --time=01:00:00 # 1 hour of wall time #SBATCH --nodes=1 # 1 GPU node #SBATCH --partition=gpu2 # GPU2 partition #SBATCH --ntasks=1 # 1 CPU core to drive GPU #SBATCH --gres=gpu:1 # Request 1 GPU # Load all required modules below. As an example we load cuda/9.1 module load cuda/9.1 # Add lines here to run your GPU-based computations.","title":"Running GPU code on Midway2"},{"location":"midway23/examples/hybrid/","text":"Hybrid MPI/OpenMP jobs MPI and OpenMP can be used at the same time to create a Hybrid MPI/OpenMP program. Let\u2019s look at an example Hybrid MPI/OpenMP hello world program and explain the steps needed to compile and submit it to the queue. An example hybrid MPI hello world program: hellohybrid.c #include <stdio.h> #include <omp.h> #include \"mpi.h\" int main ( int argc , char * argv []) { int numprocs , rank , namelen ; char processor_name [ MPI_MAX_PROCESSOR_NAME ]; int iam = 0 , np = 1 ; MPI_Init ( & argc , & argv ); MPI_Comm_size ( MPI_COMM_WORLD , & numprocs ); MPI_Comm_rank ( MPI_COMM_WORLD , & rank ); MPI_Get_processor_name ( processor_name , & namelen ); #pragma omp parallel default(shared) private(iam, np) { np = omp_get_num_threads (); iam = omp_get_thread_num (); printf ( \"Hello from thread %d out of %d from process %d out of %d on %s \\n \" , iam , np , rank , numprocs , processor_name ); } MPI_Finalize (); } To run the program on the RCC cluster, copy hellohybrid.c and hellohybrid.sbatch to your home directory, then compile the code interactively by entering the following commands into a terminal on a Midway2 login node: module load openmpi mpicc -fopenmp hellohybrid.c -o hellohybrid Here we load the default MPI compiler, but it should be possible to use any available MPI compiler to compile and run this example. Note that the option -fopenmp must be used here to compile the program because the code includes OpenMP directives (use -openmp for the Intel compiler and -mp for the PGI compiler). hellohybrid.sbatch is a submission script that can be used to submit a job to Midway2 to run the hellohybrid program. #!/bin/bash # A job submission script for running a hybrid MPI/OpenMP job on # Midway2. #SBATCH --job-name=hellohybrid #SBATCH --output=hellohybrid.out #SBATCH --ntasks=4 #SBATCH --cpus-per-task=8 #SBATCH --partition=broadwl #SBATCH --constraint=edr # Load the default OpenMPI module. module load openmpi # Set OMP_NUM_THREADS to the number of CPUs per task we asked for. export OMP_NUM_THREADS = $SLURM_CPUS_PER_TASK # Run the process with mpirun. Note that the -n option is not required # in this case; mpirun will automatically determine how many processes # to run from the Slurm settings. mpirun ./hellohybrid The options are similar to running an MPI job, with some differences: * ` --ntasks = 4 ` specifies the number of MPI processes ( \u201ctasks\u201d ) . * ` --cpus-per-task = 8 ` allocates 8 CPUs for each task. * ` export OMP_NUM_THREADS = $SLURM_CPUS_PER_TASK ` sets the number of OpenMP threads to the number of requested cores ( CPUs ) for each task. You can submit ` hellohybrid.sbatch ` using the following command from one of Midway2 login nodes: ``` default sbatch hellohybrid.sbatch Here is an example output of this program submitted to the broadwl partition on Midway2: Hello from thread 0 out of 8 from process 0 out of 4 on midway2-0269.rcc.local Hello from thread 6 out of 8 from process 0 out of 4 on midway2-0269.rcc.local Hello from thread 0 out of 8 from process 1 out of 4 on midway2-0269.rcc.local Hello from thread 7 out of 8 from process 1 out of 4 on midway2-0269.rcc.local Hello from thread 3 out of 8 from process 1 out of 4 on midway2-0269.rcc.local Hello from thread 2 out of 8 from process 0 out of 4 on midway2-0269.rcc.local Hello from thread 3 out of 8 from process 0 out of 4 on midway2-0269.rcc.local Hello from thread 4 out of 8 from process 0 out of 4 on midway2-0269.rcc.local Hello from thread 5 out of 8 from process 0 out of 4 on midway2-0269.rcc.local Hello from thread 1 out of 8 from process 0 out of 4 on midway2-0269.rcc.local Hello from thread 7 out of 8 from process 0 out of 4 on midway2-0269.rcc.local Hello from thread 2 out of 8 from process 1 out of 4 on midway2-0269.rcc.local Hello from thread 1 out of 8 from process 1 out of 4 on midway2-0269.rcc.local Hello from thread 4 out of 8 from process 1 out of 4 on midway2-0269.rcc.local Hello from thread 5 out of 8 from process 1 out of 4 on midway2-0269.rcc.local Hello from thread 6 out of 8 from process 1 out of 4 on midway2-0269.rcc.local Hello from thread 0 out of 8 from process 2 out of 4 on midway2-0269.rcc.local Hello from thread 7 out of 8 from process 2 out of 4 on midway2-0269.rcc.local Hello from thread 4 out of 8 from process 2 out of 4 on midway2-0269.rcc.local Hello from thread 5 out of 8 from process 2 out of 4 on midway2-0269.rcc.local Hello from thread 1 out of 8 from process 2 out of 4 on midway2-0269.rcc.local Hello from thread 6 out of 8 from process 2 out of 4 on midway2-0269.rcc.local Hello from thread 3 out of 8 from process 2 out of 4 on midway2-0269.rcc.local Hello from thread 2 out of 8 from process 2 out of 4 on midway2-0269.rcc.local Hello from thread 0 out of 8 from process 3 out of 4 on midway2-0270.rcc.local Hello from thread 7 out of 8 from process 3 out of 4 on midway2-0270.rcc.local Hello from thread 4 out of 8 from process 3 out of 4 on midway2-0270.rcc.local Hello from thread 6 out of 8 from process 3 out of 4 on midway2-0270.rcc.local Hello from thread 2 out of 8 from process 3 out of 4 on midway2-0270.rcc.local Hello from thread 5 out of 8 from process 3 out of 4 on midway2-0270.rcc.local Hello from thread 1 out of 8 from process 3 out of 4 on midway2-0270.rcc.local","title":"Hybrid MPI/OpenMP jobs"},{"location":"midway23/examples/hybrid/#hybrid-mpiopenmp-jobs","text":"MPI and OpenMP can be used at the same time to create a Hybrid MPI/OpenMP program. Let\u2019s look at an example Hybrid MPI/OpenMP hello world program and explain the steps needed to compile and submit it to the queue. An example hybrid MPI hello world program: hellohybrid.c #include <stdio.h> #include <omp.h> #include \"mpi.h\" int main ( int argc , char * argv []) { int numprocs , rank , namelen ; char processor_name [ MPI_MAX_PROCESSOR_NAME ]; int iam = 0 , np = 1 ; MPI_Init ( & argc , & argv ); MPI_Comm_size ( MPI_COMM_WORLD , & numprocs ); MPI_Comm_rank ( MPI_COMM_WORLD , & rank ); MPI_Get_processor_name ( processor_name , & namelen ); #pragma omp parallel default(shared) private(iam, np) { np = omp_get_num_threads (); iam = omp_get_thread_num (); printf ( \"Hello from thread %d out of %d from process %d out of %d on %s \\n \" , iam , np , rank , numprocs , processor_name ); } MPI_Finalize (); } To run the program on the RCC cluster, copy hellohybrid.c and hellohybrid.sbatch to your home directory, then compile the code interactively by entering the following commands into a terminal on a Midway2 login node: module load openmpi mpicc -fopenmp hellohybrid.c -o hellohybrid Here we load the default MPI compiler, but it should be possible to use any available MPI compiler to compile and run this example. Note that the option -fopenmp must be used here to compile the program because the code includes OpenMP directives (use -openmp for the Intel compiler and -mp for the PGI compiler). hellohybrid.sbatch is a submission script that can be used to submit a job to Midway2 to run the hellohybrid program. #!/bin/bash # A job submission script for running a hybrid MPI/OpenMP job on # Midway2. #SBATCH --job-name=hellohybrid #SBATCH --output=hellohybrid.out #SBATCH --ntasks=4 #SBATCH --cpus-per-task=8 #SBATCH --partition=broadwl #SBATCH --constraint=edr # Load the default OpenMPI module. module load openmpi # Set OMP_NUM_THREADS to the number of CPUs per task we asked for. export OMP_NUM_THREADS = $SLURM_CPUS_PER_TASK # Run the process with mpirun. Note that the -n option is not required # in this case; mpirun will automatically determine how many processes # to run from the Slurm settings. mpirun ./hellohybrid The options are similar to running an MPI job, with some differences: * ` --ntasks = 4 ` specifies the number of MPI processes ( \u201ctasks\u201d ) . * ` --cpus-per-task = 8 ` allocates 8 CPUs for each task. * ` export OMP_NUM_THREADS = $SLURM_CPUS_PER_TASK ` sets the number of OpenMP threads to the number of requested cores ( CPUs ) for each task. You can submit ` hellohybrid.sbatch ` using the following command from one of Midway2 login nodes: ``` default sbatch hellohybrid.sbatch Here is an example output of this program submitted to the broadwl partition on Midway2: Hello from thread 0 out of 8 from process 0 out of 4 on midway2-0269.rcc.local Hello from thread 6 out of 8 from process 0 out of 4 on midway2-0269.rcc.local Hello from thread 0 out of 8 from process 1 out of 4 on midway2-0269.rcc.local Hello from thread 7 out of 8 from process 1 out of 4 on midway2-0269.rcc.local Hello from thread 3 out of 8 from process 1 out of 4 on midway2-0269.rcc.local Hello from thread 2 out of 8 from process 0 out of 4 on midway2-0269.rcc.local Hello from thread 3 out of 8 from process 0 out of 4 on midway2-0269.rcc.local Hello from thread 4 out of 8 from process 0 out of 4 on midway2-0269.rcc.local Hello from thread 5 out of 8 from process 0 out of 4 on midway2-0269.rcc.local Hello from thread 1 out of 8 from process 0 out of 4 on midway2-0269.rcc.local Hello from thread 7 out of 8 from process 0 out of 4 on midway2-0269.rcc.local Hello from thread 2 out of 8 from process 1 out of 4 on midway2-0269.rcc.local Hello from thread 1 out of 8 from process 1 out of 4 on midway2-0269.rcc.local Hello from thread 4 out of 8 from process 1 out of 4 on midway2-0269.rcc.local Hello from thread 5 out of 8 from process 1 out of 4 on midway2-0269.rcc.local Hello from thread 6 out of 8 from process 1 out of 4 on midway2-0269.rcc.local Hello from thread 0 out of 8 from process 2 out of 4 on midway2-0269.rcc.local Hello from thread 7 out of 8 from process 2 out of 4 on midway2-0269.rcc.local Hello from thread 4 out of 8 from process 2 out of 4 on midway2-0269.rcc.local Hello from thread 5 out of 8 from process 2 out of 4 on midway2-0269.rcc.local Hello from thread 1 out of 8 from process 2 out of 4 on midway2-0269.rcc.local Hello from thread 6 out of 8 from process 2 out of 4 on midway2-0269.rcc.local Hello from thread 3 out of 8 from process 2 out of 4 on midway2-0269.rcc.local Hello from thread 2 out of 8 from process 2 out of 4 on midway2-0269.rcc.local Hello from thread 0 out of 8 from process 3 out of 4 on midway2-0270.rcc.local Hello from thread 7 out of 8 from process 3 out of 4 on midway2-0270.rcc.local Hello from thread 4 out of 8 from process 3 out of 4 on midway2-0270.rcc.local Hello from thread 6 out of 8 from process 3 out of 4 on midway2-0270.rcc.local Hello from thread 2 out of 8 from process 3 out of 4 on midway2-0270.rcc.local Hello from thread 5 out of 8 from process 3 out of 4 on midway2-0270.rcc.local Hello from thread 1 out of 8 from process 3 out of 4 on midway2-0270.rcc.local","title":"Hybrid MPI/OpenMP jobs"},{"location":"midway23/examples/mpi/","text":"MPI jobs Here we present a couple small examples illustrating how to use MPI for distributed computing Midway. For more information on the MPI libraries available on Midway, see Message Passing Interface (MPI) . Our main illustration is a \u201chello world\u201d example. See file hellompi.c for the C code we will compile and run. #include <stdio.h> #include <stdlib.h> #include <mpi.h> int main ( int argc , char * argv [], char * envp []) { int numprocs , rank , namelen ; char processor_name [ MPI_MAX_PROCESSOR_NAME ]; MPI_Init ( & argc , & argv ); MPI_Comm_size ( MPI_COMM_WORLD , & numprocs ); MPI_Comm_rank ( MPI_COMM_WORLD , & rank ); MPI_Get_processor_name ( processor_name , & namelen ); printf ( \"Process %d on %s out of %d \\n \" , rank , processor_name , numprocs ); MPI_Finalize (); } Copy hellompi.c to your home directory on Midway, load the default OpenMPI module, and compile the program on a Midway login node: module load openmpi mpicc hellompi.c -o hellompi hellompi.sbatch is a submission script that can be used to submit a job to Midway to run the hellompi program: #!/bin/bash #SBATCH --job-name=hellompi #SBATCH --output=hellompi.out #SBATCH --ntasks=56 #SBATCH --partition=broadwl #SBATCH --constraint=fdr # Load the default OpenMPI module. module load openmpi # Run the hellompi program with mpirun. The -n flag is not required; # mpirun will automatically figure out the best configuration from the # Slurm environment variables. mpirun ./hellompi Submit the MPI job to the Slurm job scheduler from a Midway login node: sbatch hellompi.sbatch Here is an example output: Process 1 on midway2-0172.rcc.local out of 56 Process 3 on midway2-0172.rcc.local out of 56 Process 5 on midway2-0172.rcc.local out of 56 Process 7 on midway2-0172.rcc.local out of 56 Process 6 on midway2-0172.rcc.local out of 56 Process 9 on midway2-0172.rcc.local out of 56 Process 10 on midway2-0172.rcc.local out of 56 Process 11 on midway2-0172.rcc.local out of 56 Process 13 on midway2-0172.rcc.local out of 56 Process 0 on midway2-0172.rcc.local out of 56 Process 2 on midway2-0172.rcc.local out of 56 Process 4 on midway2-0172.rcc.local out of 56 Process 8 on midway2-0172.rcc.local out of 56 Process 12 on midway2-0172.rcc.local out of 56 Process 17 on midway2-0173.rcc.local out of 56 Process 19 on midway2-0173.rcc.local out of 56 Process 21 on midway2-0173.rcc.local out of 56 Process 28 on midway2-0173.rcc.local out of 56 Process 29 on midway2-0173.rcc.local out of 56 Process 31 on midway2-0173.rcc.local out of 56 Process 32 on midway2-0173.rcc.local out of 56 Process 15 on midway2-0173.rcc.local out of 56 Process 18 on midway2-0173.rcc.local out of 56 Process 20 on midway2-0173.rcc.local out of 56 Process 22 on midway2-0173.rcc.local out of 56 Process 23 on midway2-0173.rcc.local out of 56 Process 24 on midway2-0173.rcc.local out of 56 Process 52 on midway2-0175.rcc.local out of 56 Process 25 on midway2-0173.rcc.local out of 56 Process 53 on midway2-0175.rcc.local out of 56 Process 26 on midway2-0173.rcc.local out of 56 Process 54 on midway2-0175.rcc.local out of 56 Process 27 on midway2-0173.rcc.local out of 56 Process 55 on midway2-0175.rcc.local out of 56 Process 14 on midway2-0173.rcc.local out of 56 Process 16 on midway2-0173.rcc.local out of 56 Process 30 on midway2-0173.rcc.local out of 56 Process 43 on midway2-0174.rcc.local out of 56 Process 51 on midway2-0174.rcc.local out of 56 Process 48 on midway2-0174.rcc.local out of 56 Process 49 on midway2-0174.rcc.local out of 56 Process 46 on midway2-0174.rcc.local out of 56 Process 44 on midway2-0174.rcc.local out of 56 Process 45 on midway2-0174.rcc.local out of 56 Process 40 on midway2-0174.rcc.local out of 56 Process 42 on midway2-0174.rcc.local out of 56 Process 36 on midway2-0174.rcc.local out of 56 Process 37 on midway2-0174.rcc.local out of 56 Process 47 on midway2-0174.rcc.local out of 56 Process 34 on midway2-0174.rcc.local out of 56 Process 38 on midway2-0174.rcc.local out of 56 Process 35 on midway2-0174.rcc.local out of 56 Process 39 on midway2-0174.rcc.local out of 56 Process 41 on midway2-0174.rcc.local out of 56 Process 50 on midway2-0174.rcc.local out of 56 Process 33 on midway2-0174.rcc.local out of 56 From this output, we observe that the computation is distributed on 4 different nodes, with many threads running simultaneously on the same node. When developing your own sbatch script for MPI-based computations, keep in mind the following points. Without the --constraint=fdr or --constraint=edr options, your computations may run on nodes with FDR, EDR, or combination of both. It is possible to control the number of tasks that are run per node with the --ntasks-per-node option. For example, submitting the job like this to Midway: sbatch --ntasks-per-node=1 hellompi.sbatch results in each thread running on a different node: Process 52 on midway2-0175.rcc.local out of 56 Process 50 on midway2-0173.rcc.local out of 56 Process 49 on midway2-0172.rcc.local out of 56 Process 0 on midway2-0002.rcc.local out of 56 Process 13 on midway2-0052.rcc.local out of 56 Process 2 on midway2-0013.rcc.local out of 56 Process 9 on midway2-0033.rcc.local out of 56 Process 54 on midway2-0177.rcc.local out of 56 Process 53 on midway2-0176.rcc.local out of 56 Process 44 on midway2-0157.rcc.local out of 56 Process 55 on midway2-0178.rcc.local out of 56 Process 11 on midway2-0041.rcc.local out of 56 Process 40 on midway2-0152.rcc.local out of 56 Process 43 on midway2-0156.rcc.local out of 56 Process 45 on midway2-0161.rcc.local out of 56 Process 46 on midway2-0162.rcc.local out of 56 Process 38 on midway2-0147.rcc.local out of 56 Process 39 on midway2-0148.rcc.local out of 56 Process 24 on midway2-0101.rcc.local out of 56 Process 3 on midway2-0014.rcc.local out of 56 Process 42 on midway2-0155.rcc.local out of 56 Process 51 on midway2-0174.rcc.local out of 56 Process 36 on midway2-0145.rcc.local out of 56 Process 25 on midway2-0102.rcc.local out of 56 Process 16 on midway2-0055.rcc.local out of 56 Process 18 on midway2-0057.rcc.local out of 56 Process 12 on midway2-0051.rcc.local out of 56 Process 14 on midway2-0053.rcc.local out of 56 Process 4 on midway2-0015.rcc.local out of 56 Process 15 on midway2-0054.rcc.local out of 56 Process 48 on midway2-0164.rcc.local out of 56 Process 28 on midway2-0105.rcc.local out of 56 Process 22 on midway2-0097.rcc.local out of 56 Process 30 on midway2-0118.rcc.local out of 56 Process 1 on midway2-0012.rcc.local out of 56 Process 35 on midway2-0144.rcc.local out of 56 Process 17 on midway2-0056.rcc.local out of 56 Process 37 on midway2-0146.rcc.local out of 56 Process 32 on midway2-0141.rcc.local out of 56 Process 34 on midway2-0143.rcc.local out of 56 Process 27 on midway2-0104.rcc.local out of 56 Process 31 on midway2-0119.rcc.local out of 56 Process 29 on midway2-0106.rcc.local out of 56 Process 10 on midway2-0034.rcc.local out of 56 Process 47 on midway2-0163.rcc.local out of 56 Process 33 on midway2-0142.rcc.local out of 56 Process 26 on midway2-0103.rcc.local out of 56 Process 7 on midway2-0019.rcc.local out of 56 Process 20 on midway2-0073.rcc.local out of 56 Process 5 on midway2-0016.rcc.local out of 56 Process 8 on midway2-0027.rcc.local out of 56 Process 41 on midway2-0153.rcc.local out of 56 Process 6 on midway2-0017.rcc.local out of 56 Process 21 on midway2-0096.rcc.local out of 56 Process 19 on midway2-0072.rcc.local out of 56 Process 23 on midway2-0100.rcc.local out of 56 Additional notes Both OpenMPI and IntelMPI have the ability to launch MPI programs directly with the Slurm command srun . It is not necessary to use this mode for most jobs, but it may provide additional job launch options. For example, from a Midway login node it is possible to launch the above hellompi program using OpenMPI using 28 MPI processes: srun -n28 hellompi With IntelMPI, you need to also set an environment variable for this to work: export I_MPI_PMI_LIBRARY=/software/slurm-current-$DISTARCH/lib/libpmi.so srun -n28 hellompi","title":"MPI jobs"},{"location":"midway23/examples/mpi/#mpi-jobs","text":"Here we present a couple small examples illustrating how to use MPI for distributed computing Midway. For more information on the MPI libraries available on Midway, see Message Passing Interface (MPI) . Our main illustration is a \u201chello world\u201d example. See file hellompi.c for the C code we will compile and run. #include <stdio.h> #include <stdlib.h> #include <mpi.h> int main ( int argc , char * argv [], char * envp []) { int numprocs , rank , namelen ; char processor_name [ MPI_MAX_PROCESSOR_NAME ]; MPI_Init ( & argc , & argv ); MPI_Comm_size ( MPI_COMM_WORLD , & numprocs ); MPI_Comm_rank ( MPI_COMM_WORLD , & rank ); MPI_Get_processor_name ( processor_name , & namelen ); printf ( \"Process %d on %s out of %d \\n \" , rank , processor_name , numprocs ); MPI_Finalize (); } Copy hellompi.c to your home directory on Midway, load the default OpenMPI module, and compile the program on a Midway login node: module load openmpi mpicc hellompi.c -o hellompi hellompi.sbatch is a submission script that can be used to submit a job to Midway to run the hellompi program: #!/bin/bash #SBATCH --job-name=hellompi #SBATCH --output=hellompi.out #SBATCH --ntasks=56 #SBATCH --partition=broadwl #SBATCH --constraint=fdr # Load the default OpenMPI module. module load openmpi # Run the hellompi program with mpirun. The -n flag is not required; # mpirun will automatically figure out the best configuration from the # Slurm environment variables. mpirun ./hellompi Submit the MPI job to the Slurm job scheduler from a Midway login node: sbatch hellompi.sbatch Here is an example output: Process 1 on midway2-0172.rcc.local out of 56 Process 3 on midway2-0172.rcc.local out of 56 Process 5 on midway2-0172.rcc.local out of 56 Process 7 on midway2-0172.rcc.local out of 56 Process 6 on midway2-0172.rcc.local out of 56 Process 9 on midway2-0172.rcc.local out of 56 Process 10 on midway2-0172.rcc.local out of 56 Process 11 on midway2-0172.rcc.local out of 56 Process 13 on midway2-0172.rcc.local out of 56 Process 0 on midway2-0172.rcc.local out of 56 Process 2 on midway2-0172.rcc.local out of 56 Process 4 on midway2-0172.rcc.local out of 56 Process 8 on midway2-0172.rcc.local out of 56 Process 12 on midway2-0172.rcc.local out of 56 Process 17 on midway2-0173.rcc.local out of 56 Process 19 on midway2-0173.rcc.local out of 56 Process 21 on midway2-0173.rcc.local out of 56 Process 28 on midway2-0173.rcc.local out of 56 Process 29 on midway2-0173.rcc.local out of 56 Process 31 on midway2-0173.rcc.local out of 56 Process 32 on midway2-0173.rcc.local out of 56 Process 15 on midway2-0173.rcc.local out of 56 Process 18 on midway2-0173.rcc.local out of 56 Process 20 on midway2-0173.rcc.local out of 56 Process 22 on midway2-0173.rcc.local out of 56 Process 23 on midway2-0173.rcc.local out of 56 Process 24 on midway2-0173.rcc.local out of 56 Process 52 on midway2-0175.rcc.local out of 56 Process 25 on midway2-0173.rcc.local out of 56 Process 53 on midway2-0175.rcc.local out of 56 Process 26 on midway2-0173.rcc.local out of 56 Process 54 on midway2-0175.rcc.local out of 56 Process 27 on midway2-0173.rcc.local out of 56 Process 55 on midway2-0175.rcc.local out of 56 Process 14 on midway2-0173.rcc.local out of 56 Process 16 on midway2-0173.rcc.local out of 56 Process 30 on midway2-0173.rcc.local out of 56 Process 43 on midway2-0174.rcc.local out of 56 Process 51 on midway2-0174.rcc.local out of 56 Process 48 on midway2-0174.rcc.local out of 56 Process 49 on midway2-0174.rcc.local out of 56 Process 46 on midway2-0174.rcc.local out of 56 Process 44 on midway2-0174.rcc.local out of 56 Process 45 on midway2-0174.rcc.local out of 56 Process 40 on midway2-0174.rcc.local out of 56 Process 42 on midway2-0174.rcc.local out of 56 Process 36 on midway2-0174.rcc.local out of 56 Process 37 on midway2-0174.rcc.local out of 56 Process 47 on midway2-0174.rcc.local out of 56 Process 34 on midway2-0174.rcc.local out of 56 Process 38 on midway2-0174.rcc.local out of 56 Process 35 on midway2-0174.rcc.local out of 56 Process 39 on midway2-0174.rcc.local out of 56 Process 41 on midway2-0174.rcc.local out of 56 Process 50 on midway2-0174.rcc.local out of 56 Process 33 on midway2-0174.rcc.local out of 56 From this output, we observe that the computation is distributed on 4 different nodes, with many threads running simultaneously on the same node. When developing your own sbatch script for MPI-based computations, keep in mind the following points. Without the --constraint=fdr or --constraint=edr options, your computations may run on nodes with FDR, EDR, or combination of both. It is possible to control the number of tasks that are run per node with the --ntasks-per-node option. For example, submitting the job like this to Midway: sbatch --ntasks-per-node=1 hellompi.sbatch results in each thread running on a different node: Process 52 on midway2-0175.rcc.local out of 56 Process 50 on midway2-0173.rcc.local out of 56 Process 49 on midway2-0172.rcc.local out of 56 Process 0 on midway2-0002.rcc.local out of 56 Process 13 on midway2-0052.rcc.local out of 56 Process 2 on midway2-0013.rcc.local out of 56 Process 9 on midway2-0033.rcc.local out of 56 Process 54 on midway2-0177.rcc.local out of 56 Process 53 on midway2-0176.rcc.local out of 56 Process 44 on midway2-0157.rcc.local out of 56 Process 55 on midway2-0178.rcc.local out of 56 Process 11 on midway2-0041.rcc.local out of 56 Process 40 on midway2-0152.rcc.local out of 56 Process 43 on midway2-0156.rcc.local out of 56 Process 45 on midway2-0161.rcc.local out of 56 Process 46 on midway2-0162.rcc.local out of 56 Process 38 on midway2-0147.rcc.local out of 56 Process 39 on midway2-0148.rcc.local out of 56 Process 24 on midway2-0101.rcc.local out of 56 Process 3 on midway2-0014.rcc.local out of 56 Process 42 on midway2-0155.rcc.local out of 56 Process 51 on midway2-0174.rcc.local out of 56 Process 36 on midway2-0145.rcc.local out of 56 Process 25 on midway2-0102.rcc.local out of 56 Process 16 on midway2-0055.rcc.local out of 56 Process 18 on midway2-0057.rcc.local out of 56 Process 12 on midway2-0051.rcc.local out of 56 Process 14 on midway2-0053.rcc.local out of 56 Process 4 on midway2-0015.rcc.local out of 56 Process 15 on midway2-0054.rcc.local out of 56 Process 48 on midway2-0164.rcc.local out of 56 Process 28 on midway2-0105.rcc.local out of 56 Process 22 on midway2-0097.rcc.local out of 56 Process 30 on midway2-0118.rcc.local out of 56 Process 1 on midway2-0012.rcc.local out of 56 Process 35 on midway2-0144.rcc.local out of 56 Process 17 on midway2-0056.rcc.local out of 56 Process 37 on midway2-0146.rcc.local out of 56 Process 32 on midway2-0141.rcc.local out of 56 Process 34 on midway2-0143.rcc.local out of 56 Process 27 on midway2-0104.rcc.local out of 56 Process 31 on midway2-0119.rcc.local out of 56 Process 29 on midway2-0106.rcc.local out of 56 Process 10 on midway2-0034.rcc.local out of 56 Process 47 on midway2-0163.rcc.local out of 56 Process 33 on midway2-0142.rcc.local out of 56 Process 26 on midway2-0103.rcc.local out of 56 Process 7 on midway2-0019.rcc.local out of 56 Process 20 on midway2-0073.rcc.local out of 56 Process 5 on midway2-0016.rcc.local out of 56 Process 8 on midway2-0027.rcc.local out of 56 Process 41 on midway2-0153.rcc.local out of 56 Process 6 on midway2-0017.rcc.local out of 56 Process 21 on midway2-0096.rcc.local out of 56 Process 19 on midway2-0072.rcc.local out of 56 Process 23 on midway2-0100.rcc.local out of 56","title":"MPI jobs"},{"location":"midway23/examples/mpi/#additional-notes","text":"Both OpenMPI and IntelMPI have the ability to launch MPI programs directly with the Slurm command srun . It is not necessary to use this mode for most jobs, but it may provide additional job launch options. For example, from a Midway login node it is possible to launch the above hellompi program using OpenMPI using 28 MPI processes: srun -n28 hellompi With IntelMPI, you need to also set an environment variable for this to work: export I_MPI_PMI_LIBRARY=/software/slurm-current-$DISTARCH/lib/libpmi.so srun -n28 hellompi","title":"Additional notes"},{"location":"midway23/examples/srun/","text":"Parallel batch jobs Computations involving a very large number of independent computations should be combined in some way to reduce the number of jobs submitted to Slurm. Here we illustrate one strategy for doing this using GNU Parallel and srun . The parallel program executes tasks simultaneously until all tasks have been completed. Here\u2019s an example script, parallel.sbatch : #!/bin/sh #SBATCH --time=01:00:00 #SBATCH --partition=broadwl #SBATCH --ntasks=28 #SBATCH --mem-per-cpu=2G # NOTE DO NOT USE THE --mem= OPTION # Load the default version of GNU parallel. module load parallel # When running a large number of tasks simultaneously, it may be # necessary to increase the user process limit. ulimit -u 10000 # This specifies the options used to run srun. The \"-N1 -n1\" options are # used to allocates a single core to each task. srun = \"srun --exclusive -N1 -n1\" # This specifies the options used to run GNU parallel: # # --delay of 0.2 prevents overloading the controlling node. # # -j is the number of tasks run simultaneously. # # The combination of --joblog and --resume create a task log that # can be used to monitor progress. # parallel = \"parallel --delay 0.2 -j $SLURM_NTASKS --joblog runtask.log --resume\" # Run a script, runtask.sh, using GNU parallel and srun. Parallel # will run the runtask script for the numbers 1 through 128. To # illustrate, the first job will run like this: # # srun --exclusive -N1 -n1 ./runtask.sh arg1:1 > runtask.1 # $parallel \" $srun ./runtask.sh arg1:{1} > runtask.sh.{1}\" ::: { 1 ..128 } # Note that if your program does not take any input, use the -n0 option to # call the parallel command: # # $parallel -n0 \"$srun ./run_noinput_task.sh > output.{1}\" ::: {1..128} In this example, our aim is to run script runtask.sh 128 times. The --ntasks option is set to 28, so at most 28 tasks can be run simultaneously. Here is the runtask.sh script that is run by GNU parallel: #!/bin/sh # This script outputs some useful information so we can see what parallel # and srun are doing. sleepsecs = $ [ ( $RANDOM % 10 ) + 10 ] s # $1 is arg1:{1} from GNU parallel. # # $PARALLEL_SEQ is a special variable from GNU parallel. It gives the # number of the job in the sequence. # # Here we print the sleep time, host name, and the date and time. echo task $1 seq: $PARALLEL_SEQ sleep: $sleepsecs host: $( hostname ) date: $( date ) # Sleep a random amount of time. sleep $sleepsecs To submit this job, copy both parallel.sbatch and runtask.sh to the same directory, and run chmod +x runtask.sh to make runtask.sh executable. Then the job can be submitted to the Slurm queue: sbatch parallel.sbatch When this job completes, you should see output files with names runtask.sh.N , where N is a number between 1 and 128. The content of the first output file (i.e., runtask.sh.1 ) should look something like this: task arg1:1 seq:1 sleep:14s host:midway2-0002 date:Thu Jan 10 09:17:36 CST 2017 Another file runtask.log is also created. It gives a list of the completed jobs. (Note: If the sbatch is submitted again, nothing will be run until runtask.log is removed.) It is also possible to use this same technique to run multithreaded tasks in parallel. Here is an example sbatch script, parallel-hybrid.sbatch , that distributes multithreaded computations (each using 28 CPUs) across 2 nodes: #!/bin/sh #SBATCH --partition=broadwl #SBATCH --time=01:00:00 #SBATCH --nodes=2 #SBATCH --ntasks-per-node=1 #SBATCH --cpus-per-task=28 #SBATCH --exclusive # Load the default version of GNU parallel. module load parallel srun = \"srun --exclusive -N1 -n1 --cpus-per-task $SLURM_CPUS_PER_TASK \" # Instead of $SLURM_NTASKS, use $SLURM_NNODES to determine how # many jobs should be run simultaneously. parallel = \"parallel --delay 0.2 -j $SLURM_NNODES --joblog runtask.log --resume\" # Run the parallel command. $parallel \" $srun ./runtask.sh arg1:{1} > runtask.sh.{1}\" ::: { 1 ..6 }","title":"Parallel batch jobs"},{"location":"midway23/examples/srun/#parallel-batch-jobs","text":"Computations involving a very large number of independent computations should be combined in some way to reduce the number of jobs submitted to Slurm. Here we illustrate one strategy for doing this using GNU Parallel and srun . The parallel program executes tasks simultaneously until all tasks have been completed. Here\u2019s an example script, parallel.sbatch : #!/bin/sh #SBATCH --time=01:00:00 #SBATCH --partition=broadwl #SBATCH --ntasks=28 #SBATCH --mem-per-cpu=2G # NOTE DO NOT USE THE --mem= OPTION # Load the default version of GNU parallel. module load parallel # When running a large number of tasks simultaneously, it may be # necessary to increase the user process limit. ulimit -u 10000 # This specifies the options used to run srun. The \"-N1 -n1\" options are # used to allocates a single core to each task. srun = \"srun --exclusive -N1 -n1\" # This specifies the options used to run GNU parallel: # # --delay of 0.2 prevents overloading the controlling node. # # -j is the number of tasks run simultaneously. # # The combination of --joblog and --resume create a task log that # can be used to monitor progress. # parallel = \"parallel --delay 0.2 -j $SLURM_NTASKS --joblog runtask.log --resume\" # Run a script, runtask.sh, using GNU parallel and srun. Parallel # will run the runtask script for the numbers 1 through 128. To # illustrate, the first job will run like this: # # srun --exclusive -N1 -n1 ./runtask.sh arg1:1 > runtask.1 # $parallel \" $srun ./runtask.sh arg1:{1} > runtask.sh.{1}\" ::: { 1 ..128 } # Note that if your program does not take any input, use the -n0 option to # call the parallel command: # # $parallel -n0 \"$srun ./run_noinput_task.sh > output.{1}\" ::: {1..128} In this example, our aim is to run script runtask.sh 128 times. The --ntasks option is set to 28, so at most 28 tasks can be run simultaneously. Here is the runtask.sh script that is run by GNU parallel: #!/bin/sh # This script outputs some useful information so we can see what parallel # and srun are doing. sleepsecs = $ [ ( $RANDOM % 10 ) + 10 ] s # $1 is arg1:{1} from GNU parallel. # # $PARALLEL_SEQ is a special variable from GNU parallel. It gives the # number of the job in the sequence. # # Here we print the sleep time, host name, and the date and time. echo task $1 seq: $PARALLEL_SEQ sleep: $sleepsecs host: $( hostname ) date: $( date ) # Sleep a random amount of time. sleep $sleepsecs To submit this job, copy both parallel.sbatch and runtask.sh to the same directory, and run chmod +x runtask.sh to make runtask.sh executable. Then the job can be submitted to the Slurm queue: sbatch parallel.sbatch When this job completes, you should see output files with names runtask.sh.N , where N is a number between 1 and 128. The content of the first output file (i.e., runtask.sh.1 ) should look something like this: task arg1:1 seq:1 sleep:14s host:midway2-0002 date:Thu Jan 10 09:17:36 CST 2017 Another file runtask.log is also created. It gives a list of the completed jobs. (Note: If the sbatch is submitted again, nothing will be run until runtask.log is removed.) It is also possible to use this same technique to run multithreaded tasks in parallel. Here is an example sbatch script, parallel-hybrid.sbatch , that distributes multithreaded computations (each using 28 CPUs) across 2 nodes: #!/bin/sh #SBATCH --partition=broadwl #SBATCH --time=01:00:00 #SBATCH --nodes=2 #SBATCH --ntasks-per-node=1 #SBATCH --cpus-per-task=28 #SBATCH --exclusive # Load the default version of GNU parallel. module load parallel srun = \"srun --exclusive -N1 -n1 --cpus-per-task $SLURM_CPUS_PER_TASK \" # Instead of $SLURM_NTASKS, use $SLURM_NNODES to determine how # many jobs should be run simultaneously. parallel = \"parallel --delay 0.2 -j $SLURM_NNODES --joblog runtask.log --resume\" # Run the parallel command. $parallel \" $srun ./runtask.sh arg1:{1} > runtask.sh.{1}\" ::: { 1 ..6 }","title":"Parallel batch jobs"},{"location":"midwayr/midwayR_overview/","text":"Getting Started","title":"Overview"},{"location":"midwayr/midwayR_overview/#getting-started","text":"","title":"Getting Started"},{"location":"other_systems/beagle3_overview/","text":"Hardware Overview","title":"Overview"},{"location":"other_systems/beagle3_overview/#hardware-overview","text":"","title":"Hardware Overview"},{"location":"other_systems/dali_overview/","text":"Hardware Overview","title":"Overview"},{"location":"other_systems/dali_overview/#hardware-overview","text":"","title":"Hardware Overview"},{"location":"other_systems/midwayssd_overview/","text":"MidwaySSD Overview","title":"Overview"},{"location":"other_systems/midwayssd_overview/#midwayssd-overview","text":"","title":"MidwaySSD Overview"},{"location":"other_systems/skyway_overview/","text":"Hardware Overview","title":"Overview"},{"location":"other_systems/skyway_overview/#hardware-overview","text":"","title":"Hardware Overview"}]}